import numpy as np
import torch
import json
from tqdm import tqdm
import torch.nn.functional as F
import argparse
import os

# Argument Parsing
parser = argparse.ArgumentParser(description="Evaluate text-video similarity.")
parser.add_argument("--feature_path", type=str, required=True, help="Path to features .npy file")
parser.add_argument("--metadata_path", type=str, required=True, help="Path to metadata .json file")
args = parser.parse_args()

# âœ… GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# âœ… ë°ì´í„° íŒŒì¼ ë¡œë“œ
text_features = torch.tensor(np.load(os.path.join(args.feature_path, "text_features.npy"), mmap_mode="r"), dtype=torch.float32).to(device)
video_features = torch.tensor(np.load(os.path.join(args.feature_path, "video_features.npy"), mmap_mode="r"), dtype=torch.float32).to(device)

# âœ… ë¹„ë””ì˜¤ ë° í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open(os.path.join(args.metadata_path, "video_metadata.json"), "r") as f:
    video_metadata = json.load(f)
with open(os.path.join(args.metadata_path, "text_metadata.json"), "r") as f:
    text_metadata = json.load(f)

# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„°
text_batch_size = 100
video_batch_size = 5000
top_k_list = [1, 10, 100]

# âœ… ì •ë‹µ ë¹„ë””ì˜¤ ë§¤í•‘ (query_id -> ì •ë‹µ ë¹„ë””ì˜¤ ID)
query_to_gt = {qid: meta["vid"] for qid, meta in text_metadata.items()}

# âœ… ë¹„ë””ì˜¤ ID ë¦¬ìŠ¤íŠ¸
video_ids = list(video_metadata.keys())

# âœ… Top-K í‰ê°€ ê²°ê³¼ ì €ì¥
correct_top_k = {k: 0 for k in top_k_list}
total_queries = len(text_metadata)
processed_queries = 0

# âœ… ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
print("ğŸ”¹ Processing Text Batches...")
text_progress = tqdm(range(0, total_queries, text_batch_size), desc="Text Batches", unit="batch")

for text_start in text_progress:
    text_end = min(text_start + text_batch_size, total_queries)

    # ğŸ”¹ í…ìŠ¤íŠ¸ ë°°ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    text_batch = text_features[text_start:text_end].to(device)
    query_ids = list(text_metadata.keys())[text_start:text_end]

    # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ì •ê·œí™”
    text_batch = F.normalize(text_batch, p=2, dim=1)

    # ğŸ”¹ ìœ ì‚¬ë„ í–‰ë ¬ ì´ˆê¸°í™”
    similarity_matrix = torch.zeros((text_batch.shape[0], video_features.shape[0]), device=device)

    # ğŸ”¹ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—°ì‚°
    for video_start in range(0, video_features.shape[0], video_batch_size):
        video_end = min(video_start + video_batch_size, video_features.shape[0])
        video_batch = video_features[video_start:video_end].to(device)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ì •ê·œí™”
        video_batch = F.normalize(video_batch, p=2, dim=1)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (í–‰ë ¬ ì—°ì‚°)
        similarity_matrix[:, video_start:video_end] = F.cosine_similarity(
            text_batch.unsqueeze(1), video_batch.unsqueeze(0), dim=2
        )

    # âœ… ë¹„ë””ì˜¤ ë‹¨ìœ„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚° (í”„ë ˆì„ ë‹¨ìœ„ -> ë¹„ë””ì˜¤ ë‹¨ìœ„)
    video_similarities_per_query = torch.zeros((text_batch.shape[0], len(video_ids)), device=device)

    for vid_idx, vid in enumerate(video_ids):
        if vid not in video_metadata:
            continue  # ì—†ëŠ” ë¹„ë””ì˜¤ëŠ” ìŠ¤í‚µ

        global_start_idx = video_metadata[vid]["start_index"]
        total_vid_start = global_start_idx
        total_vid_end = global_start_idx + video_metadata[vid]["scene_segments"][-1][0]

        # âœ… ë¹„ë””ì˜¤ ë‚´ ëª¨ë“  í”„ë ˆì„ ìœ ì‚¬ë„ì˜ í‰ê· ì„ êµ¬í•´ì„œ ë¹„ë””ì˜¤ ë‹¨ìœ„ ìœ ì‚¬ë„ ìƒì„±
        video_similarities_per_query[:, vid_idx] = similarity_matrix[:, total_vid_start:total_vid_end].mean(dim=1)

    # âœ… Top-K ë¹„ë””ì˜¤ Retrieval ìˆ˜í–‰
    _, topk_indices = torch.topk(video_similarities_per_query, max(top_k_list), dim=1)

    # âœ… Top-K ë¹„ë””ì˜¤ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    sorted_videos_batch = [[video_ids[idx] for idx in indices] for indices in topk_indices.tolist()]

    # âœ… í‰ê°€ ìˆ˜í–‰
    for i, query_id in enumerate(query_ids):
        sorted_videos = sorted_videos_batch[i]
        for k in top_k_list:
            top_k_videos = sorted_videos[:k]
            if query_to_gt[query_id] in top_k_videos:
                correct_top_k[k] += 1

    # âœ… ì¤‘ê°„ í‰ê°€ ê²°ê³¼ ì—…ë°ì´íŠ¸
    processed_queries += len(query_ids)
    current_top_k_acc = {k: correct_top_k[k] / processed_queries for k in top_k_list}

    # âœ… tqdmì— ì •í™•ë„ ì—…ë°ì´íŠ¸
    text_progress.set_postfix({
        f"Top-{k} Acc": f"{current_top_k_acc[k]:.4f}" for k in top_k_list
    })

# âœ… ìµœì¢… í‰ê°€ ê²°ê³¼ ì¶œë ¥
print("\nâœ… Evaluation Results:")
for k in top_k_list:
    accuracy = correct_top_k[k] / total_queries
    print(f"ğŸ¯ Top-{k} Accuracy: {accuracy:.4f}")
