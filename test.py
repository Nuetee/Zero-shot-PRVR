import numpy as np
import torch
import json
from tqdm import tqdm
import torch.nn.functional as F  # cosine_similarity ì‚¬ìš©

# âœ… GPU ì„¤ì • (ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# âœ… ë°ì´í„° íŒŒì¼ ë¡œë“œ (mmap_mode="r" ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³  ì½ê¸°)
text_features = torch.tensor(np.load("text_features.npy", mmap_mode="r"), dtype=torch.float32).to(device)
video_features = torch.tensor(np.load("video_features.npy", mmap_mode="r"), dtype=torch.float32).to(device)

# âœ… ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open("video_metadata.json", "r") as f:
    video_metadata = json.load(f)

# âœ… í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ (query_id, ì •ë‹µ ë¹„ë””ì˜¤ ì •ë³´ í¬í•¨)
with open("text_metadata.json", "r") as f:
    text_metadata = json.load(f)

# âœ… ë¹„ë””ì˜¤ë³„ í›„ë³´ êµ¬ê°„ ì •ë³´ ì €ì¥
video_segments = {vid: torch.tensor(meta["proposals"], device=device) for vid, meta in video_metadata.items()}

# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
text_batch_size = 100
video_batch_size = 5000

# âœ… ì •ë‹µ ë¹„ë””ì˜¤ ë§¤í•‘ (query_id -> ì •ë‹µ ë¹„ë””ì˜¤ ID)
query_to_gt = {qid: meta["vid"] for qid, meta in text_metadata.items()}

# âœ… ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
results = []

# âœ… ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (GPU í™œìš©)
print("ğŸ”¹ Processing Text Batches...")
text_progress = tqdm(range(0, len(text_metadata), text_batch_size), desc="Text Batches", unit="batch")

for text_start in text_progress:
    text_end = min(text_start + text_batch_size, len(text_metadata))

    # ğŸ”¹ í…ìŠ¤íŠ¸ ë°°ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸° (GPU ì´ë™)
    text_batch = text_features[text_start:text_end].to(device)
    query_ids = list(text_metadata.keys())[text_start:text_end]

    # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ì •ê·œí™”
    text_batch = F.normalize(text_batch, p=2, dim=1)

    # ğŸ”¹ ìœ ì‚¬ë„ í–‰ë ¬ ì €ì¥ (í˜„ì¬ í…ìŠ¤íŠ¸ ë°°ì¹˜ì— ëŒ€í•œ ë¹„ë””ì˜¤ ìœ ì‚¬ë„)
    similarity_matrix = torch.zeros((text_batch.shape[0], video_features.shape[0]), device=device)

    # ğŸ”¹ ë¹„ë””ì˜¤ í”„ë ˆì„ë„ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì½ìœ¼ë©° ì—°ì‚° (GPU í™œìš©)
    for video_start in tqdm(range(0, video_features.shape[0], video_batch_size), desc="Video Batches", leave=False):
        video_end = min(video_start + video_batch_size, video_features.shape[0])

        # ğŸ”¹ ë¹„ë””ì˜¤ í”„ë ˆì„ ë°°ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸° (GPU ì´ë™)
        video_batch = video_features[video_start:video_end].to(device)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ì •ê·œí™”
        video_batch = F.normalize(video_batch, p=2, dim=1)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity_matrix[:, video_start:video_end] = F.cosine_similarity(
            text_batch.unsqueeze(1), video_batch.unsqueeze(0), dim=2
        )

    # ğŸ”¹ ê° ì¿¼ë¦¬ë³„ ë¶„ì„
    for i, query_id in enumerate(query_ids):
        similarity_vector = similarity_matrix[i]

        # ğŸ”¹ ì •ë‹µ ë¹„ë””ì˜¤ ID ê°€ì ¸ì˜¤ê¸°
        gt_vid = query_to_gt[query_id]
        
        if gt_vid not in video_metadata:
            continue  # ì •ë‹µ ë¹„ë””ì˜¤ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ

        # ğŸ”¹ ì •ë‹µ ë¹„ë””ì˜¤ì˜ ìœ ì‚¬ë„ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        global_start_idx = video_metadata[gt_vid]["start_index"]
        total_vid_start = global_start_idx
        total_vid_end = global_start_idx + video_metadata[gt_vid]["scene_segments"][-1][0]

        # âœ… (1) ì •ë‹µ ë¹„ë””ì˜¤ ì „ì²´ í”„ë ˆì„ ìœ ì‚¬ë„ í‰ê· ê°’
        video_similarities = similarity_vector[total_vid_start:total_vid_end]
        mean_video_similarity = torch.mean(video_similarities).item()
        min_video_similarity = torch.min(video_similarities).item()
        max_video_similarity = torch.max(video_similarities).item()

        # âœ… (2) ì •ë‹µ ë¹„ë””ì˜¤ ë‚´ segmentë“¤ì˜ ìœ ì‚¬ë„ í†µê³„ ê³„ì‚°
        if gt_vid in video_segments:
            segments = video_segments[gt_vid]
            padded_video_similarities = torch.cat((torch.tensor([0.0], device=video_similarities.device), video_similarities))
            cumsum_sim = torch.cumsum(padded_video_similarities, dim=0)

            segment_starts = segments[:, 0]  
            segment_ends = segments[:, 1]  

            segment_sums = cumsum_sim[segment_ends] - cumsum_sim[segment_starts]
            segment_lengths = (segment_ends - segment_starts).float()
            segment_avg_similarities = segment_sums / segment_lengths

            min_segment_similarity = torch.min(segment_avg_similarities).item()
            max_segment_similarity = torch.max(segment_avg_similarities).item()
            mean_segment_similarity = torch.mean(segment_avg_similarities).item()
        else:
            min_segment_similarity = None
            max_segment_similarity = None
            mean_segment_similarity = None

        # âœ… ê²°ê³¼ ì €ì¥
        results.append({
            "query_id": query_id,
            "gt_vid": gt_vid,
            "mean_video_similarity": mean_video_similarity,
            "min_video_similarity": min_video_similarity,
            "max_video_similarity": max_video_similarity,
            "min_segment_similarity": min_segment_similarity,
            "max_segment_similarity": max_segment_similarity,
            "mean_segment_similarity": mean_segment_similarity,
        })

# âœ… ì „ì²´ í†µê³„ ê³„ì‚°
valid_mean_video_sims = [r["mean_video_similarity"] for r in results if r["mean_video_similarity"] is not None]
valid_min_video_sims = [r["min_video_similarity"] for r in results if r["min_video_similarity"] is not None]
valid_max_video_sims = [r["max_video_similarity"] for r in results if r["max_video_similarity"] is not None]
valid_min_segment_sims = [r["min_segment_similarity"] for r in results if r["min_segment_similarity"] is not None]
valid_max_segment_sims = [r["max_segment_similarity"] for r in results if r["max_segment_similarity"] is not None]
valid_mean_segment_sims = [r["mean_segment_similarity"] for r in results if r["mean_segment_similarity"] is not None]

print("\nâœ… Overall Results Summary:")
print(f"ğŸ“Š Mean of mean_video_similarity: {np.mean(valid_mean_video_sims):.4f}" if valid_mean_video_sims else "No valid mean_video_similarity")
print(f"ğŸ“‰ Min of min_video_similarity: {np.min(valid_min_video_sims):.4f}" if valid_min_video_sims else "No valid min_video_similarity")
print(f"ğŸ“ˆ Max of max_video_similarity: {np.max(valid_max_video_sims):.4f}" if valid_max_video_sims else "No valid max_video_similarity")
print(f"ğŸ“Š Mean of mean_segment_similarity: {np.mean(valid_mean_segment_sims):.4f}" if valid_mean_segment_sims else "No valid mean_segment_similarity")
print(f"ğŸ“‰ Min of min_segment_similarity: {np.min(valid_min_segment_sims):.4f}" if valid_min_segment_sims else "No valid min_segment_similarity")
print(f"ğŸ“ˆ Max of max_segment_similarity: {np.max(valid_max_segment_sims):.4f}" if valid_max_segment_sims else "No valid max_segment_similarity")