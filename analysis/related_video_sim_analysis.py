import numpy as np
import torch
import json
from tqdm import tqdm
import torch.nn.functional as F
import matplotlib.pyplot as plt  # ì‹œê°í™” ì¶”ê°€

# âœ… GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# âœ… ë°ì´í„° íŒŒì¼ ë¡œë“œ
text_features = torch.tensor(np.load("text_features.npy", mmap_mode="r"), dtype=torch.float32).to(device)
video_features = torch.tensor(np.load("video_features.npy", mmap_mode="r"), dtype=torch.float32).to(device)

# âœ… ë¹„ë””ì˜¤ ë° í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open("video_metadata.json", "r") as f:
    video_metadata = json.load(f)
with open("text_metadata.json", "r") as f:
    text_metadata = json.load(f)

# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„°
text_batch_size = 100
video_batch_size = 5000

# âœ… ì •ë‹µ ë¹„ë””ì˜¤ ë§¤í•‘
query_to_gt = {qid: meta["vid"] for qid, meta in text_metadata.items()}

# âœ… ë¹„ë””ì˜¤ ID ë¦¬ìŠ¤íŠ¸
video_ids = list(video_metadata.keys())

# âœ… ìœ ì‚¬ë„ ì €ì¥ ë¦¬ìŠ¤íŠ¸
related_video_similarities = []
unrelated_video_similarities = []

# âœ… ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
print("ğŸ”¹ Processing Text Batches...")
text_progress = tqdm(range(0, len(text_metadata), text_batch_size), desc="Text Batches", unit="batch")

for text_start in text_progress:
    text_end = min(text_start + text_batch_size, len(text_metadata))

    # ğŸ”¹ í…ìŠ¤íŠ¸ ë°°ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    text_batch = text_features[text_start:text_end].to(device)
    query_ids = list(text_metadata.keys())[text_start:text_end]

    # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ì •ê·œí™”
    text_batch = F.normalize(text_batch, p=2, dim=1)

    # ğŸ”¹ ìœ ì‚¬ë„ í–‰ë ¬ ì´ˆê¸°í™”
    similarity_matrix = torch.zeros((text_batch.shape[0], video_features.shape[0]), device=device)

    # ğŸ”¹ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—°ì‚°
    for video_start in range(0, video_features.shape[0], video_batch_size):
        video_end = min(video_start + video_batch_size, video_features.shape[0])
        video_batch = video_features[video_start:video_end].to(device)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ì •ê·œí™”
        video_batch = F.normalize(video_batch, p=2, dim=1)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (í–‰ë ¬ ì—°ì‚°)
        similarity_matrix[:, video_start:video_end] = F.cosine_similarity(
            text_batch.unsqueeze(1), video_batch.unsqueeze(0), dim=2
        )

    # âœ… ë¹„ë””ì˜¤ ë‹¨ìœ„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚° (í”„ë ˆì„ ë‹¨ìœ„ -> ë¹„ë””ì˜¤ ë‹¨ìœ„)
    video_similarities_per_query = torch.zeros((text_batch.shape[0], len(video_ids)), device=device)

    for vid_idx, vid in enumerate(video_ids):
        if vid not in video_metadata:
            continue  # ì—†ëŠ” ë¹„ë””ì˜¤ëŠ” ìŠ¤í‚µ

        global_start_idx = video_metadata[vid]["start_index"]
        total_vid_start = global_start_idx
        total_vid_end = global_start_idx + video_metadata[vid]["scene_segments"][-1][0]

        # âœ… ë¹„ë””ì˜¤ ë‚´ ëª¨ë“  í”„ë ˆì„ ìœ ì‚¬ë„ì˜ í‰ê· ì„ êµ¬í•´ì„œ ë¹„ë””ì˜¤ ë‹¨ìœ„ ìœ ì‚¬ë„ ìƒì„±
        video_similarities_per_query[:, vid_idx] = similarity_matrix[:, total_vid_start:total_vid_end].mean(dim=1)

    # âœ… ì—°ê´€ëœ ë¹„ë””ì˜¤ ë° ì—°ê´€ë˜ì§€ ì•Šì€ ë¹„ë””ì˜¤ ìœ ì‚¬ë„ ë³‘ë ¬ ì—°ì‚°
    for i, query_id in enumerate(query_ids):
        gt_vid = query_to_gt[query_id]

        # ğŸ”¹ (1) ì—°ê´€ëœ ë¹„ë””ì˜¤ ìœ ì‚¬ë„ ê³„ì‚°
        if gt_vid in video_ids:
            gt_vid_index = video_ids.index(gt_vid)  # âœ… ë¬¸ìì—´ ê¸°ë°˜ìœ¼ë¡œ ì¸ë±ìŠ¤ ì°¾ê¸°
            related_video_similarities.append(video_similarities_per_query[i, gt_vid_index].item())

        # ğŸ”¹ (2) ì—°ê´€ë˜ì§€ ì•Šì€ ë¹„ë””ì˜¤ ìœ ì‚¬ë„ ë³‘ë ¬ ì—°ì‚°
        unrelated_indices = [idx for idx, vid in enumerate(video_ids) if vid != gt_vid]  # âœ… ë¬¸ìì—´ ë¹„êµ
        unrelated_video_sims = video_similarities_per_query[i, unrelated_indices]  # âœ… ì—°ê´€ë˜ì§€ ì•Šì€ ë¹„ë””ì˜¤ ì„ íƒ
        
        if unrelated_video_sims.numel() > 0:  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ í‰ê·  ê³„ì‚°
            unrelated_video_similarities.append(torch.mean(unrelated_video_sims).item())

# âœ… ì „ì²´ í†µê³„ ì¶œë ¥
print("\nâœ… Similarity Distribution Summary:")
print(f"ğŸ“Š Mean similarity for related videos: {np.mean(related_video_similarities):.4f}")
print(f"ğŸ“Š Mean similarity for unrelated videos: {np.mean(unrelated_video_similarities):.4f}")
print(f"ğŸ“‰ Min similarity for related videos: {np.min(related_video_similarities):.4f}")
print(f"ğŸ“‰ Min similarity for unrelated videos: {np.min(unrelated_video_similarities):.4f}")
print(f"ğŸ“ˆ Max similarity for related videos: {np.max(related_video_similarities):.4f}")
print(f"ğŸ“ˆ Max similarity for unrelated videos: {np.max(unrelated_video_similarities):.4f}")

# âœ… íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.hist(related_video_similarities, bins=50, alpha=0.7, label="Related Videos", color="blue", edgecolor="black")
plt.hist(unrelated_video_similarities, bins=50, alpha=0.7, label="Unrelated Videos", color="red", edgecolor="black")
plt.xlabel("Cosine Similarity")
plt.ylabel("Frequency")
plt.legend()
plt.title("Distribution of Query-Video Similarities")
plt.savefig("query_video_similarity_distribution.png")

# âœ… JSON íŒŒì¼ ì €ì¥
results = {
    "related_video_similarities": related_video_similarities,
    "unrelated_video_similarities": unrelated_video_similarities,
}
with open("query_video_similarity_distribution.json", "w") as f:
    json.dump(results, f, indent=4)

print("\nâœ… Results saved to query_video_similarity_distribution.json and query_video_similarity_distribution.png")

