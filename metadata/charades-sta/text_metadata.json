{
    "3MSZA_0": {
        "text": "person turn a light on.",
        "vid": "3MSZA",
        "timestamps": [
            24.3,
            30.4
        ]
    },
    "3MSZA_1": {
        "text": "person flipped the light switch near the door.",
        "vid": "3MSZA",
        "timestamps": [
            24.3,
            30.4
        ]
    },
    "3MSZA_2": {
        "text": "person turn the light switch on.",
        "vid": "3MSZA",
        "timestamps": [
            24.3,
            30.4
        ]
    },
    "3MSZA_3": {
        "text": "person is playing with the switch for the light.",
        "vid": "3MSZA",
        "timestamps": [
            24.3,
            30.4
        ]
    },
    "AMT7R_0": {
        "text": "a person is putting a picture onto the wall.",
        "vid": "AMT7R",
        "timestamps": [
            4.3,
            12.5
        ]
    },
    "YVKIV_0": {
        "text": "the person puts down the bag.",
        "vid": "YVKIV",
        "timestamps": [
            4.4,
            9.2
        ]
    },
    "VXJS4_0": {
        "text": "a person walks through the doorway.",
        "vid": "VXJS4",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "VXJS4_1": {
        "text": "a person opens the door.",
        "vid": "VXJS4",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "GBD1Y_0": {
        "text": "person closes the door.",
        "vid": "GBD1Y",
        "timestamps": [
            26.2,
            31.3
        ]
    },
    "GBD1Y_1": {
        "text": "person closing the door.",
        "vid": "GBD1Y",
        "timestamps": [
            26.2,
            31.3
        ]
    },
    "KVXJ9_0": {
        "text": "person runs up the stairs.",
        "vid": "KVXJ9",
        "timestamps": [
            1.0,
            11.0
        ]
    },
    "KVXJ9_1": {
        "text": "a person watches another run up some stairs.",
        "vid": "KVXJ9",
        "timestamps": [
            1.0,
            11.0
        ]
    },
    "E6DLK_0": {
        "text": "person runs to the window to look out.",
        "vid": "E6DLK",
        "timestamps": [
            9.3,
            14.4
        ]
    },
    "E6DLK_1": {
        "text": "a person sits in a chair.",
        "vid": "E6DLK",
        "timestamps": [
            3.1,
            11.8
        ]
    },
    "E6DLK_2": {
        "text": "person runs to the window.",
        "vid": "E6DLK",
        "timestamps": [
            9.3,
            14.4
        ]
    },
    "E6DLK_3": {
        "text": "person runs to the door.",
        "vid": "E6DLK",
        "timestamps": [
            9.3,
            14.4
        ]
    },
    "E6DLK_4": {
        "text": "a person sits on a chair.",
        "vid": "E6DLK",
        "timestamps": [
            3.1,
            11.8
        ]
    },
    "E6DLK_5": {
        "text": "the person sits in the chair momentarily.",
        "vid": "E6DLK",
        "timestamps": [
            3.1,
            11.8
        ]
    },
    "AKO6M_0": {
        "text": "a person stands in the bathroom holding a glass.",
        "vid": "AKO6M",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "AKO6M_1": {
        "text": "the person takes a bag from the bottom cabinet.",
        "vid": "AKO6M",
        "timestamps": [
            12.7,
            19.9
        ]
    },
    "F7TG5_0": {
        "text": "person sits in a chair.",
        "vid": "F7TG5",
        "timestamps": [
            13.2,
            20.8
        ]
    },
    "F7TG5_1": {
        "text": "person sits down on a chair.",
        "vid": "F7TG5",
        "timestamps": [
            13.2,
            20.8
        ]
    },
    "F7TG5_2": {
        "text": "person throwing a blanket onto the vacuum.",
        "vid": "F7TG5",
        "timestamps": [
            10.7,
            16.5
        ]
    },
    "F7TG5_3": {
        "text": "person they throw their clothes on to a nearby desk.",
        "vid": "F7TG5",
        "timestamps": [
            6.9,
            13.1
        ]
    },
    "KOVTR_0": {
        "text": "person they stand up.",
        "vid": "KOVTR",
        "timestamps": [
            10.2,
            19.8
        ]
    },
    "KOVTR_1": {
        "text": "a person awakens in their sofa.",
        "vid": "KOVTR",
        "timestamps": [
            4.2,
            14.2
        ]
    },
    "KOVTR_2": {
        "text": "person takes some medicine.",
        "vid": "KOVTR",
        "timestamps": [
            28.4,
            35.0
        ]
    },
    "FPJ9D_0": {
        "text": "person sit on a chair.",
        "vid": "FPJ9D",
        "timestamps": [
            25.8,
            34.0
        ]
    },
    "5NV2Z_0": {
        "text": "person takes a cup off a desk.",
        "vid": "5NV2Z",
        "timestamps": [
            5.1,
            10.2
        ]
    },
    "5NV2Z_1": {
        "text": "person opens the front door.",
        "vid": "5NV2Z",
        "timestamps": [
            13.2,
            23.0
        ]
    },
    "5NV2Z_2": {
        "text": "the person opens a door leading outside.",
        "vid": "5NV2Z",
        "timestamps": [
            13.2,
            23.0
        ]
    },
    "5NV2Z_3": {
        "text": "a person takes a cup from a table.",
        "vid": "5NV2Z",
        "timestamps": [
            5.1,
            10.2
        ]
    },
    "Y1HGC_0": {
        "text": "a person walks in a doorway drinking some coffee.",
        "vid": "Y1HGC",
        "timestamps": [
            0.2,
            9.8
        ]
    },
    "Y1HGC_1": {
        "text": "person drinking a glass of water.",
        "vid": "Y1HGC",
        "timestamps": [
            1.7,
            12.1
        ]
    },
    "9JZO2_0": {
        "text": "person put on their shoes.",
        "vid": "9JZO2",
        "timestamps": [
            26.1,
            36.0
        ]
    },
    "9JZO2_1": {
        "text": "person holding a glass cup.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            9.9
        ]
    },
    "9JZO2_2": {
        "text": "a person eats some food.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "9JZO2_3": {
        "text": "a person is in a entryway eating a sandwich.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            15.1
        ]
    },
    "9JZO2_4": {
        "text": "person holding a glass of water.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            9.9
        ]
    },
    "9JZO2_5": {
        "text": "the person puts the cup down.",
        "vid": "9JZO2",
        "timestamps": [
            14.1,
            20.3
        ]
    },
    "9JZO2_6": {
        "text": "person stands in doorway holding a glass.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            9.9
        ]
    },
    "9JZO2_7": {
        "text": "person eating a sandwich.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            15.1
        ]
    },
    "9JZO2_8": {
        "text": "person puts on some shoes.",
        "vid": "9JZO2",
        "timestamps": [
            26.1,
            36.0
        ]
    },
    "9JZO2_9": {
        "text": "person holding a cup in the doorway.",
        "vid": "9JZO2",
        "timestamps": [
            0.0,
            9.9
        ]
    },
    "9JZO2_10": {
        "text": "the person walks into the house puts down the food.",
        "vid": "9JZO2",
        "timestamps": [
            11.6,
            20.8
        ]
    },
    "9JZO2_11": {
        "text": "person start smiling as the dress.",
        "vid": "9JZO2",
        "timestamps": [
            22.9,
            29.8
        ]
    },
    "4J1AP_0": {
        "text": "person drinking a glass of water.",
        "vid": "4J1AP",
        "timestamps": [
            13.1,
            21.5
        ]
    },
    "4J1AP_1": {
        "text": "lastly the person takes a drink from a cup.",
        "vid": "4J1AP",
        "timestamps": [
            9.8,
            15.7
        ]
    },
    "V1WN7_0": {
        "text": "person sitting on bed.",
        "vid": "V1WN7",
        "timestamps": [
            0.0,
            15.9
        ]
    },
    "V1WN7_1": {
        "text": "a person is dressing.",
        "vid": "V1WN7",
        "timestamps": [
            0.0,
            14.4
        ]
    },
    "V1WN7_2": {
        "text": "person sitting on their bed.",
        "vid": "V1WN7",
        "timestamps": [
            0.0,
            15.9
        ]
    },
    "BL7OF_0": {
        "text": "a person throws a pair of shoes under the window.",
        "vid": "BL7OF",
        "timestamps": [
            1.0,
            5.0
        ]
    },
    "BL7OF_1": {
        "text": "the person throws shoes under the window.",
        "vid": "BL7OF",
        "timestamps": [
            1.0,
            5.0
        ]
    },
    "5C4EK_0": {
        "text": "a person reads a book.",
        "vid": "5C4EK",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "S591U_0": {
        "text": "person sitting on top of bed closes laptop.",
        "vid": "S591U",
        "timestamps": [
            9.4,
            17.0
        ]
    },
    "DLFPX_0": {
        "text": "a person is standing on their stairs holding a bag.",
        "vid": "DLFPX",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "9HG4Z_0": {
        "text": "a person is closing a door.",
        "vid": "9HG4Z",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "I7AS7_0": {
        "text": "a person runs through a doorway.",
        "vid": "I7AS7",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "I7AS7_1": {
        "text": "a person runs into the dining room.",
        "vid": "I7AS7",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "I7AS7_2": {
        "text": "the person opens the bag.",
        "vid": "I7AS7",
        "timestamps": [
            0.5,
            6.4
        ]
    },
    "J48N6_0": {
        "text": "the same person was laughing as he was undressing.",
        "vid": "J48N6",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "J48N6_1": {
        "text": "person begins to undress.",
        "vid": "J48N6",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "J48N6_2": {
        "text": "the person was putting the bag into the cabinet.",
        "vid": "J48N6",
        "timestamps": [
            14.6,
            21.2
        ]
    },
    "JVLAZ_0": {
        "text": "person laying on the bed sneezing.",
        "vid": "JVLAZ",
        "timestamps": [
            9.3,
            18.0
        ]
    },
    "JVLAZ_1": {
        "text": "person is lying on bed sneezing.",
        "vid": "JVLAZ",
        "timestamps": [
            9.3,
            18.0
        ]
    },
    "JVLAZ_2": {
        "text": "person drinks water from a cup.",
        "vid": "JVLAZ",
        "timestamps": [
            19.4,
            29.5
        ]
    },
    "2RFLZ_0": {
        "text": "a person picks up their phone talks on it.",
        "vid": "2RFLZ",
        "timestamps": [
            3.0,
            10.4
        ]
    },
    "2RFLZ_1": {
        "text": "person takes a phone off a desk.",
        "vid": "2RFLZ",
        "timestamps": [
            2.4,
            6.9
        ]
    },
    "N3U9S_0": {
        "text": "person opens a cabinet door twice.",
        "vid": "N3U9S",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "J9T5D_0": {
        "text": "person start laughing.",
        "vid": "J9T5D",
        "timestamps": [
            27.1,
            35.0
        ]
    },
    "1CYLM_0": {
        "text": "a person sits down on a couch.",
        "vid": "1CYLM",
        "timestamps": [
            0.0,
            14.2
        ]
    },
    "1CYLM_1": {
        "text": "the person is drinking something from a cup.",
        "vid": "1CYLM",
        "timestamps": [
            0.0,
            14.0
        ]
    },
    "V2GC9_0": {
        "text": "person putting groceries away.",
        "vid": "V2GC9",
        "timestamps": [
            10.1,
            24.2
        ]
    },
    "V2GC9_1": {
        "text": "person opening a pantry door.",
        "vid": "V2GC9",
        "timestamps": [
            11.3,
            21.1
        ]
    },
    "V2GC9_2": {
        "text": "a person walks through the house holding a bag.",
        "vid": "V2GC9",
        "timestamps": [
            2.3,
            13.9
        ]
    },
    "V2GC9_3": {
        "text": "person put groceries away.",
        "vid": "V2GC9",
        "timestamps": [
            10.1,
            24.2
        ]
    },
    "LGJAR_0": {
        "text": "person turns on the light.",
        "vid": "LGJAR",
        "timestamps": [
            17.6,
            25.2
        ]
    },
    "ZHRPD_0": {
        "text": "the person puts the towel onto the shelf.",
        "vid": "ZHRPD",
        "timestamps": [
            11.8,
            19.6
        ]
    },
    "ZHRPD_1": {
        "text": "the person takes a phone.",
        "vid": "ZHRPD",
        "timestamps": [
            15.6,
            21.6
        ]
    },
    "43CCM_0": {
        "text": "person undressing by the shelf beside the doorway.",
        "vid": "43CCM",
        "timestamps": [
            7.7,
            22.0
        ]
    },
    "43CCM_1": {
        "text": "a person opens a door.",
        "vid": "43CCM",
        "timestamps": [
            0.1,
            9.0
        ]
    },
    "YZ8HK_0": {
        "text": "the person closes the laptop.",
        "vid": "YZ8HK",
        "timestamps": [
            1.4,
            8.7
        ]
    },
    "2P7A9_0": {
        "text": "person take a picture from the top of a cabinet.",
        "vid": "2P7A9",
        "timestamps": [
            20.4,
            27.6
        ]
    },
    "2P7A9_1": {
        "text": "person sit down in a chair at a desk.",
        "vid": "2P7A9",
        "timestamps": [
            20.9,
            30.3
        ]
    },
    "2P7A9_2": {
        "text": "person looking at the picture for a second.",
        "vid": "2P7A9",
        "timestamps": [
            26.9,
            31.6
        ]
    },
    "2P7A9_3": {
        "text": "the person puts a picture on their desk.",
        "vid": "2P7A9",
        "timestamps": [
            26.5,
            35.8
        ]
    },
    "2P7A9_4": {
        "text": "person they put down the broom.",
        "vid": "2P7A9",
        "timestamps": [
            18.8,
            24.0
        ]
    },
    "2P7A9_5": {
        "text": "person put the picture on the desk.",
        "vid": "2P7A9",
        "timestamps": [
            26.5,
            35.8
        ]
    },
    "1ZWPP_0": {
        "text": "a person is smiling in the mirror of their bathroom.",
        "vid": "1ZWPP",
        "timestamps": [
            2.6,
            7.7
        ]
    },
    "1ZWPP_1": {
        "text": "person opens the door.",
        "vid": "1ZWPP",
        "timestamps": [
            13.0,
            19.4
        ]
    },
    "1ZWPP_2": {
        "text": "person they open the door.",
        "vid": "1ZWPP",
        "timestamps": [
            13.0,
            19.4
        ]
    },
    "QUXYH_0": {
        "text": "person laughs in the kitchen.",
        "vid": "QUXYH",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "QUXYH_1": {
        "text": "person seems to be laughing into the blanket.",
        "vid": "QUXYH",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "QUXYH_2": {
        "text": "person eats one.",
        "vid": "QUXYH",
        "timestamps": [
            21.8,
            31.2
        ]
    },
    "QUXYH_3": {
        "text": "person takes some food.",
        "vid": "QUXYH",
        "timestamps": [
            15.1,
            22.9
        ]
    },
    "QUXYH_4": {
        "text": "a person snuggles with a blanket.",
        "vid": "QUXYH",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "QUXYH_5": {
        "text": "person eats it.",
        "vid": "QUXYH",
        "timestamps": [
            21.8,
            31.2
        ]
    },
    "V3SOF_0": {
        "text": "person opened up the refrigerator.",
        "vid": "V3SOF",
        "timestamps": [
            20.0,
            28.2
        ]
    },
    "SY5QP_0": {
        "text": "a person is standing in the room holding a sandwich.",
        "vid": "SY5QP",
        "timestamps": [
            0.0,
            14.0
        ]
    },
    "SY5QP_1": {
        "text": "the person puts the sandwich down.",
        "vid": "SY5QP",
        "timestamps": [
            11.2,
            17.7
        ]
    },
    "AOK1L_0": {
        "text": "person drinking from a cup.",
        "vid": "AOK1L",
        "timestamps": [
            30.5,
            36.0
        ]
    },
    "AOK1L_1": {
        "text": "person drinking from a glass.",
        "vid": "AOK1L",
        "timestamps": [
            30.5,
            36.0
        ]
    },
    "NBSPH_0": {
        "text": "person sits on the table.",
        "vid": "NBSPH",
        "timestamps": [
            26.8,
            32.0
        ]
    },
    "NBSPH_1": {
        "text": "person takes a towel from a container.",
        "vid": "NBSPH",
        "timestamps": [
            11.7,
            17.8
        ]
    },
    "NBSPH_2": {
        "text": "person takes out a towel.",
        "vid": "NBSPH",
        "timestamps": [
            11.7,
            17.8
        ]
    },
    "HY4FS_0": {
        "text": "person the open the cabinet.",
        "vid": "HY4FS",
        "timestamps": [
            4.9,
            11.6
        ]
    },
    "HY4FS_1": {
        "text": "a person walks into a bathroom holding dishes.",
        "vid": "HY4FS",
        "timestamps": [
            0.4,
            9.2
        ]
    },
    "YSE1G_0": {
        "text": "person closed the door.",
        "vid": "YSE1G",
        "timestamps": [
            0.6,
            8.9
        ]
    },
    "XMYXI_0": {
        "text": "a person sits in a chair.",
        "vid": "XMYXI",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "XMYXI_1": {
        "text": "person he begins to laugh at something.",
        "vid": "XMYXI",
        "timestamps": [
            10.1,
            15.5
        ]
    },
    "XMYXI_2": {
        "text": "a man is sitting at a chair.",
        "vid": "XMYXI",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "XMYXI_3": {
        "text": "a person is smiling.",
        "vid": "XMYXI",
        "timestamps": [
            0.0,
            15.9
        ]
    },
    "QLEN3_0": {
        "text": "person open the closet.",
        "vid": "QLEN3",
        "timestamps": [
            14.0,
            19.0
        ]
    },
    "YSKX3_0": {
        "text": "person throws pillow on it.",
        "vid": "YSKX3",
        "timestamps": [
            13.0,
            18.0
        ]
    },
    "HBWLV_0": {
        "text": "person puts the shoes on the floor.",
        "vid": "HBWLV",
        "timestamps": [
            9.4,
            14.3
        ]
    },
    "XE19C_0": {
        "text": "person puts a cup in the sink.",
        "vid": "XE19C",
        "timestamps": [
            0.9,
            8.5
        ]
    },
    "XE19C_1": {
        "text": "person closes the door.",
        "vid": "XE19C",
        "timestamps": [
            24.6,
            31.0
        ]
    },
    "XE19C_2": {
        "text": "person puts the cup in the sink.",
        "vid": "XE19C",
        "timestamps": [
            0.9,
            8.5
        ]
    },
    "W3SC3_0": {
        "text": "the person immediately opened a window.",
        "vid": "W3SC3",
        "timestamps": [
            8.0,
            15.2
        ]
    },
    "W3SC3_1": {
        "text": "person opens a window.",
        "vid": "W3SC3",
        "timestamps": [
            8.0,
            15.2
        ]
    },
    "W3SC3_2": {
        "text": "person opens the window.",
        "vid": "W3SC3",
        "timestamps": [
            8.0,
            15.2
        ]
    },
    "WKPQ3_0": {
        "text": "person they talk on the phone.",
        "vid": "WKPQ3",
        "timestamps": [
            15.8,
            28.7
        ]
    },
    "WKPQ3_1": {
        "text": "person close the closet door.",
        "vid": "WKPQ3",
        "timestamps": [
            25.3,
            30.9
        ]
    },
    "WKPQ3_2": {
        "text": "person turns on the light.",
        "vid": "WKPQ3",
        "timestamps": [
            5.1,
            11.0
        ]
    },
    "FXZI5_0": {
        "text": "a person is dressing in a towel.",
        "vid": "FXZI5",
        "timestamps": [
            3.0,
            12.4
        ]
    },
    "OE2M1_0": {
        "text": "another person comes in takes the box away.",
        "vid": "OE2M1",
        "timestamps": [
            12.9,
            19.3
        ]
    },
    "OE2M1_1": {
        "text": "person takes the tray of food.",
        "vid": "OE2M1",
        "timestamps": [
            12.9,
            18.7
        ]
    },
    "OE2M1_2": {
        "text": "person takes the box.",
        "vid": "OE2M1",
        "timestamps": [
            12.9,
            19.3
        ]
    },
    "ZF7YA_0": {
        "text": "the person sits on a pillow on the floor.",
        "vid": "ZF7YA",
        "timestamps": [
            5.3,
            11.7
        ]
    },
    "ZF7YA_1": {
        "text": "a person runs down a few stairs.",
        "vid": "ZF7YA",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "ZF7YA_2": {
        "text": "person sitting on the floor.",
        "vid": "ZF7YA",
        "timestamps": [
            5.3,
            11.7
        ]
    },
    "B82GJ_0": {
        "text": "the person takes a paper towel from the table.",
        "vid": "B82GJ",
        "timestamps": [
            17.7,
            22.5
        ]
    },
    "FYYFX_0": {
        "text": "person opens a window.",
        "vid": "FYYFX",
        "timestamps": [
            2.0,
            11.2
        ]
    },
    "FYYFX_1": {
        "text": "person takes a camera from a table.",
        "vid": "FYYFX",
        "timestamps": [
            8.6,
            14.1
        ]
    },
    "FYYFX_2": {
        "text": "person get something to look out the window with.",
        "vid": "FYYFX",
        "timestamps": [
            14.0,
            24.7
        ]
    },
    "FYYFX_3": {
        "text": "person upon awakening.",
        "vid": "FYYFX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "FYYFX_4": {
        "text": "person looks out the window.",
        "vid": "FYYFX",
        "timestamps": [
            14.0,
            24.7
        ]
    },
    "Q7IQI_0": {
        "text": "person looks at some books open it.",
        "vid": "Q7IQI",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "Q7IQI_1": {
        "text": "person start sneezing with looking at the papers.",
        "vid": "Q7IQI",
        "timestamps": [
            1.8,
            8.6
        ]
    },
    "Q7IQI_2": {
        "text": "a person is sneezing into a blanket.",
        "vid": "Q7IQI",
        "timestamps": [
            1.8,
            8.6
        ]
    },
    "HSEH1_0": {
        "text": "person is fixing a light bulb.",
        "vid": "HSEH1",
        "timestamps": [
            10.0,
            22.6
        ]
    },
    "HSEH1_1": {
        "text": "a person is fixing a light on the room.",
        "vid": "HSEH1",
        "timestamps": [
            10.0,
            22.6
        ]
    },
    "HSEH1_2": {
        "text": "a person is fixing a light.",
        "vid": "HSEH1",
        "timestamps": [
            10.0,
            22.6
        ]
    },
    "6ZWSU_0": {
        "text": "person puts the books down.",
        "vid": "6ZWSU",
        "timestamps": [
            1.4,
            7.2
        ]
    },
    "6ZWSU_1": {
        "text": "person they immediately put their books down.",
        "vid": "6ZWSU",
        "timestamps": [
            1.4,
            7.2
        ]
    },
    "6ZWSU_2": {
        "text": "the person takes their phone out.",
        "vid": "6ZWSU",
        "timestamps": [
            16.2,
            21.8
        ]
    },
    "6ZWSU_3": {
        "text": "person take their shoes off.",
        "vid": "6ZWSU",
        "timestamps": [
            10.6,
            19.3
        ]
    },
    "6ZWSU_4": {
        "text": "person closes the door.",
        "vid": "6ZWSU",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "6ZWSU_5": {
        "text": "the person takes their phone.",
        "vid": "6ZWSU",
        "timestamps": [
            16.2,
            21.8
        ]
    },
    "6ZWSU_6": {
        "text": "person plays with their phone.",
        "vid": "6ZWSU",
        "timestamps": [
            19.1,
            32.0
        ]
    },
    "V0ZD9_0": {
        "text": "person washes a cup.",
        "vid": "V0ZD9",
        "timestamps": [
            0.5,
            16.0
        ]
    },
    "V0ZD9_1": {
        "text": "person putting on clothes in a dining room.",
        "vid": "V0ZD9",
        "timestamps": [
            23.2,
            39.0
        ]
    },
    "AK2KG_0": {
        "text": "person opens up the window.",
        "vid": "AK2KG",
        "timestamps": [
            12.5,
            19.0
        ]
    },
    "AK2KG_1": {
        "text": "a person is sitting on a bed.",
        "vid": "AK2KG",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "AK2KG_2": {
        "text": "this person is sitting on their bed in the bedroom.",
        "vid": "AK2KG",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "AK2KG_3": {
        "text": "person begins opening the window.",
        "vid": "AK2KG",
        "timestamps": [
            12.5,
            19.0
        ]
    },
    "AK2KG_4": {
        "text": "person opened the window.",
        "vid": "AK2KG",
        "timestamps": [
            12.5,
            19.0
        ]
    },
    "AK2KG_5": {
        "text": "a person was sitting on a bed.",
        "vid": "AK2KG",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "8MQH6_0": {
        "text": "a person opens a closet door.",
        "vid": "8MQH6",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "8MQH6_1": {
        "text": "a person opens up the closet.",
        "vid": "8MQH6",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "8MQH6_2": {
        "text": "a person opens a closet.",
        "vid": "8MQH6",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "8MQH6_3": {
        "text": "person they hold the shoes.",
        "vid": "8MQH6",
        "timestamps": [
            9.9,
            15.8
        ]
    },
    "MAUMO_0": {
        "text": "person takes a drink from a glass.",
        "vid": "MAUMO",
        "timestamps": [
            0.0,
            9.6
        ]
    },
    "EHS68_0": {
        "text": "another person is throwing a pair of shoes.",
        "vid": "EHS68",
        "timestamps": [
            1.1,
            6.4
        ]
    },
    "G30NS_0": {
        "text": "person puts it into a box.",
        "vid": "G30NS",
        "timestamps": [
            2.5,
            10.6
        ]
    },
    "G30NS_1": {
        "text": "person puts the box down.",
        "vid": "G30NS",
        "timestamps": [
            2.5,
            10.6
        ]
    },
    "G30NS_2": {
        "text": "person putting things on a shelf.",
        "vid": "G30NS",
        "timestamps": [
            0.4,
            7.6
        ]
    },
    "G30NS_3": {
        "text": "the person takes a large blanket.",
        "vid": "G30NS",
        "timestamps": [
            7.0,
            14.0
        ]
    },
    "SUJWY_0": {
        "text": "the person laughs at something on the screen multiple times.",
        "vid": "SUJWY",
        "timestamps": [
            17.1,
            29.7
        ]
    },
    "SUJWY_1": {
        "text": "the person begins laughing at something on the screen.",
        "vid": "SUJWY",
        "timestamps": [
            17.1,
            29.7
        ]
    },
    "KERO6_0": {
        "text": "the person puts some food onto a pan.",
        "vid": "KERO6",
        "timestamps": [
            11.4,
            16.9
        ]
    },
    "SV6KF_0": {
        "text": "a person throws a broom at the stairs.",
        "vid": "SV6KF",
        "timestamps": [
            9.3,
            14.5
        ]
    },
    "SV6KF_1": {
        "text": "this person throws the broom down.",
        "vid": "SV6KF",
        "timestamps": [
            9.3,
            14.5
        ]
    },
    "VCYH8_0": {
        "text": "person turns off the light as they're leaving.",
        "vid": "VCYH8",
        "timestamps": [
            18.2,
            23.8
        ]
    },
    "VCYH8_1": {
        "text": "person turns off a light.",
        "vid": "VCYH8",
        "timestamps": [
            18.2,
            23.8
        ]
    },
    "G852Y_0": {
        "text": "one person is wrapped in a blanket sneezing.",
        "vid": "G852Y",
        "timestamps": [
            3.0,
            10.1
        ]
    },
    "OKXIQ_0": {
        "text": "person they use the doorknob to open the cabinet.",
        "vid": "OKXIQ",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "KB7WQ_0": {
        "text": "person they close the box.",
        "vid": "KB7WQ",
        "timestamps": [
            7.3,
            14.0
        ]
    },
    "KB7WQ_1": {
        "text": "the person closes a box that's been searched through.",
        "vid": "KB7WQ",
        "timestamps": [
            7.3,
            14.0
        ]
    },
    "27DCQ_0": {
        "text": "a person awakens in bed.",
        "vid": "27DCQ",
        "timestamps": [
            13.5,
            19.2
        ]
    },
    "UM5II_0": {
        "text": "the person eats a few bite.",
        "vid": "UM5II",
        "timestamps": [
            3.7,
            14.0
        ]
    },
    "UM5II_1": {
        "text": "a person is sneezing on the medicine.",
        "vid": "UM5II",
        "timestamps": [
            0.9,
            7.7
        ]
    },
    "UM5II_2": {
        "text": "person starts sneezing.",
        "vid": "UM5II",
        "timestamps": [
            0.9,
            7.7
        ]
    },
    "UM5II_3": {
        "text": "a person is sneezing.",
        "vid": "UM5II",
        "timestamps": [
            0.9,
            7.7
        ]
    },
    "XT9D4_0": {
        "text": "a person is putting food into the refrigerator.",
        "vid": "XT9D4",
        "timestamps": [
            18.3,
            25.3
        ]
    },
    "XT9D4_1": {
        "text": "a person is putting away groceries in the fridge.",
        "vid": "XT9D4",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "XT9D4_2": {
        "text": "person their phone rings so they close the fridge door.",
        "vid": "XT9D4",
        "timestamps": [
            25.5,
            30.6
        ]
    },
    "XT9D4_3": {
        "text": "person closed the refrigerator door.",
        "vid": "XT9D4",
        "timestamps": [
            25.5,
            30.6
        ]
    },
    "1W6YY_0": {
        "text": "person closes the cabinet door.",
        "vid": "1W6YY",
        "timestamps": [
            3.5,
            7.9
        ]
    },
    "YOCRB_0": {
        "text": "person sit down in a chair.",
        "vid": "YOCRB",
        "timestamps": [
            26.4,
            36.0
        ]
    },
    "YOCRB_1": {
        "text": "person sitting in a chair.",
        "vid": "YOCRB",
        "timestamps": [
            26.4,
            36.0
        ]
    },
    "ZDV60_0": {
        "text": "a person opens a closet door.",
        "vid": "ZDV60",
        "timestamps": [
            0.3,
            9.2
        ]
    },
    "ZDV60_1": {
        "text": "person start dressing themselves.",
        "vid": "ZDV60",
        "timestamps": [
            10.6,
            20.7
        ]
    },
    "ZDV60_2": {
        "text": "person opens the door.",
        "vid": "ZDV60",
        "timestamps": [
            1.5,
            10.3
        ]
    },
    "ZDV60_3": {
        "text": "the person puts shoes on.",
        "vid": "ZDV60",
        "timestamps": [
            25.4,
            32.0
        ]
    },
    "GHC5X_0": {
        "text": "a person takes a glass of water.",
        "vid": "GHC5X",
        "timestamps": [
            22.2,
            27.8
        ]
    },
    "6IOV0_0": {
        "text": "person working on a laptop.",
        "vid": "6IOV0",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "6IOV0_1": {
        "text": "person playing a casual game on their laptop.",
        "vid": "6IOV0",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "6IOV0_2": {
        "text": "person drinking a bottle of soda.",
        "vid": "6IOV0",
        "timestamps": [
            9.5,
            16.4
        ]
    },
    "OP2SS_0": {
        "text": "the person takes out their laptop.",
        "vid": "OP2SS",
        "timestamps": [
            20.4,
            26.7
        ]
    },
    "PPY0W_0": {
        "text": "a person is holding a bag.",
        "vid": "PPY0W",
        "timestamps": [
            0.0,
            7.8
        ]
    },
    "DCV2M_0": {
        "text": "person start undressing.",
        "vid": "DCV2M",
        "timestamps": [
            25.4,
            32.0
        ]
    },
    "DCV2M_1": {
        "text": "a person is awakening.",
        "vid": "DCV2M",
        "timestamps": [
            3.0,
            13.6
        ]
    },
    "TEV5K_0": {
        "text": "person begings to drink a glass of water.",
        "vid": "TEV5K",
        "timestamps": [
            7.1,
            16.2
        ]
    },
    "TEV5K_1": {
        "text": "a person opens their kitchen window.",
        "vid": "TEV5K",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "TEV5K_2": {
        "text": "a person opens the window.",
        "vid": "TEV5K",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "Q3BCC_0": {
        "text": "a person closes a door.",
        "vid": "Q3BCC",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "Q3BCC_1": {
        "text": "person trying to close the door.",
        "vid": "Q3BCC",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "M8OYC_0": {
        "text": "a person walks in holding a bag of groceries.",
        "vid": "M8OYC",
        "timestamps": [
            1.7,
            11.5
        ]
    },
    "FBOF0_0": {
        "text": "a person awakens in bed.",
        "vid": "FBOF0",
        "timestamps": [
            9.2,
            22.2
        ]
    },
    "FBOF0_1": {
        "text": "the person throws the blanket off of the bed.",
        "vid": "FBOF0",
        "timestamps": [
            26.8,
            32.1
        ]
    },
    "D1NT7_0": {
        "text": "a person is putting some dishes into a box.",
        "vid": "D1NT7",
        "timestamps": [
            10.8,
            18.6
        ]
    },
    "D1NT7_1": {
        "text": "person they put the box on a bed.",
        "vid": "D1NT7",
        "timestamps": [
            10.8,
            18.6
        ]
    },
    "D1NT7_2": {
        "text": "a person is putting some plates in a box.",
        "vid": "D1NT7",
        "timestamps": [
            10.8,
            18.6
        ]
    },
    "3UACJ_0": {
        "text": "person takes a drink from a glass.",
        "vid": "3UACJ",
        "timestamps": [
            1.8,
            6.4
        ]
    },
    "U2AO1_0": {
        "text": "closes the doors.the person takes the food.",
        "vid": "U2AO1",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "U2AO1_1": {
        "text": "person starts eating.",
        "vid": "U2AO1",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "U2AO1_2": {
        "text": "a person closed a cabinet.",
        "vid": "U2AO1",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "U2AO1_3": {
        "text": "person looks for something to eat.",
        "vid": "U2AO1",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "U2AO1_4": {
        "text": "the person eats it.",
        "vid": "U2AO1",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "U2AO1_5": {
        "text": "person a opens the door bites into a snack.",
        "vid": "U2AO1",
        "timestamps": [
            4.1,
            9.7
        ]
    },
    "3J9L5_0": {
        "text": "a person is eating.",
        "vid": "3J9L5",
        "timestamps": [
            1.0,
            6.6
        ]
    },
    "3J9L5_1": {
        "text": "a person is throwing the bag at the light switch.",
        "vid": "3J9L5",
        "timestamps": [
            2.8,
            9.0
        ]
    },
    "XQVXF_0": {
        "text": "person opens a fridge door.",
        "vid": "XQVXF",
        "timestamps": [
            4.5,
            11.1
        ]
    },
    "XQVXF_1": {
        "text": "another person opens an oven door to look inside.",
        "vid": "XQVXF",
        "timestamps": [
            4.5,
            11.1
        ]
    },
    "XQVXF_2": {
        "text": "one person is cooking.",
        "vid": "XQVXF",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "9LWQ6_0": {
        "text": "a person undresses.",
        "vid": "9LWQ6",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "9LWQ6_1": {
        "text": "person takes their shoes off.",
        "vid": "9LWQ6",
        "timestamps": [
            11.0,
            21.0
        ]
    },
    "9LWQ6_2": {
        "text": "person takes off their shoes.",
        "vid": "9LWQ6",
        "timestamps": [
            11.0,
            21.0
        ]
    },
    "9LWQ6_3": {
        "text": "person puts the clothes on the bed.",
        "vid": "9LWQ6",
        "timestamps": [
            1.1,
            10.0
        ]
    },
    "2ADJI_0": {
        "text": "person putting away groceries.",
        "vid": "2ADJI",
        "timestamps": [
            10.0,
            21.9
        ]
    },
    "2ADJI_1": {
        "text": "person drinking from a glass of water.",
        "vid": "2ADJI",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "B1AMA_0": {
        "text": "person dresses in pajamas.",
        "vid": "B1AMA",
        "timestamps": [
            21.0,
            35.7
        ]
    },
    "LA6AA_0": {
        "text": "a person was holding a blanket.",
        "vid": "LA6AA",
        "timestamps": [
            2.2,
            11.8
        ]
    },
    "LA6AA_1": {
        "text": "a person is holding a blanket.",
        "vid": "LA6AA",
        "timestamps": [
            2.2,
            11.8
        ]
    },
    "YNWMW_0": {
        "text": "the person takes a broom.",
        "vid": "YNWMW",
        "timestamps": [
            9.9,
            15.9
        ]
    },
    "YNWMW_1": {
        "text": "a person eats some food.",
        "vid": "YNWMW",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "YNWMW_2": {
        "text": "a person is in a basement eating.",
        "vid": "YNWMW",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "LUTIO_0": {
        "text": "the person lays on the floor the gets up.",
        "vid": "LUTIO",
        "timestamps": [
            0.0,
            10.4
        ]
    },
    "Q6290_0": {
        "text": "person watching the television eating an apple.",
        "vid": "Q6290",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "Q6290_1": {
        "text": "a person is standing eating something as they watch tv.",
        "vid": "Q6290",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "Q6290_2": {
        "text": "person eating a sandwich out of a dish.",
        "vid": "Q6290",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "TAQ25_0": {
        "text": "the person closes the laptop.",
        "vid": "TAQ25",
        "timestamps": [
            11.6,
            17.7
        ]
    },
    "TAQ25_1": {
        "text": "the person closes the laptop screen.",
        "vid": "TAQ25",
        "timestamps": [
            11.6,
            17.7
        ]
    },
    "TAQ25_2": {
        "text": "person smiling at their laptop.",
        "vid": "TAQ25",
        "timestamps": [
            4.3,
            16.5
        ]
    },
    "EEVD3_0": {
        "text": "person begins to eat it.",
        "vid": "EEVD3",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "EEVD3_1": {
        "text": "a person is holding the door to the refrigerator open.",
        "vid": "EEVD3",
        "timestamps": [
            2.0,
            7.9
        ]
    },
    "EEVD3_2": {
        "text": "person removes a snack to eat.",
        "vid": "EEVD3",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "EEVD3_3": {
        "text": "person eat the food.",
        "vid": "EEVD3",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "EEVD3_4": {
        "text": "person they begin eating the fruit.",
        "vid": "EEVD3",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "EEVD3_5": {
        "text": "person closing the door.",
        "vid": "EEVD3",
        "timestamps": [
            11.4,
            16.9
        ]
    },
    "IOGR7_0": {
        "text": "person they stand up.",
        "vid": "IOGR7",
        "timestamps": [
            19.7,
            28.3
        ]
    },
    "2OREK_0": {
        "text": "looking out the window in a curious manner.",
        "vid": "2OREK",
        "timestamps": [
            11.5,
            17.6
        ]
    },
    "JCT0K_0": {
        "text": "a person is opening the closet door.",
        "vid": "JCT0K",
        "timestamps": [
            2.6,
            10.2
        ]
    },
    "JCT0K_1": {
        "text": "person opens the closet.",
        "vid": "JCT0K",
        "timestamps": [
            0.1,
            6.2
        ]
    },
    "H0P5D_0": {
        "text": "one person was running into the table.",
        "vid": "H0P5D",
        "timestamps": [
            11.0,
            18.1
        ]
    },
    "H0P5D_1": {
        "text": "person they laugh.",
        "vid": "H0P5D",
        "timestamps": [
            23.7,
            32.0
        ]
    },
    "BFCU9_0": {
        "text": "person eating it.",
        "vid": "BFCU9",
        "timestamps": [
            0.2,
            5.3
        ]
    },
    "BFCU9_1": {
        "text": "a person is eating from a can.",
        "vid": "BFCU9",
        "timestamps": [
            0.2,
            5.3
        ]
    },
    "BFCU9_2": {
        "text": "a person eats something from a jar.",
        "vid": "BFCU9",
        "timestamps": [
            0.2,
            5.3
        ]
    },
    "BFCU9_3": {
        "text": "person puts the jar down on a table.",
        "vid": "BFCU9",
        "timestamps": [
            14.0,
            18.0
        ]
    },
    "BFCU9_4": {
        "text": "person the put the food down.",
        "vid": "BFCU9",
        "timestamps": [
            3.2,
            8.4
        ]
    },
    "BFCU9_5": {
        "text": "person eats it.",
        "vid": "BFCU9",
        "timestamps": [
            0.2,
            5.3
        ]
    },
    "BFCU9_6": {
        "text": "a person is holding some food.",
        "vid": "BFCU9",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "TUD6M_0": {
        "text": "person throws their blanket inside.",
        "vid": "TUD6M",
        "timestamps": [
            4.3,
            8.0
        ]
    },
    "TUD6M_1": {
        "text": "person throwing a blanket into a closet.",
        "vid": "TUD6M",
        "timestamps": [
            4.3,
            8.0
        ]
    },
    "A3XXB_0": {
        "text": "person puts them away on a shelf in a closet.",
        "vid": "A3XXB",
        "timestamps": [
            1.9,
            7.1
        ]
    },
    "A3XXB_1": {
        "text": "a person is tidying a blanket.",
        "vid": "A3XXB",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "L5YHH_0": {
        "text": "a person is turns on the light in their closet.",
        "vid": "L5YHH",
        "timestamps": [
            0.6,
            5.7
        ]
    },
    "L5YHH_1": {
        "text": "person open the door.",
        "vid": "L5YHH",
        "timestamps": [
            18.6,
            31.6
        ]
    },
    "L5YHH_2": {
        "text": "person opens the closet.",
        "vid": "L5YHH",
        "timestamps": [
            17.3,
            35.4
        ]
    },
    "GL2JW_0": {
        "text": "person closes a cupboard door.",
        "vid": "GL2JW",
        "timestamps": [
            14.9,
            21.9
        ]
    },
    "GL2JW_1": {
        "text": "the person closes a cupboard door.",
        "vid": "GL2JW",
        "timestamps": [
            14.9,
            21.9
        ]
    },
    "GL2JW_2": {
        "text": "a person is closing a cabinet.",
        "vid": "GL2JW",
        "timestamps": [
            14.1,
            22.3
        ]
    },
    "FAJEA_0": {
        "text": "person they take some medicine.",
        "vid": "FAJEA",
        "timestamps": [
            14.3,
            23.5
        ]
    },
    "FAJEA_1": {
        "text": "person drink from a cup.",
        "vid": "FAJEA",
        "timestamps": [
            23.4,
            31.0
        ]
    },
    "RXELU_0": {
        "text": "person turns the light on.",
        "vid": "RXELU",
        "timestamps": [
            2.5,
            6.6
        ]
    },
    "RXELU_1": {
        "text": "person turns on the light.",
        "vid": "RXELU",
        "timestamps": [
            2.5,
            6.6
        ]
    },
    "RXELU_2": {
        "text": "person smiling in the mirror.",
        "vid": "RXELU",
        "timestamps": [
            8.9,
            16.0
        ]
    },
    "RXELU_3": {
        "text": "the person drinks from a cup of coffee.",
        "vid": "RXELU",
        "timestamps": [
            3.7,
            9.7
        ]
    },
    "QCVZN_0": {
        "text": "a person takes a book off a shelf.",
        "vid": "QCVZN",
        "timestamps": [
            6.2,
            12.0
        ]
    },
    "5B9XE_0": {
        "text": "person turns off the ceiling light.",
        "vid": "5B9XE",
        "timestamps": [
            18.7,
            29.0
        ]
    },
    "5B9XE_1": {
        "text": "person turns the light off.",
        "vid": "5B9XE",
        "timestamps": [
            18.7,
            29.0
        ]
    },
    "5B9XE_2": {
        "text": "person turns off the light.",
        "vid": "5B9XE",
        "timestamps": [
            18.7,
            29.0
        ]
    },
    "5B9XE_3": {
        "text": "a person runs into a room.",
        "vid": "5B9XE",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "5B9XE_4": {
        "text": "a person runs into the bedroom.",
        "vid": "5B9XE",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "LKNZD_0": {
        "text": "a person is throwing clothes on the floor.",
        "vid": "LKNZD",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "0DVVD_0": {
        "text": "a person closes a window.",
        "vid": "0DVVD",
        "timestamps": [
            2.8,
            14.3
        ]
    },
    "0DVVD_1": {
        "text": "a person is opening a window in the bathroom.",
        "vid": "0DVVD",
        "timestamps": [
            0.1,
            10.3
        ]
    },
    "U8M2P_0": {
        "text": "another person is sneezing on a sandwich.",
        "vid": "U8M2P",
        "timestamps": [
            1.6,
            13.3
        ]
    },
    "VAV4C_0": {
        "text": "person eating a sandwich.",
        "vid": "VAV4C",
        "timestamps": [
            13.8,
            23.5
        ]
    },
    "VAV4C_1": {
        "text": "the person is sitting on a closed toilet eating.",
        "vid": "VAV4C",
        "timestamps": [
            13.8,
            23.5
        ]
    },
    "VAV4C_2": {
        "text": "a person is in a bathroom drinking from a cup.",
        "vid": "VAV4C",
        "timestamps": [
            9.3,
            17.6
        ]
    },
    "VAV4C_3": {
        "text": "person repeats the process until he is finished with both.",
        "vid": "VAV4C",
        "timestamps": [
            13.8,
            23.5
        ]
    },
    "VAV4C_4": {
        "text": "person walk out the doorway.",
        "vid": "VAV4C",
        "timestamps": [
            43.3,
            48.0
        ]
    },
    "6C0BK_0": {
        "text": "a person is putting a towel on a towel rack.",
        "vid": "6C0BK",
        "timestamps": [
            0.3,
            7.8
        ]
    },
    "5CN21_0": {
        "text": "a person is standing in their garage holding a pillow.",
        "vid": "5CN21",
        "timestamps": [
            11.6,
            17.5
        ]
    },
    "5CN21_1": {
        "text": "person holding a pillow.",
        "vid": "5CN21",
        "timestamps": [
            11.6,
            17.5
        ]
    },
    "OTIA2_0": {
        "text": "person turns on a lightswitch.",
        "vid": "OTIA2",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "OTIA2_1": {
        "text": "a person walks through the doorway into the home office.",
        "vid": "OTIA2",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "OTIA2_2": {
        "text": "person turns on the light.",
        "vid": "OTIA2",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "OTIA2_3": {
        "text": "a person is walking to turn on the light.",
        "vid": "OTIA2",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "B4ED1_0": {
        "text": "a person is pouring water into a cup.",
        "vid": "B4ED1",
        "timestamps": [
            23.5,
            32.8
        ]
    },
    "86E2E_0": {
        "text": "the person is sitting on the floor.",
        "vid": "86E2E",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "86E2E_1": {
        "text": "person snuggling with a pillow.",
        "vid": "86E2E",
        "timestamps": [
            2.2,
            8.2
        ]
    },
    "86E2E_2": {
        "text": "person begins to eat from a bowl on the floor.",
        "vid": "86E2E",
        "timestamps": [
            15.3,
            20.8
        ]
    },
    "86E2E_3": {
        "text": "person eats something.",
        "vid": "86E2E",
        "timestamps": [
            15.3,
            20.8
        ]
    },
    "86E2E_4": {
        "text": "person holds a pillow.",
        "vid": "86E2E",
        "timestamps": [
            1.3,
            8.4
        ]
    },
    "86E2E_5": {
        "text": "a person sits on the floor.",
        "vid": "86E2E",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "86E2E_6": {
        "text": "person eating as they are laying down.",
        "vid": "86E2E",
        "timestamps": [
            15.3,
            20.8
        ]
    },
    "86E2E_7": {
        "text": "person eating food in a home office / study.",
        "vid": "86E2E",
        "timestamps": [
            15.3,
            20.8
        ]
    },
    "YJ1KW_0": {
        "text": "person sits down in a chair.",
        "vid": "YJ1KW",
        "timestamps": [
            8.8,
            14.3
        ]
    },
    "YJ1KW_1": {
        "text": "person sits down in a red chair.",
        "vid": "YJ1KW",
        "timestamps": [
            8.8,
            14.3
        ]
    },
    "DJ87X_0": {
        "text": "a person is looking out the window.",
        "vid": "DJ87X",
        "timestamps": [
            0.0,
            9.6
        ]
    },
    "DJ87X_1": {
        "text": "a person looks out the bathroom window.",
        "vid": "DJ87X",
        "timestamps": [
            0.0,
            9.6
        ]
    },
    "DJ87X_2": {
        "text": "person takes their phone out of the cabinet.",
        "vid": "DJ87X",
        "timestamps": [
            19.2,
            26.8
        ]
    },
    "N0ZPI_0": {
        "text": "person take a drink from the cup.",
        "vid": "N0ZPI",
        "timestamps": [
            14.4,
            20.8
        ]
    },
    "N0ZPI_1": {
        "text": "person throw it on the floor.",
        "vid": "N0ZPI",
        "timestamps": [
            21.8,
            26.5
        ]
    },
    "OVD84_0": {
        "text": "a person turns on some lights.",
        "vid": "OVD84",
        "timestamps": [
            4.1,
            10.8
        ]
    },
    "OVD84_1": {
        "text": "person turns on the light.",
        "vid": "OVD84",
        "timestamps": [
            4.1,
            10.8
        ]
    },
    "OVD84_2": {
        "text": "person turns on a light.",
        "vid": "OVD84",
        "timestamps": [
            4.1,
            10.8
        ]
    },
    "NW0KT_0": {
        "text": "person takes book out.",
        "vid": "NW0KT",
        "timestamps": [
            7.9,
            18.8
        ]
    },
    "NW0KT_1": {
        "text": "person takes a book out from the entertainment center.",
        "vid": "NW0KT",
        "timestamps": [
            7.9,
            18.8
        ]
    },
    "NW0KT_2": {
        "text": "a person is tidying some books on a shelf.",
        "vid": "NW0KT",
        "timestamps": [
            43.6,
            50.0
        ]
    },
    "8SDK5_0": {
        "text": "person sits down in a chair.",
        "vid": "8SDK5",
        "timestamps": [
            15.4,
            23.0
        ]
    },
    "8SDK5_1": {
        "text": "person laughing so hard.",
        "vid": "8SDK5",
        "timestamps": [
            5.9,
            16.7
        ]
    },
    "95GB4_0": {
        "text": "person takes a picture with a camera.",
        "vid": "95GB4",
        "timestamps": [
            8.8,
            19.8
        ]
    },
    "95GB4_1": {
        "text": "the person takes a picture of something.",
        "vid": "95GB4",
        "timestamps": [
            8.8,
            19.8
        ]
    },
    "95GB4_2": {
        "text": "the person puts the phone away.",
        "vid": "95GB4",
        "timestamps": [
            5.1,
            13.1
        ]
    },
    "95GB4_3": {
        "text": "person washes their hands with hand sanitizer.",
        "vid": "95GB4",
        "timestamps": [
            18.3,
            31.0
        ]
    },
    "95GB4_4": {
        "text": "person playing with a phone.",
        "vid": "95GB4",
        "timestamps": [
            0.0,
            11.2
        ]
    },
    "95GB4_5": {
        "text": "person takes a picture.",
        "vid": "95GB4",
        "timestamps": [
            8.8,
            19.8
        ]
    },
    "95GB4_6": {
        "text": "person playing with their phone.",
        "vid": "95GB4",
        "timestamps": [
            0.0,
            11.2
        ]
    },
    "TDAY1_0": {
        "text": "person working on a laptop.",
        "vid": "TDAY1",
        "timestamps": [
            0.0,
            16.6
        ]
    },
    "TDAY1_1": {
        "text": "person stand up from the laying position.",
        "vid": "TDAY1",
        "timestamps": [
            23.4,
            35.0
        ]
    },
    "NRGQB_0": {
        "text": "person throws their shoes off by kicking them.",
        "vid": "NRGQB",
        "timestamps": [
            6.1,
            11.6
        ]
    },
    "5R8BL_0": {
        "text": "person begin undressing.",
        "vid": "5R8BL",
        "timestamps": [
            12.1,
            22.0
        ]
    },
    "5R8BL_1": {
        "text": "a person opens their closet door.",
        "vid": "5R8BL",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "5R8BL_2": {
        "text": "person they throw the pillow behind them.",
        "vid": "5R8BL",
        "timestamps": [
            5.7,
            13.1
        ]
    },
    "BI4KK_0": {
        "text": "person drinking from a glass of water.",
        "vid": "BI4KK",
        "timestamps": [
            0.9,
            8.4
        ]
    },
    "DU416_0": {
        "text": "person holding a bag.",
        "vid": "DU416",
        "timestamps": [
            7.9,
            18.0
        ]
    },
    "NO1GJ_0": {
        "text": "person washes clothes.",
        "vid": "NO1GJ",
        "timestamps": [
            15.9,
            25.8
        ]
    },
    "NO1GJ_1": {
        "text": "a person is washing the clothes.",
        "vid": "NO1GJ",
        "timestamps": [
            15.9,
            25.8
        ]
    },
    "NO1GJ_2": {
        "text": "a person is undressing in their laundry room.",
        "vid": "NO1GJ",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "NO1GJ_3": {
        "text": "person they take a towel from a cabinet.",
        "vid": "NO1GJ",
        "timestamps": [
            8.0,
            16.1
        ]
    },
    "NO1GJ_4": {
        "text": "a person is undressing in the laundry room.",
        "vid": "NO1GJ",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "NO1GJ_5": {
        "text": "person their other clothes into the washer.",
        "vid": "NO1GJ",
        "timestamps": [
            15.9,
            25.8
        ]
    },
    "NO1GJ_6": {
        "text": "person talking a towel off the shelf.",
        "vid": "NO1GJ",
        "timestamps": [
            16.4,
            25.4
        ]
    },
    "7SNIO_0": {
        "text": "one person runs into the room laughing.",
        "vid": "7SNIO",
        "timestamps": [
            0.0,
            7.3
        ]
    },
    "7SNIO_1": {
        "text": "the person runs into the room.",
        "vid": "7SNIO",
        "timestamps": [
            0.0,
            7.3
        ]
    },
    "7SNIO_2": {
        "text": "a person runs into a living.",
        "vid": "7SNIO",
        "timestamps": [
            0.0,
            7.3
        ]
    },
    "QOYH2_0": {
        "text": "person takes a drink from a cup.",
        "vid": "QOYH2",
        "timestamps": [
            17.5,
            25.3
        ]
    },
    "QWKVM_0": {
        "text": "person closes the door.",
        "vid": "QWKVM",
        "timestamps": [
            10.3,
            19.1
        ]
    },
    "QWKVM_1": {
        "text": "person puts a glass on the desk.",
        "vid": "QWKVM",
        "timestamps": [
            1.2,
            8.0
        ]
    },
    "QWKVM_2": {
        "text": "one person opens the door.",
        "vid": "QWKVM",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "QWKVM_3": {
        "text": "a man opens a door.",
        "vid": "QWKVM",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "COBS0_0": {
        "text": "a smiling person takes a towel.",
        "vid": "COBS0",
        "timestamps": [
            6.7,
            14.0
        ]
    },
    "TJZ0P_0": {
        "text": "the person is seated in a chair.",
        "vid": "TJZ0P",
        "timestamps": [
            10.2,
            19.0
        ]
    },
    "TJZ0P_1": {
        "text": "person eats some food.",
        "vid": "TJZ0P",
        "timestamps": [
            10.2,
            19.0
        ]
    },
    "TJZ0P_2": {
        "text": "person takes a bite of food.",
        "vid": "TJZ0P",
        "timestamps": [
            8.5,
            14.2
        ]
    },
    "TJZ0P_3": {
        "text": "person they start sneezing.",
        "vid": "TJZ0P",
        "timestamps": [
            2.8,
            10.4
        ]
    },
    "759MY_0": {
        "text": "person put something on the table.",
        "vid": "759MY",
        "timestamps": [
            7.5,
            13.0
        ]
    },
    "759MY_1": {
        "text": "person putting on their shoes.",
        "vid": "759MY",
        "timestamps": [
            11.9,
            17.4
        ]
    },
    "759MY_2": {
        "text": "person put on their shoes.",
        "vid": "759MY",
        "timestamps": [
            11.9,
            17.4
        ]
    },
    "759MY_3": {
        "text": "a person awakens in their home office.",
        "vid": "759MY",
        "timestamps": [
            1.8,
            6.8
        ]
    },
    "F1V30_0": {
        "text": "a person holding a towel walks up to a counter.",
        "vid": "F1V30",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "F1V30_1": {
        "text": "person washing a glass.",
        "vid": "F1V30",
        "timestamps": [
            23.1,
            33.0
        ]
    },
    "U502L_0": {
        "text": "a person awakens in their bathroom holding their phone.",
        "vid": "U502L",
        "timestamps": [
            20.4,
            26.9
        ]
    },
    "U502L_1": {
        "text": "person takes a towel off the shower rod.",
        "vid": "U502L",
        "timestamps": [
            27.5,
            32.3
        ]
    },
    "OPPVW_0": {
        "text": "person laugh about it.",
        "vid": "OPPVW",
        "timestamps": [
            19.2,
            25.0
        ]
    },
    "NI15V_0": {
        "text": "person holding a towel in the other hand.",
        "vid": "NI15V",
        "timestamps": [
            13.5,
            19.5
        ]
    },
    "NI15V_1": {
        "text": "the person in the doorway walks away holding the towel.",
        "vid": "NI15V",
        "timestamps": [
            18.5,
            25.4
        ]
    },
    "6HT0J_0": {
        "text": "person start reading a book.",
        "vid": "6HT0J",
        "timestamps": [
            6.8,
            19.5
        ]
    },
    "6HT0J_1": {
        "text": "person holding a cup.",
        "vid": "6HT0J",
        "timestamps": [
            8.2,
            20.1
        ]
    },
    "BM3UJ_0": {
        "text": "a person walks through the entryway holding a glass.",
        "vid": "BM3UJ",
        "timestamps": [
            6.4,
            17.3
        ]
    },
    "BM3UJ_1": {
        "text": "a person opens the door to their study.",
        "vid": "BM3UJ",
        "timestamps": [
            3.4,
            9.8
        ]
    },
    "BM3UJ_2": {
        "text": "a person opens the front door to their residence.",
        "vid": "BM3UJ",
        "timestamps": [
            3.4,
            9.8
        ]
    },
    "DM2XL_0": {
        "text": "person opens the front door.",
        "vid": "DM2XL",
        "timestamps": [
            15.4,
            20.9
        ]
    },
    "DM2XL_1": {
        "text": "person opening a door.",
        "vid": "DM2XL",
        "timestamps": [
            15.4,
            20.9
        ]
    },
    "RQRRD_0": {
        "text": "person quickly undressing.",
        "vid": "RQRRD",
        "timestamps": [
            7.5,
            24.3
        ]
    },
    "RQRRD_1": {
        "text": "a person runs into the bedroom.",
        "vid": "RQRRD",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "RQRRD_2": {
        "text": "the person throws their dirty clothes onto a sofa.",
        "vid": "RQRRD",
        "timestamps": [
            16.9,
            22.3
        ]
    },
    "RQRRD_3": {
        "text": "a person runs into the the living room.",
        "vid": "RQRRD",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "RQRRD_4": {
        "text": "person takes new clothes from a box.",
        "vid": "RQRRD",
        "timestamps": [
            5.2,
            11.8
        ]
    },
    "S2FUO_0": {
        "text": "a person kneeling on the floor talks on a phone.",
        "vid": "S2FUO",
        "timestamps": [
            0.0,
            8.4
        ]
    },
    "S2FUO_1": {
        "text": "person talking on the phone.",
        "vid": "S2FUO",
        "timestamps": [
            0.0,
            8.4
        ]
    },
    "S2FUO_2": {
        "text": "the person pours something into a glass.",
        "vid": "S2FUO",
        "timestamps": [
            13.3,
            22.4
        ]
    },
    "S2FUO_3": {
        "text": "a person talks on their phone in the kitchen.",
        "vid": "S2FUO",
        "timestamps": [
            0.0,
            8.4
        ]
    },
    "36T5X_0": {
        "text": "person starts undressing out of their outdoor clothes.",
        "vid": "36T5X",
        "timestamps": [
            24.0,
            34.0
        ]
    },
    "36T5X_1": {
        "text": "person closes the door.",
        "vid": "36T5X",
        "timestamps": [
            14.2,
            23.0
        ]
    },
    "36T5X_2": {
        "text": "person another closes the door.",
        "vid": "36T5X",
        "timestamps": [
            14.2,
            23.0
        ]
    },
    "36T5X_3": {
        "text": "person closing the door.",
        "vid": "36T5X",
        "timestamps": [
            14.2,
            23.0
        ]
    },
    "36T5X_4": {
        "text": "person begins to undress.",
        "vid": "36T5X",
        "timestamps": [
            24.0,
            34.0
        ]
    },
    "AL1WC_0": {
        "text": "the person closes the door.",
        "vid": "AL1WC",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "HOYUT_0": {
        "text": "person closes the pantry door.",
        "vid": "HOYUT",
        "timestamps": [
            11.8,
            17.5
        ]
    },
    "L39A4_0": {
        "text": "a person sits on the floor reading a book.",
        "vid": "L39A4",
        "timestamps": [
            0.6,
            7.8
        ]
    },
    "4H64T_0": {
        "text": "person eating some leftovers from a take-out carton.",
        "vid": "4H64T",
        "timestamps": [
            32.1,
            44.0
        ]
    },
    "4H64T_1": {
        "text": "person takes out some food.",
        "vid": "4H64T",
        "timestamps": [
            20.6,
            30.0
        ]
    },
    "4H64T_2": {
        "text": "person opens a refrigerator.",
        "vid": "4H64T",
        "timestamps": [
            14.6,
            21.2
        ]
    },
    "4H64T_3": {
        "text": "person start to eat the food with a plastic fork.",
        "vid": "4H64T",
        "timestamps": [
            32.1,
            44.0
        ]
    },
    "4H64T_4": {
        "text": "person opens the refrigerator.",
        "vid": "4H64T",
        "timestamps": [
            14.6,
            21.2
        ]
    },
    "AIJ0M_0": {
        "text": "that same person takes a towel.",
        "vid": "AIJ0M",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "AIJ0M_1": {
        "text": "person opens the door.",
        "vid": "AIJ0M",
        "timestamps": [
            7.4,
            13.1
        ]
    },
    "AIJ0M_2": {
        "text": "person holding a towel over one arm.",
        "vid": "AIJ0M",
        "timestamps": [
            0.5,
            12.8
        ]
    },
    "FXGQI_0": {
        "text": "person sneezing into the mirror they are holding.",
        "vid": "FXGQI",
        "timestamps": [
            1.7,
            6.7
        ]
    },
    "FXGQI_1": {
        "text": "person they start sneezing.",
        "vid": "FXGQI",
        "timestamps": [
            1.7,
            6.7
        ]
    },
    "KY2KA_0": {
        "text": "person knees takes a book from a cabinet.",
        "vid": "KY2KA",
        "timestamps": [
            3.7,
            9.5
        ]
    },
    "KY2KA_1": {
        "text": "a person takes a book from a shelf.",
        "vid": "KY2KA",
        "timestamps": [
            3.7,
            9.5
        ]
    },
    "KY2KA_2": {
        "text": "one person takes a book from a wardrobe.",
        "vid": "KY2KA",
        "timestamps": [
            3.7,
            9.5
        ]
    },
    "MNNJS_0": {
        "text": "person pouring coffee into a cup in the dining room.",
        "vid": "MNNJS",
        "timestamps": [
            21.3,
            30.7
        ]
    },
    "MNNJS_1": {
        "text": "the person puts the cups onto a table.",
        "vid": "MNNJS",
        "timestamps": [
            18.5,
            24.0
        ]
    },
    "MNNJS_2": {
        "text": "person pour a cup of coffee.",
        "vid": "MNNJS",
        "timestamps": [
            21.3,
            30.7
        ]
    },
    "QMIKJ_0": {
        "text": "a person is putting their laptop on their desk.",
        "vid": "QMIKJ",
        "timestamps": [
            0.7,
            9.8
        ]
    },
    "QMIKJ_1": {
        "text": "person watching television.",
        "vid": "QMIKJ",
        "timestamps": [
            0.0,
            9.3
        ]
    },
    "QMIKJ_2": {
        "text": "person puts a laptop down on a table.",
        "vid": "QMIKJ",
        "timestamps": [
            1.6,
            9.3
        ]
    },
    "HRASP_0": {
        "text": "a person turns on the light to an entryway.",
        "vid": "HRASP",
        "timestamps": [
            2.7,
            7.9
        ]
    },
    "HRASP_1": {
        "text": "person seen closing a door.",
        "vid": "HRASP",
        "timestamps": [
            19.7,
            26.4
        ]
    },
    "HRASP_2": {
        "text": "person turns on a light.",
        "vid": "HRASP",
        "timestamps": [
            2.7,
            7.9
        ]
    },
    "HRASP_3": {
        "text": "person are seen throwing shoes on the floor.",
        "vid": "HRASP",
        "timestamps": [
            6.3,
            11.6
        ]
    },
    "UY0SK_0": {
        "text": "the person takes a bite out of the sandwich.",
        "vid": "UY0SK",
        "timestamps": [
            13.2,
            18.1
        ]
    },
    "UY0SK_1": {
        "text": "person sit to eat a sandwich.",
        "vid": "UY0SK",
        "timestamps": [
            22.9,
            28.0
        ]
    },
    "UY0SK_2": {
        "text": "person watch the television in the next room.",
        "vid": "UY0SK",
        "timestamps": [
            14.6,
            28.0
        ]
    },
    "YQT32_0": {
        "text": "person takes several pictures of different things in the room.",
        "vid": "YQT32",
        "timestamps": [
            17.8,
            27.2
        ]
    },
    "SJ4QF_0": {
        "text": "person washes a glass.",
        "vid": "SJ4QF",
        "timestamps": [
            6.4,
            15.5
        ]
    },
    "69R8T_0": {
        "text": "person eats it from a plate.",
        "vid": "69R8T",
        "timestamps": [
            24.9,
            33.0
        ]
    },
    "2Z8G8_0": {
        "text": "person they put the bag on a shelf.",
        "vid": "2Z8G8",
        "timestamps": [
            6.2,
            15.5
        ]
    },
    "2Z8G8_1": {
        "text": "person tidying up a blanket.",
        "vid": "2Z8G8",
        "timestamps": [
            14.9,
            29.4
        ]
    },
    "XVI3M_0": {
        "text": "person they put the laptop on the pillow.",
        "vid": "XVI3M",
        "timestamps": [
            14.8,
            20.9
        ]
    },
    "XVI3M_1": {
        "text": "person stand up.",
        "vid": "XVI3M",
        "timestamps": [
            17.6,
            24.9
        ]
    },
    "XVI3M_2": {
        "text": "the person puts the laptop down.",
        "vid": "XVI3M",
        "timestamps": [
            14.8,
            20.9
        ]
    },
    "Y3M3W_0": {
        "text": "the person is looking at an opened book.",
        "vid": "Y3M3W",
        "timestamps": [
            1.7,
            8.0
        ]
    },
    "URK3G_0": {
        "text": "person open the books.",
        "vid": "URK3G",
        "timestamps": [
            14.5,
            20.8
        ]
    },
    "URK3G_1": {
        "text": "person start drinking from the glass.",
        "vid": "URK3G",
        "timestamps": [
            3.7,
            18.6
        ]
    },
    "URK3G_2": {
        "text": "another person runs in with homework.",
        "vid": "URK3G",
        "timestamps": [
            5.9,
            11.6
        ]
    },
    "URK3G_3": {
        "text": "one person opens the refrigerator.",
        "vid": "URK3G",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "G8NEV_0": {
        "text": "the person starts reading a book.",
        "vid": "G8NEV",
        "timestamps": [
            14.7,
            24.0
        ]
    },
    "G8NEV_1": {
        "text": "person a few moments later laughs.",
        "vid": "G8NEV",
        "timestamps": [
            18.2,
            24.2
        ]
    },
    "G8NEV_2": {
        "text": "person laughs a little bit.",
        "vid": "G8NEV",
        "timestamps": [
            18.2,
            24.2
        ]
    },
    "C0CMQ_0": {
        "text": "person open the door at the bottom of the stairs.",
        "vid": "C0CMQ",
        "timestamps": [
            11.8,
            18.7
        ]
    },
    "C0CMQ_1": {
        "text": "person walks through the doorway.",
        "vid": "C0CMQ",
        "timestamps": [
            13.6,
            20.0
        ]
    },
    "C0CMQ_2": {
        "text": "person opens a door.",
        "vid": "C0CMQ",
        "timestamps": [
            11.8,
            18.7
        ]
    },
    "7XMBM_0": {
        "text": "person starts eating.",
        "vid": "7XMBM",
        "timestamps": [
            9.3,
            18.3
        ]
    },
    "7XMBM_1": {
        "text": "person eating from a bowl.",
        "vid": "7XMBM",
        "timestamps": [
            9.3,
            18.3
        ]
    },
    "7XMBM_2": {
        "text": "another person walks into a room eating some food.",
        "vid": "7XMBM",
        "timestamps": [
            9.3,
            18.3
        ]
    },
    "61IVZ_0": {
        "text": "person closes the door.",
        "vid": "61IVZ",
        "timestamps": [
            2.6,
            9.2
        ]
    },
    "61IVZ_1": {
        "text": "person they set down the bag they're holding.",
        "vid": "61IVZ",
        "timestamps": [
            0.0,
            12.0
        ]
    },
    "61IVZ_2": {
        "text": "person put down the bag they were holding.",
        "vid": "61IVZ",
        "timestamps": [
            5.8,
            13.3
        ]
    },
    "61IVZ_3": {
        "text": "the person puts a bag down.",
        "vid": "61IVZ",
        "timestamps": [
            5.8,
            13.3
        ]
    },
    "61IVZ_4": {
        "text": "a person opens the door.",
        "vid": "61IVZ",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "A33VQ_0": {
        "text": "person holding a chair opened a refrigerator.",
        "vid": "A33VQ",
        "timestamps": [
            11.1,
            19.7
        ]
    },
    "A33VQ_1": {
        "text": "person opening a refrigerator in the dining room.",
        "vid": "A33VQ",
        "timestamps": [
            11.1,
            19.7
        ]
    },
    "A33VQ_2": {
        "text": "person closes the refrigerator.",
        "vid": "A33VQ",
        "timestamps": [
            21.0,
            29.4
        ]
    },
    "ZMY8M_0": {
        "text": "person takes some food from a bowl.",
        "vid": "ZMY8M",
        "timestamps": [
            6.4,
            11.8
        ]
    },
    "ZMY8M_1": {
        "text": "a person eats a sandwich from the table.",
        "vid": "ZMY8M",
        "timestamps": [
            8.1,
            13.8
        ]
    },
    "ZMY8M_2": {
        "text": "the person eats some food.",
        "vid": "ZMY8M",
        "timestamps": [
            8.1,
            13.8
        ]
    },
    "ZMY8M_3": {
        "text": "person opening a cabinet in a kitchen.",
        "vid": "ZMY8M",
        "timestamps": [
            19.8,
            25.5
        ]
    },
    "ZMY8M_4": {
        "text": "person eating breakfast.",
        "vid": "ZMY8M",
        "timestamps": [
            8.1,
            13.8
        ]
    },
    "ZMY8M_5": {
        "text": "person opens cabinets above it.",
        "vid": "ZMY8M",
        "timestamps": [
            19.8,
            25.5
        ]
    },
    "39E0I_0": {
        "text": "a person runs around covered in a blanket.",
        "vid": "39E0I",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "T9Y1N_0": {
        "text": "the person starts smiling.",
        "vid": "T9Y1N",
        "timestamps": [
            22.4,
            32.0
        ]
    },
    "T9Y1N_1": {
        "text": "the person opens the box.",
        "vid": "T9Y1N",
        "timestamps": [
            5.0,
            10.9
        ]
    },
    "T9Y1N_2": {
        "text": "a person is sneezing on a box.",
        "vid": "T9Y1N",
        "timestamps": [
            6.6,
            18.3
        ]
    },
    "T9Y1N_3": {
        "text": "a person opens the doors to the pantry.",
        "vid": "T9Y1N",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "0PU21_0": {
        "text": "the person puts the cup down.",
        "vid": "0PU21",
        "timestamps": [
            13.6,
            17.8
        ]
    },
    "AX46Z_0": {
        "text": "person starts laughing.",
        "vid": "AX46Z",
        "timestamps": [
            12.8,
            28.7
        ]
    },
    "AX46Z_1": {
        "text": "person laughs as they lean against the dresser.",
        "vid": "AX46Z",
        "timestamps": [
            12.8,
            28.7
        ]
    },
    "AX46Z_2": {
        "text": "the animal sitting on the bed climbs on the person.",
        "vid": "AX46Z",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "AX46Z_3": {
        "text": "a person is awakening in their bed.",
        "vid": "AX46Z",
        "timestamps": [
            1.2,
            7.2
        ]
    },
    "9POJB_0": {
        "text": "the person sits in a chair for a moment.",
        "vid": "9POJB",
        "timestamps": [
            14.0,
            27.9
        ]
    },
    "9POJB_1": {
        "text": "person takes a blanket.",
        "vid": "9POJB",
        "timestamps": [
            16.5,
            22.6
        ]
    },
    "9POJB_2": {
        "text": "person sitting in a chair drinking a something.",
        "vid": "9POJB",
        "timestamps": [
            14.0,
            27.9
        ]
    },
    "9POJB_3": {
        "text": "person stand up.",
        "vid": "9POJB",
        "timestamps": [
            2.2,
            7.2
        ]
    },
    "K0FAG_0": {
        "text": "a person is smiling.",
        "vid": "K0FAG",
        "timestamps": [
            11.0,
            21.1
        ]
    },
    "K0FAG_1": {
        "text": "a person is standing in their kitchen laughing.",
        "vid": "K0FAG",
        "timestamps": [
            11.0,
            21.1
        ]
    },
    "N0G70_0": {
        "text": "a person puts food into a sandwich maker.",
        "vid": "N0G70",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "N0G70_1": {
        "text": "a person cooks a sandwich on a panini maker.",
        "vid": "N0G70",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "SJ51G_0": {
        "text": "person puts the blanket into a closet.",
        "vid": "SJ51G",
        "timestamps": [
            16.0,
            21.7
        ]
    },
    "SJ51G_1": {
        "text": "a person is seen snuggling up to a blanket.",
        "vid": "SJ51G",
        "timestamps": [
            0.0,
            13.0
        ]
    },
    "SJ51G_2": {
        "text": "a person opens a door.",
        "vid": "SJ51G",
        "timestamps": [
            9.9,
            18.9
        ]
    },
    "SJ51G_3": {
        "text": "person open their closet door.",
        "vid": "SJ51G",
        "timestamps": [
            9.9,
            18.9
        ]
    },
    "SJ51G_4": {
        "text": "person close the door.",
        "vid": "SJ51G",
        "timestamps": [
            19.1,
            29.3
        ]
    },
    "SJ51G_5": {
        "text": "person put the blanket away.",
        "vid": "SJ51G",
        "timestamps": [
            16.0,
            21.7
        ]
    },
    "SJ51G_6": {
        "text": "a person is snuggling with a blanket.",
        "vid": "SJ51G",
        "timestamps": [
            0.0,
            13.0
        ]
    },
    "30I35_0": {
        "text": "person took a drink from the glass.",
        "vid": "30I35",
        "timestamps": [
            1.5,
            8.3
        ]
    },
    "30I35_1": {
        "text": "person poured its contents into the glass.",
        "vid": "30I35",
        "timestamps": [
            9.0,
            14.6
        ]
    },
    "30I35_2": {
        "text": "person pours a glass of something.",
        "vid": "30I35",
        "timestamps": [
            9.0,
            14.6
        ]
    },
    "30I35_3": {
        "text": "person takes a drink from the glass.",
        "vid": "30I35",
        "timestamps": [
            1.5,
            8.3
        ]
    },
    "30I35_4": {
        "text": "person pours water into a glass.",
        "vid": "30I35",
        "timestamps": [
            9.0,
            14.6
        ]
    },
    "MUWG4_0": {
        "text": "person pours soda into a cup.",
        "vid": "MUWG4",
        "timestamps": [
            5.0,
            13.4
        ]
    },
    "WD35N_0": {
        "text": "a person opens a cabinet.",
        "vid": "WD35N",
        "timestamps": [
            3.9,
            9.7
        ]
    },
    "WD35N_1": {
        "text": "person closes the cabinet.",
        "vid": "WD35N",
        "timestamps": [
            3.9,
            9.0
        ]
    },
    "WD35N_2": {
        "text": "person takes a pillow from inside.",
        "vid": "WD35N",
        "timestamps": [
            8.9,
            14.3
        ]
    },
    "WD35N_3": {
        "text": "person takes out a pillow like object.",
        "vid": "WD35N",
        "timestamps": [
            8.9,
            14.3
        ]
    },
    "LLT3E_0": {
        "text": "person walks through a doorway to leave the room.",
        "vid": "LLT3E",
        "timestamps": [
            15.4,
            22.4
        ]
    },
    "LLT3E_1": {
        "text": "person they walk through a doorway.",
        "vid": "LLT3E",
        "timestamps": [
            15.4,
            22.4
        ]
    },
    "8UCK1_0": {
        "text": "a person opens a cabinet.",
        "vid": "8UCK1",
        "timestamps": [
            1.6,
            7.0
        ]
    },
    "8UCK1_1": {
        "text": "a person is opening a cabinet.",
        "vid": "8UCK1",
        "timestamps": [
            1.6,
            7.0
        ]
    },
    "8UCK1_2": {
        "text": "person closing the cabinet.",
        "vid": "8UCK1",
        "timestamps": [
            8.7,
            13.9
        ]
    },
    "4U8WV_0": {
        "text": "person holding a small hand towel.",
        "vid": "4U8WV",
        "timestamps": [
            0.0,
            14.7
        ]
    },
    "4U8WV_1": {
        "text": "the person puts the towel down on the couch.",
        "vid": "4U8WV",
        "timestamps": [
            8.5,
            15.2
        ]
    },
    "LSFJG_0": {
        "text": "person starts running in place.",
        "vid": "LSFJG",
        "timestamps": [
            20.7,
            26.0
        ]
    },
    "LSFJG_1": {
        "text": "a person puts on a pair of shoes.",
        "vid": "LSFJG",
        "timestamps": [
            1.8,
            9.4
        ]
    },
    "LSFJG_2": {
        "text": "person begins running in place.",
        "vid": "LSFJG",
        "timestamps": [
            20.7,
            26.0
        ]
    },
    "LSFJG_3": {
        "text": "person they start running in place again.",
        "vid": "LSFJG",
        "timestamps": [
            20.7,
            26.0
        ]
    },
    "LSFJG_4": {
        "text": "person start watching themselves in a mirror.",
        "vid": "LSFJG",
        "timestamps": [
            13.3,
            20.6
        ]
    },
    "LSFJG_5": {
        "text": "person start running in palce again.",
        "vid": "LSFJG",
        "timestamps": [
            20.7,
            26.0
        ]
    },
    "LSFJG_6": {
        "text": "person starts running in place again.",
        "vid": "LSFJG",
        "timestamps": [
            20.7,
            26.0
        ]
    },
    "W0QSB_0": {
        "text": "a person is cooking on a stove.",
        "vid": "W0QSB",
        "timestamps": [
            0.0,
            14.4
        ]
    },
    "5IPJA_0": {
        "text": "person puts a pillow on their head.",
        "vid": "5IPJA",
        "timestamps": [
            13.9,
            20.9
        ]
    },
    "S7JTZ_0": {
        "text": "person uses it to take pictures of their self.",
        "vid": "S7JTZ",
        "timestamps": [
            3.0,
            14.5
        ]
    },
    "S7JTZ_1": {
        "text": "person take a timed picture.",
        "vid": "S7JTZ",
        "timestamps": [
            3.0,
            14.5
        ]
    },
    "S7JTZ_2": {
        "text": "a person walks into the bathroom holding a camera.",
        "vid": "S7JTZ",
        "timestamps": [
            2.4,
            14.5
        ]
    },
    "RVVDR_0": {
        "text": "person puts the bag on the table.",
        "vid": "RVVDR",
        "timestamps": [
            7.9,
            15.0
        ]
    },
    "RVVDR_1": {
        "text": "person putting it on a table.",
        "vid": "RVVDR",
        "timestamps": [
            3.7,
            12.6
        ]
    },
    "RVVDR_2": {
        "text": "a person was holding a bag which he.",
        "vid": "RVVDR",
        "timestamps": [
            0.0,
            13.8
        ]
    },
    "RVVDR_3": {
        "text": "a person is putting groceries in a bag.",
        "vid": "RVVDR",
        "timestamps": [
            0.5,
            11.0
        ]
    },
    "RVVDR_4": {
        "text": "a person opens a bag.",
        "vid": "RVVDR",
        "timestamps": [
            0.0,
            11.6
        ]
    },
    "T06AT_0": {
        "text": "one person runs into the bathroom grasping a pillow.",
        "vid": "T06AT",
        "timestamps": [
            0.0,
            13.4
        ]
    },
    "T06AT_1": {
        "text": "a man runs into a bathroom holding a pillow.",
        "vid": "T06AT",
        "timestamps": [
            0.0,
            13.4
        ]
    },
    "T06AT_2": {
        "text": "another person is inside holding a blanket.",
        "vid": "T06AT",
        "timestamps": [
            5.0,
            13.4
        ]
    },
    "TZ9FE_0": {
        "text": "a person runs to the closet.",
        "vid": "TZ9FE",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "TZ9FE_1": {
        "text": "a person runs into a room.",
        "vid": "TZ9FE",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "TZ9FE_2": {
        "text": "person puts the clothes away.",
        "vid": "TZ9FE",
        "timestamps": [
            23.0,
            29.0
        ]
    },
    "TZ9FE_3": {
        "text": "person holding a stack of clothes.",
        "vid": "TZ9FE",
        "timestamps": [
            0.0,
            14.0
        ]
    },
    "T7ST5_0": {
        "text": "the person used the spoon to eat from the cup.",
        "vid": "T7ST5",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "T7ST5_1": {
        "text": "person eating a piece of pie.",
        "vid": "T7ST5",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "IQA16_0": {
        "text": "person putting them on a table.",
        "vid": "IQA16",
        "timestamps": [
            0.8,
            13.6
        ]
    },
    "IQA16_1": {
        "text": "person turns off the light.",
        "vid": "IQA16",
        "timestamps": [
            11.2,
            19.6
        ]
    },
    "IQA16_2": {
        "text": "person switch the light off.",
        "vid": "IQA16",
        "timestamps": [
            11.2,
            19.6
        ]
    },
    "IQA16_3": {
        "text": "the person turns off the light.",
        "vid": "IQA16",
        "timestamps": [
            11.2,
            19.6
        ]
    },
    "M3OMM_0": {
        "text": "a man begins to undress.",
        "vid": "M3OMM",
        "timestamps": [
            0.0,
            8.4
        ]
    },
    "J7BOV_0": {
        "text": "a person is putting a camera next to a towel.",
        "vid": "J7BOV",
        "timestamps": [
            4.6,
            11.9
        ]
    },
    "RPXAC_0": {
        "text": "person dressing themselves.",
        "vid": "RPXAC",
        "timestamps": [
            10.1,
            22.2
        ]
    },
    "RLQ9K_0": {
        "text": "the person takes out a bottle of medicine.",
        "vid": "RLQ9K",
        "timestamps": [
            16.1,
            30.7
        ]
    },
    "RLQ9K_1": {
        "text": "person take some medicine.",
        "vid": "RLQ9K",
        "timestamps": [
            16.1,
            30.7
        ]
    },
    "PRTAJ_0": {
        "text": "a person opens a cabinet.",
        "vid": "PRTAJ",
        "timestamps": [
            7.5,
            19.7
        ]
    },
    "PRTAJ_1": {
        "text": "person closes the cabinet.",
        "vid": "PRTAJ",
        "timestamps": [
            8.7,
            17.1
        ]
    },
    "PRTAJ_2": {
        "text": "person looks out the window.",
        "vid": "PRTAJ",
        "timestamps": [
            31.4,
            43.0
        ]
    },
    "PRTAJ_3": {
        "text": "person gets dressed.",
        "vid": "PRTAJ",
        "timestamps": [
            18.8,
            33.1
        ]
    },
    "KZ36U_0": {
        "text": "a person runs into the garage.",
        "vid": "KZ36U",
        "timestamps": [
            2.9,
            8.0
        ]
    },
    "KZ36U_1": {
        "text": "the person takes a picture of something.",
        "vid": "KZ36U",
        "timestamps": [
            9.0,
            15.5
        ]
    },
    "CD9GP_0": {
        "text": "person stand up.",
        "vid": "CD9GP",
        "timestamps": [
            23.5,
            28.9
        ]
    },
    "7NXWU_0": {
        "text": "person drinking from a cup.",
        "vid": "7NXWU",
        "timestamps": [
            4.2,
            13.1
        ]
    },
    "OHNUQ_0": {
        "text": "a person is eating some food.",
        "vid": "OHNUQ",
        "timestamps": [
            6.5,
            13.5
        ]
    },
    "OHNUQ_1": {
        "text": "person they are watching television in the living room.",
        "vid": "OHNUQ",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "OHNUQ_2": {
        "text": "person eating it out of the box.",
        "vid": "OHNUQ",
        "timestamps": [
            6.5,
            13.5
        ]
    },
    "OHNUQ_3": {
        "text": "person watching the television.",
        "vid": "OHNUQ",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "OHNUQ_4": {
        "text": "person watching television.",
        "vid": "OHNUQ",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "5VUT9_0": {
        "text": "the person is holding a broom.",
        "vid": "5VUT9",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "5VUT9_1": {
        "text": "person put the broom aside.",
        "vid": "5VUT9",
        "timestamps": [
            5.0,
            10.0
        ]
    },
    "5VUT9_2": {
        "text": "person open a cabinet door get a cup out.",
        "vid": "5VUT9",
        "timestamps": [
            8.0,
            13.0
        ]
    },
    "5VUT9_3": {
        "text": "a person standing in the doorway holds a broom.",
        "vid": "5VUT9",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "5VUT9_4": {
        "text": "person pour a cup of coffee.",
        "vid": "5VUT9",
        "timestamps": [
            18.0,
            25.0
        ]
    },
    "FQS7O_0": {
        "text": "person closes a book.",
        "vid": "FQS7O",
        "timestamps": [
            6.9,
            11.5
        ]
    },
    "55NRK_0": {
        "text": "person begins sneezing.",
        "vid": "55NRK",
        "timestamps": [
            19.1,
            30.6
        ]
    },
    "UNWMJ_0": {
        "text": "the person was undressing by the wardrobe.",
        "vid": "UNWMJ",
        "timestamps": [
            1.3,
            13.6
        ]
    },
    "X9M5B_0": {
        "text": "the person is sitting in the couch with the laptop.",
        "vid": "X9M5B",
        "timestamps": [
            0.0,
            15.9
        ]
    },
    "9RRED_0": {
        "text": "person sits down on a sofa.",
        "vid": "9RRED",
        "timestamps": [
            25.5,
            32.0
        ]
    },
    "9RRED_1": {
        "text": "person takes off his shoes.",
        "vid": "9RRED",
        "timestamps": [
            18.3,
            25.3
        ]
    },
    "9RRED_2": {
        "text": "this person takes off their shoes.",
        "vid": "9RRED",
        "timestamps": [
            18.3,
            25.3
        ]
    },
    "9RRED_3": {
        "text": "person drinking from a water bottle.",
        "vid": "9RRED",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "9RRED_4": {
        "text": "the person takes off a pair of shoes.",
        "vid": "9RRED",
        "timestamps": [
            18.3,
            25.3
        ]
    },
    "9RRED_5": {
        "text": "person sits on a couch.",
        "vid": "9RRED",
        "timestamps": [
            25.5,
            32.0
        ]
    },
    "9RRED_6": {
        "text": "person drinking from a plastic water bottle.",
        "vid": "9RRED",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "IALUY_0": {
        "text": "person holding a towel.",
        "vid": "IALUY",
        "timestamps": [
            9.5,
            20.4
        ]
    },
    "IALUY_1": {
        "text": "a person is sneezing.",
        "vid": "IALUY",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "IALUY_2": {
        "text": "person takes a towel from a rack.",
        "vid": "IALUY",
        "timestamps": [
            8.6,
            15.1
        ]
    },
    "HHNTA_0": {
        "text": "person open a box.",
        "vid": "HHNTA",
        "timestamps": [
            24.9,
            31.1
        ]
    },
    "HHNTA_1": {
        "text": "person eating something.",
        "vid": "HHNTA",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "HHNTA_2": {
        "text": "a person is walking around the room eating a sandwich.",
        "vid": "HHNTA",
        "timestamps": [
            0.0,
            14.7
        ]
    },
    "HHNTA_3": {
        "text": "person removes a sweatshirt.",
        "vid": "HHNTA",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "HHNTA_4": {
        "text": "person start undressing.",
        "vid": "HHNTA",
        "timestamps": [
            13.9,
            26.2
        ]
    },
    "HHNTA_5": {
        "text": "person takes off a sweatshirt.",
        "vid": "HHNTA",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "HHNTA_6": {
        "text": "the person takes off their hoodie/sweater.",
        "vid": "HHNTA",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "BM9NZ_0": {
        "text": "the person eats food.",
        "vid": "BM9NZ",
        "timestamps": [
            24.1,
            30.8
        ]
    },
    "BM9NZ_1": {
        "text": "a person is snuggling with their pillow in bed.",
        "vid": "BM9NZ",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "BM9NZ_2": {
        "text": "person snuggling with a pillow.",
        "vid": "BM9NZ",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "BM9NZ_3": {
        "text": "person they start eating.",
        "vid": "BM9NZ",
        "timestamps": [
            24.1,
            30.8
        ]
    },
    "318CP_0": {
        "text": "person pick up a cup to drink.",
        "vid": "318CP",
        "timestamps": [
            19.7,
            33.0
        ]
    },
    "318CP_1": {
        "text": "person eat it.",
        "vid": "318CP",
        "timestamps": [
            8.7,
            23.6
        ]
    },
    "318CP_2": {
        "text": "person eats it.",
        "vid": "318CP",
        "timestamps": [
            8.7,
            23.6
        ]
    },
    "318CP_3": {
        "text": "person drinks from a cup.",
        "vid": "318CP",
        "timestamps": [
            19.7,
            33.0
        ]
    },
    "H608V_0": {
        "text": "a person is running in the living room in circles.",
        "vid": "H608V",
        "timestamps": [
            11.6,
            22.0
        ]
    },
    "H608V_1": {
        "text": "person eats a sandwich.",
        "vid": "H608V",
        "timestamps": [
            0.9,
            7.9
        ]
    },
    "H608V_2": {
        "text": "person begins to run around in a circle again.",
        "vid": "H608V",
        "timestamps": [
            11.6,
            22.0
        ]
    },
    "H608V_3": {
        "text": "a person runs around the room in a circle.",
        "vid": "H608V",
        "timestamps": [
            11.6,
            22.0
        ]
    },
    "H608V_4": {
        "text": "person take a bite of a sandwich.",
        "vid": "H608V",
        "timestamps": [
            1.0,
            6.4
        ]
    },
    "H608V_5": {
        "text": "person continue to run.",
        "vid": "H608V",
        "timestamps": [
            11.6,
            22.0
        ]
    },
    "H608V_6": {
        "text": "person start running again.",
        "vid": "H608V",
        "timestamps": [
            11.6,
            22.0
        ]
    },
    "IGZZG_0": {
        "text": "person reading a book.",
        "vid": "IGZZG",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "IGZZG_1": {
        "text": "person reading books.",
        "vid": "IGZZG",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "IGZZG_2": {
        "text": "the person is sitting on the floor watching television.",
        "vid": "IGZZG",
        "timestamps": [
            5.4,
            11.6
        ]
    },
    "MPHFU_0": {
        "text": "a person looks at a picture in a picture frame.",
        "vid": "MPHFU",
        "timestamps": [
            0.0,
            11.2
        ]
    },
    "MPHFU_1": {
        "text": "a person holds a picture.",
        "vid": "MPHFU",
        "timestamps": [
            0.0,
            12.2
        ]
    },
    "YYLKT_0": {
        "text": "person begin to eat a sandwich.",
        "vid": "YYLKT",
        "timestamps": [
            12.5,
            24.0
        ]
    },
    "YYLKT_1": {
        "text": "the person puts the blanket on the floor.",
        "vid": "YYLKT",
        "timestamps": [
            7.7,
            15.3
        ]
    },
    "TUJF4_0": {
        "text": "a person opens a door.",
        "vid": "TUJF4",
        "timestamps": [
            0.9,
            8.2
        ]
    },
    "TUJF4_1": {
        "text": "person takes a pair of shoes from under a chair.",
        "vid": "TUJF4",
        "timestamps": [
            14.9,
            21.9
        ]
    },
    "A2X7Q_0": {
        "text": "person put a sandwich in the bag.",
        "vid": "A2X7Q",
        "timestamps": [
            11.1,
            18.7
        ]
    },
    "A2X7Q_1": {
        "text": "person take a bag out.",
        "vid": "A2X7Q",
        "timestamps": [
            5.5,
            10.7
        ]
    },
    "A2X7Q_2": {
        "text": "a person walks into the kitchen they open the cabinet.",
        "vid": "A2X7Q",
        "timestamps": [
            3.0,
            11.0
        ]
    },
    "URAIM_0": {
        "text": "the person takes a picture from the table.",
        "vid": "URAIM",
        "timestamps": [
            13.7,
            20.4
        ]
    },
    "URAIM_1": {
        "text": "the person takes a picture from a coffee table.",
        "vid": "URAIM",
        "timestamps": [
            13.7,
            20.4
        ]
    },
    "URAIM_2": {
        "text": "person puts it back on the table.",
        "vid": "URAIM",
        "timestamps": [
            25.7,
            32.0
        ]
    },
    "MBAA5_0": {
        "text": "a person is smiling.",
        "vid": "MBAA5",
        "timestamps": [
            14.9,
            24.2
        ]
    },
    "MBAA5_1": {
        "text": "person opens a closet door.",
        "vid": "MBAA5",
        "timestamps": [
            2.7,
            13.0
        ]
    },
    "MBAA5_2": {
        "text": "person closing a closet door in the hallway.",
        "vid": "MBAA5",
        "timestamps": [
            12.0,
            23.8
        ]
    },
    "MBAA5_3": {
        "text": "person closes the door.",
        "vid": "MBAA5",
        "timestamps": [
            12.0,
            23.8
        ]
    },
    "MBAA5_4": {
        "text": "the person opens a closet.",
        "vid": "MBAA5",
        "timestamps": [
            2.7,
            13.0
        ]
    },
    "MBAA5_5": {
        "text": "person puts it on a shelf.",
        "vid": "MBAA5",
        "timestamps": [
            7.6,
            17.5
        ]
    },
    "YE6TZ_0": {
        "text": "a person is putting a book on a chair.",
        "vid": "YE6TZ",
        "timestamps": [
            0.2,
            8.3
        ]
    },
    "YE6TZ_1": {
        "text": "person start drinking from a cup.",
        "vid": "YE6TZ",
        "timestamps": [
            10.1,
            17.3
        ]
    },
    "YE6TZ_2": {
        "text": "a person put a book into a closet.",
        "vid": "YE6TZ",
        "timestamps": [
            0.2,
            8.3
        ]
    },
    "0TDOP_0": {
        "text": "a person is putting a box on the table.",
        "vid": "0TDOP",
        "timestamps": [
            2.1,
            8.0
        ]
    },
    "0TDOP_1": {
        "text": "a person holding a brown cardboard box enters a kitchen.",
        "vid": "0TDOP",
        "timestamps": [
            0.0,
            6.7
        ]
    },
    "8B4ZP_0": {
        "text": "person they stand up.",
        "vid": "8B4ZP",
        "timestamps": [
            31.6,
            40.2
        ]
    },
    "8B4ZP_1": {
        "text": "person turn off the light.",
        "vid": "8B4ZP",
        "timestamps": [
            46.4,
            49.0
        ]
    },
    "8B4ZP_2": {
        "text": "person start undressing.",
        "vid": "8B4ZP",
        "timestamps": [
            38.4,
            47.8
        ]
    },
    "8B4ZP_3": {
        "text": "person turning off the light.",
        "vid": "8B4ZP",
        "timestamps": [
            46.4,
            49.0
        ]
    },
    "8B4ZP_4": {
        "text": "the person puts the book down.",
        "vid": "8B4ZP",
        "timestamps": [
            27.5,
            34.2
        ]
    },
    "N0NLE_0": {
        "text": "person laughs at cellphone.",
        "vid": "N0NLE",
        "timestamps": [
            23.5,
            30.0
        ]
    },
    "N0NLE_1": {
        "text": "person laughing a lot.",
        "vid": "N0NLE",
        "timestamps": [
            23.5,
            30.0
        ]
    },
    "N0NLE_2": {
        "text": "person is laughing at the camera.",
        "vid": "N0NLE",
        "timestamps": [
            23.5,
            30.0
        ]
    },
    "AVL8A_0": {
        "text": "person opens a book.",
        "vid": "AVL8A",
        "timestamps": [
            3.8,
            8.5
        ]
    },
    "AVL8A_1": {
        "text": "person smiling at the book.",
        "vid": "AVL8A",
        "timestamps": [
            4.8,
            12.2
        ]
    },
    "7ZL8E_0": {
        "text": "person putting the shoes down on the floor.",
        "vid": "7ZL8E",
        "timestamps": [
            16.6,
            27.2
        ]
    },
    "7ZL8E_1": {
        "text": "a person takes off their shoes.",
        "vid": "7ZL8E",
        "timestamps": [
            16.5,
            25.9
        ]
    },
    "7ZL8E_2": {
        "text": "person they hold each shoe.",
        "vid": "7ZL8E",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "7ZL8E_3": {
        "text": "person takes off their shoes.",
        "vid": "7ZL8E",
        "timestamps": [
            16.5,
            25.9
        ]
    },
    "V0WK7_0": {
        "text": "another person stands by them smiling.",
        "vid": "V0WK7",
        "timestamps": [
            6.1,
            16.1
        ]
    },
    "3JXKZ_0": {
        "text": "a person is opening a bag.",
        "vid": "3JXKZ",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "KQ6XW_0": {
        "text": "person take a drink from their water bottle.",
        "vid": "KQ6XW",
        "timestamps": [
            15.7,
            25.2
        ]
    },
    "9TM1K_0": {
        "text": "the person opens a box.",
        "vid": "9TM1K",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "9TM1K_1": {
        "text": "person closes the book.",
        "vid": "9TM1K",
        "timestamps": [
            25.1,
            32.0
        ]
    },
    "YMD74_0": {
        "text": "a person is awakening.",
        "vid": "YMD74",
        "timestamps": [
            3.4,
            8.8
        ]
    },
    "YMD74_1": {
        "text": "person putting on shoes.",
        "vid": "YMD74",
        "timestamps": [
            16.0,
            23.2
        ]
    },
    "YMD74_2": {
        "text": "person awakening.",
        "vid": "YMD74",
        "timestamps": [
            3.4,
            8.8
        ]
    },
    "ATIAW_0": {
        "text": "person turn on the light.",
        "vid": "ATIAW",
        "timestamps": [
            27.3,
            32.9
        ]
    },
    "ATIAW_1": {
        "text": "person turning on a light.",
        "vid": "ATIAW",
        "timestamps": [
            27.3,
            32.9
        ]
    },
    "0UK3H_0": {
        "text": "person taping the box closed.",
        "vid": "0UK3H",
        "timestamps": [
            2.1,
            8.2
        ]
    },
    "KWZSA_0": {
        "text": "person walks to the doorway.",
        "vid": "KWZSA",
        "timestamps": [
            23.8,
            31.0
        ]
    },
    "KWZSA_1": {
        "text": "a person was sitting at a table.",
        "vid": "KWZSA",
        "timestamps": [
            13.4,
            28.1
        ]
    },
    "KWZSA_2": {
        "text": "person begins tidying the table.",
        "vid": "KWZSA",
        "timestamps": [
            15.1,
            26.5
        ]
    },
    "12XD3_0": {
        "text": "person looks outy the window.",
        "vid": "12XD3",
        "timestamps": [
            4.1,
            11.9
        ]
    },
    "12XD3_1": {
        "text": "person eating some food.",
        "vid": "12XD3",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "12XD3_2": {
        "text": "the person is look at a picture.",
        "vid": "12XD3",
        "timestamps": [
            1.4,
            7.9
        ]
    },
    "12XD3_3": {
        "text": "a person is eating.",
        "vid": "12XD3",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "12XD3_4": {
        "text": "the person begins eating the sandwich.",
        "vid": "12XD3",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "12XD3_5": {
        "text": "person watching something out the window.",
        "vid": "12XD3",
        "timestamps": [
            4.1,
            11.9
        ]
    },
    "12XD3_6": {
        "text": "person looks at the picture.",
        "vid": "12XD3",
        "timestamps": [
            1.4,
            7.9
        ]
    },
    "3Q6N1_0": {
        "text": "a person opens their laptop to do their work.",
        "vid": "3Q6N1",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "3Q6N1_1": {
        "text": "a person starts working on a laptop.",
        "vid": "3Q6N1",
        "timestamps": [
            11.4,
            14.0
        ]
    },
    "7XCAP_0": {
        "text": "a person is smiling.",
        "vid": "7XCAP",
        "timestamps": [
            25.2,
            30.7
        ]
    },
    "7XCAP_1": {
        "text": "person they are drinking a glass of water.",
        "vid": "7XCAP",
        "timestamps": [
            18.1,
            32.0
        ]
    },
    "7XCAP_2": {
        "text": "person drinks from a glass.",
        "vid": "7XCAP",
        "timestamps": [
            18.1,
            32.0
        ]
    },
    "7XCAP_3": {
        "text": "person begin to drink water from a glass cup.",
        "vid": "7XCAP",
        "timestamps": [
            18.1,
            32.0
        ]
    },
    "GY8P2_0": {
        "text": "person is sneezing.",
        "vid": "GY8P2",
        "timestamps": [
            9.5,
            14.9
        ]
    },
    "GY8P2_1": {
        "text": "the sneezing person picks up a broom as well.",
        "vid": "GY8P2",
        "timestamps": [
            9.5,
            14.9
        ]
    },
    "XK0QV_0": {
        "text": "person drinking a glass of water.",
        "vid": "XK0QV",
        "timestamps": [
            0.0,
            14.3
        ]
    },
    "1HZGH_0": {
        "text": "person putting on their shoes.",
        "vid": "1HZGH",
        "timestamps": [
            16.7,
            32.2
        ]
    },
    "1HZGH_1": {
        "text": "person begin putting on their shoes.",
        "vid": "1HZGH",
        "timestamps": [
            16.7,
            32.2
        ]
    },
    "1HZGH_2": {
        "text": "person proceeds to stand put on a pair of shoes.",
        "vid": "1HZGH",
        "timestamps": [
            16.7,
            32.2
        ]
    },
    "J5K87_0": {
        "text": "a person is laughing on the phone.",
        "vid": "J5K87",
        "timestamps": [
            15.4,
            26.5
        ]
    },
    "J5K87_1": {
        "text": "person drinking a glass of orange juice.",
        "vid": "J5K87",
        "timestamps": [
            7.9,
            14.1
        ]
    },
    "DR1ZU_0": {
        "text": "person turns the light on.",
        "vid": "DR1ZU",
        "timestamps": [
            2.1,
            7.6
        ]
    },
    "DR1ZU_1": {
        "text": "a person is fixing the light near the stairs.",
        "vid": "DR1ZU",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "DR1ZU_2": {
        "text": "a person turns on the light.",
        "vid": "DR1ZU",
        "timestamps": [
            2.1,
            7.6
        ]
    },
    "874F1_0": {
        "text": "the person drinks from a glass.",
        "vid": "874F1",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "QJM3B_0": {
        "text": "person closes the book.",
        "vid": "QJM3B",
        "timestamps": [
            10.1,
            14.4
        ]
    },
    "J6JNK_0": {
        "text": "person closing a wood door.",
        "vid": "J6JNK",
        "timestamps": [
            24.0,
            32.0
        ]
    },
    "J6JNK_1": {
        "text": "a person is awakening with clothes on.",
        "vid": "J6JNK",
        "timestamps": [
            0.9,
            10.8
        ]
    },
    "J6JNK_2": {
        "text": "person closing the door.",
        "vid": "J6JNK",
        "timestamps": [
            24.0,
            32.0
        ]
    },
    "J6JNK_3": {
        "text": "person closing the door next to their bed.",
        "vid": "J6JNK",
        "timestamps": [
            24.0,
            32.0
        ]
    },
    "JVH7Q_0": {
        "text": "the person looks out the window.",
        "vid": "JVH7Q",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "FQM2N_0": {
        "text": "a person sits in a chair.",
        "vid": "FQM2N",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "FQM2N_1": {
        "text": "person sitting on the bed.",
        "vid": "FQM2N",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "21WN7_0": {
        "text": "person put the plate on a table.",
        "vid": "21WN7",
        "timestamps": [
            15.2,
            21.5
        ]
    },
    "21WN7_1": {
        "text": "a person sitting in a chair eating something.",
        "vid": "21WN7",
        "timestamps": [
            2.0,
            16.0
        ]
    },
    "21WN7_2": {
        "text": "a person is sitting on the couch eating food.",
        "vid": "21WN7",
        "timestamps": [
            2.0,
            16.0
        ]
    },
    "21WN7_3": {
        "text": "person eating food.",
        "vid": "21WN7",
        "timestamps": [
            2.0,
            16.0
        ]
    },
    "21WN7_4": {
        "text": "person puts the food on a table.",
        "vid": "21WN7",
        "timestamps": [
            15.4,
            32.1
        ]
    },
    "ECFMO_0": {
        "text": "person closes the door.",
        "vid": "ECFMO",
        "timestamps": [
            23.2,
            30.0
        ]
    },
    "ECFMO_1": {
        "text": "person simultaneously being interrupted by sneezing.",
        "vid": "ECFMO",
        "timestamps": [
            3.1,
            15.5
        ]
    },
    "GIIF8_0": {
        "text": "a person puts a bag on a shelf.",
        "vid": "GIIF8",
        "timestamps": [
            1.2,
            8.0
        ]
    },
    "75M1Z_0": {
        "text": "person sat on the sofa to read a book.",
        "vid": "75M1Z",
        "timestamps": [
            25.9,
            32.0
        ]
    },
    "75M1Z_1": {
        "text": "person sits on the sofa.",
        "vid": "75M1Z",
        "timestamps": [
            23.6,
            29.4
        ]
    },
    "75M1Z_2": {
        "text": "person opens a box with a book.",
        "vid": "75M1Z",
        "timestamps": [
            25.1,
            31.6
        ]
    },
    "75M1Z_3": {
        "text": "person opens the book.",
        "vid": "75M1Z",
        "timestamps": [
            25.1,
            31.6
        ]
    },
    "J3Y7L_0": {
        "text": "a smiling person opens a box.",
        "vid": "J3Y7L",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "J3Y7L_1": {
        "text": "a person opens a box.",
        "vid": "J3Y7L",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "TQYV1_0": {
        "text": "person starts sneezing.",
        "vid": "TQYV1",
        "timestamps": [
            21.1,
            27.2
        ]
    },
    "GKH0F_0": {
        "text": "one person takes a phone from a bag.",
        "vid": "GKH0F",
        "timestamps": [
            23.4,
            34.0
        ]
    },
    "RPY8D_0": {
        "text": "person fixes their hair.",
        "vid": "RPY8D",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "RPY8D_1": {
        "text": "person sitting on a couch.",
        "vid": "RPY8D",
        "timestamps": [
            0.0,
            15.2
        ]
    },
    "UMTLM_0": {
        "text": "person so he is closing the bathroom door.",
        "vid": "UMTLM",
        "timestamps": [
            14.5,
            20.0
        ]
    },
    "UMTLM_1": {
        "text": "person close the door.",
        "vid": "UMTLM",
        "timestamps": [
            14.5,
            20.0
        ]
    },
    "FORXE_0": {
        "text": "person runs around with a bag in their hand.",
        "vid": "FORXE",
        "timestamps": [
            7.6,
            14.3
        ]
    },
    "FORXE_1": {
        "text": "person decides to run with a bag of groceries.",
        "vid": "FORXE",
        "timestamps": [
            7.6,
            14.3
        ]
    },
    "FORXE_2": {
        "text": "a person is throwing a picture on the floor.",
        "vid": "FORXE",
        "timestamps": [
            2.5,
            9.4
        ]
    },
    "3WMV4_0": {
        "text": "a person is eating.",
        "vid": "3WMV4",
        "timestamps": [
            3.1,
            9.1
        ]
    },
    "3WMV4_1": {
        "text": "person eating a snack.",
        "vid": "3WMV4",
        "timestamps": [
            3.1,
            9.1
        ]
    },
    "3WMV4_2": {
        "text": "person drinking a glass of water.",
        "vid": "3WMV4",
        "timestamps": [
            1.5,
            5.6
        ]
    },
    "3WMV4_3": {
        "text": "person eating a sandwich.",
        "vid": "3WMV4",
        "timestamps": [
            3.1,
            9.1
        ]
    },
    "C7G1S_0": {
        "text": "this person washed the dishes over the sink.",
        "vid": "C7G1S",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "3AKML_0": {
        "text": "person takes a box off of a shelf.",
        "vid": "3AKML",
        "timestamps": [
            30.0,
            41.0
        ]
    },
    "NDDHA_0": {
        "text": "person put on shoes.",
        "vid": "NDDHA",
        "timestamps": [
            11.8,
            24.3
        ]
    },
    "NDDHA_1": {
        "text": "person runs out.",
        "vid": "NDDHA",
        "timestamps": [
            20.0,
            26.6
        ]
    },
    "NDDHA_2": {
        "text": "person running out of the room.",
        "vid": "NDDHA",
        "timestamps": [
            20.0,
            26.6
        ]
    },
    "NDDHA_3": {
        "text": "person putting shoes on.",
        "vid": "NDDHA",
        "timestamps": [
            11.8,
            24.3
        ]
    },
    "NDDHA_4": {
        "text": "person puts on some shoes.",
        "vid": "NDDHA",
        "timestamps": [
            11.8,
            24.3
        ]
    },
    "NDDHA_5": {
        "text": "person putting on shoes.",
        "vid": "NDDHA",
        "timestamps": [
            11.8,
            24.3
        ]
    },
    "W8CWW_0": {
        "text": "a person opens a door goes into a room.",
        "vid": "W8CWW",
        "timestamps": [
            16.8,
            30.4
        ]
    },
    "W8CWW_1": {
        "text": "a person opens a door.",
        "vid": "W8CWW",
        "timestamps": [
            16.8,
            30.4
        ]
    },
    "W8CWW_2": {
        "text": "person opens turns doorknob.",
        "vid": "W8CWW",
        "timestamps": [
            16.8,
            30.4
        ]
    },
    "11L5M_0": {
        "text": "person starts running in place.",
        "vid": "11L5M",
        "timestamps": [
            16.4,
            30.0
        ]
    },
    "11L5M_1": {
        "text": "person start running in place.",
        "vid": "11L5M",
        "timestamps": [
            16.4,
            30.0
        ]
    },
    "11L5M_2": {
        "text": "person they throw the broom down.",
        "vid": "11L5M",
        "timestamps": [
            15.5,
            20.4
        ]
    },
    "E6ZBZ_0": {
        "text": "person they start sneezing.",
        "vid": "E6ZBZ",
        "timestamps": [
            10.5,
            17.1
        ]
    },
    "H0L5S_0": {
        "text": "person opens the door.",
        "vid": "H0L5S",
        "timestamps": [
            23.3,
            29.4
        ]
    },
    "H0L5S_1": {
        "text": "person opening the door.",
        "vid": "H0L5S",
        "timestamps": [
            23.3,
            29.4
        ]
    },
    "SW8VM_0": {
        "text": "a smiling person is grasping a pillow.",
        "vid": "SW8VM",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "F19VE_0": {
        "text": "the person takes food from a box.",
        "vid": "F19VE",
        "timestamps": [
            19.5,
            33.8
        ]
    },
    "F19VE_1": {
        "text": "person puts other food away in a cupboard.",
        "vid": "F19VE",
        "timestamps": [
            6.7,
            16.1
        ]
    },
    "44T8B_0": {
        "text": "a person washes their hands in a bathroom.",
        "vid": "44T8B",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "O0349_0": {
        "text": "a person is doing a lot of cooking.",
        "vid": "O0349",
        "timestamps": [
            0.0,
            10.7
        ]
    },
    "O0349_1": {
        "text": "person cooks something.",
        "vid": "O0349",
        "timestamps": [
            0.0,
            10.7
        ]
    },
    "O0349_2": {
        "text": "person so they must open the pantry door.",
        "vid": "O0349",
        "timestamps": [
            8.3,
            13.5
        ]
    },
    "DSZYT_0": {
        "text": "a person drinking from a coffee cup.",
        "vid": "DSZYT",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "DSZYT_1": {
        "text": "person they drink from a glass.",
        "vid": "DSZYT",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "KCRQU_0": {
        "text": "the person opens the refrigerator.",
        "vid": "KCRQU",
        "timestamps": [
            17.2,
            24.3
        ]
    },
    "KCRQU_1": {
        "text": "person they open the refrigerator.",
        "vid": "KCRQU",
        "timestamps": [
            17.2,
            24.3
        ]
    },
    "KCRQU_2": {
        "text": "person opens the refrigerator.",
        "vid": "KCRQU",
        "timestamps": [
            17.2,
            24.3
        ]
    },
    "NBMH9_0": {
        "text": "person opening a door.",
        "vid": "NBMH9",
        "timestamps": [
            6.3,
            12.6
        ]
    },
    "NBMH9_1": {
        "text": "person closes the door.",
        "vid": "NBMH9",
        "timestamps": [
            3.7,
            10.7
        ]
    },
    "NBMH9_2": {
        "text": "person sitting in a chair.",
        "vid": "NBMH9",
        "timestamps": [
            21.4,
            37.6
        ]
    },
    "NBMH9_3": {
        "text": "person closing the door behind them.",
        "vid": "NBMH9",
        "timestamps": [
            3.7,
            10.7
        ]
    },
    "NBMH9_4": {
        "text": "person sits in a chair.",
        "vid": "NBMH9",
        "timestamps": [
            21.4,
            37.6
        ]
    },
    "SW5TC_0": {
        "text": "person laughs at a tv.",
        "vid": "SW5TC",
        "timestamps": [
            13.1,
            18.9
        ]
    },
    "SW5TC_1": {
        "text": "person laughs at the television.",
        "vid": "SW5TC",
        "timestamps": [
            13.1,
            18.9
        ]
    },
    "SW5TC_2": {
        "text": "a person awakens in a bedroom.",
        "vid": "SW5TC",
        "timestamps": [
            10.1,
            17.3
        ]
    },
    "SW5TC_3": {
        "text": "person laughs at the tv.",
        "vid": "SW5TC",
        "timestamps": [
            13.1,
            18.9
        ]
    },
    "G2JR9_0": {
        "text": "a person takes a lightbulb.",
        "vid": "G2JR9",
        "timestamps": [
            20.7,
            25.6
        ]
    },
    "G2JR9_1": {
        "text": "a person tries to put a lightbulb in a fixture.",
        "vid": "G2JR9",
        "timestamps": [
            20.7,
            25.6
        ]
    },
    "G2JR9_2": {
        "text": "person the light turns on.",
        "vid": "G2JR9",
        "timestamps": [
            20.7,
            25.6
        ]
    },
    "G2JR9_3": {
        "text": "person the lightbulb lights up.",
        "vid": "G2JR9",
        "timestamps": [
            20.7,
            25.6
        ]
    },
    "G2JR9_4": {
        "text": "a person fixing a light.",
        "vid": "G2JR9",
        "timestamps": [
            20.7,
            25.6
        ]
    },
    "G2JR9_5": {
        "text": "the person throws some bread on the floor.",
        "vid": "G2JR9",
        "timestamps": [
            24.1,
            30.9
        ]
    },
    "M9NAG_0": {
        "text": "the person walks through the doorway.",
        "vid": "M9NAG",
        "timestamps": [
            21.6,
            28.6
        ]
    },
    "M9NAG_1": {
        "text": "person stretching arms as if awakening.",
        "vid": "M9NAG",
        "timestamps": [
            14.4,
            24.3
        ]
    },
    "MS4GA_0": {
        "text": "a person opens a closet door.",
        "vid": "MS4GA",
        "timestamps": [
            5.4,
            11.5
        ]
    },
    "MS4GA_1": {
        "text": "person puts a broom into the closet.",
        "vid": "MS4GA",
        "timestamps": [
            2.8,
            9.1
        ]
    },
    "MS4GA_2": {
        "text": "a person opens a door.",
        "vid": "MS4GA",
        "timestamps": [
            1.3,
            6.9
        ]
    },
    "MS4GA_3": {
        "text": "person closes the door.",
        "vid": "MS4GA",
        "timestamps": [
            5.4,
            11.5
        ]
    },
    "MS4GA_4": {
        "text": "person puts a broom inside.",
        "vid": "MS4GA",
        "timestamps": [
            2.8,
            9.1
        ]
    },
    "MS4GA_5": {
        "text": "a person opens a door with the doorknob.",
        "vid": "MS4GA",
        "timestamps": [
            1.3,
            6.9
        ]
    },
    "YW5QQ_0": {
        "text": "person closes the door.",
        "vid": "YW5QQ",
        "timestamps": [
            22.9,
            29.7
        ]
    },
    "YW5QQ_1": {
        "text": "the person looks at a picture on the desk.",
        "vid": "YW5QQ",
        "timestamps": [
            8.1,
            21.2
        ]
    },
    "FYHTC_0": {
        "text": "person takes a sip from a glass of water.",
        "vid": "FYHTC",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "FYHTC_1": {
        "text": "person jiggles the doorknob of the closed bathroom door.",
        "vid": "FYHTC",
        "timestamps": [
            1.1,
            9.3
        ]
    },
    "FYHTC_2": {
        "text": "person opens the door.",
        "vid": "FYHTC",
        "timestamps": [
            23.2,
            29.0
        ]
    },
    "FYHTC_3": {
        "text": "person try to open the door.",
        "vid": "FYHTC",
        "timestamps": [
            23.2,
            29.0
        ]
    },
    "FKK5R_0": {
        "text": "the person is sitting in a chair.",
        "vid": "FKK5R",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "FKK5R_1": {
        "text": "person turns on the light.",
        "vid": "FKK5R",
        "timestamps": [
            12.7,
            19.9
        ]
    },
    "FKK5R_2": {
        "text": "person getting up to turn on light.",
        "vid": "FKK5R",
        "timestamps": [
            12.7,
            19.9
        ]
    },
    "FKK5R_3": {
        "text": "person walks over to the lights.",
        "vid": "FKK5R",
        "timestamps": [
            12.7,
            19.9
        ]
    },
    "QYM5H_0": {
        "text": "a person throws a blanket across the room.",
        "vid": "QYM5H",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "QYM5H_1": {
        "text": "person take a picture of the towel.",
        "vid": "QYM5H",
        "timestamps": [
            16.5,
            31.0
        ]
    },
    "QYM5H_2": {
        "text": "a person throws a towel on the floor.",
        "vid": "QYM5H",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "77Z0Z_0": {
        "text": "person opens pantry grabs towel puts it on table.",
        "vid": "77Z0Z",
        "timestamps": [
            3.0,
            12.4
        ]
    },
    "51RLB_0": {
        "text": "the person takes a drink from a water bottle.",
        "vid": "51RLB",
        "timestamps": [
            2.7,
            10.3
        ]
    },
    "3IPI3_0": {
        "text": "a person drinks from a cup.",
        "vid": "3IPI3",
        "timestamps": [
            3.2,
            9.3
        ]
    },
    "3IPI3_1": {
        "text": "the person eats a sandwich.",
        "vid": "3IPI3",
        "timestamps": [
            7.9,
            13.0
        ]
    },
    "L0HDB_0": {
        "text": "person opening a cabinet.",
        "vid": "L0HDB",
        "timestamps": [
            2.6,
            7.8
        ]
    },
    "EZRQW_0": {
        "text": "another person is playing at running back.",
        "vid": "EZRQW",
        "timestamps": [
            11.7,
            22.1
        ]
    },
    "I9CDV_0": {
        "text": "a person is eating a sandwich at the bathroom mirror.",
        "vid": "I9CDV",
        "timestamps": [
            5.2,
            11.0
        ]
    },
    "I9CDV_1": {
        "text": "person takes a picture in the mirror with a camera.",
        "vid": "I9CDV",
        "timestamps": [
            17.2,
            23.8
        ]
    },
    "I9CDV_2": {
        "text": "person takes a picture of himself in the mirror.",
        "vid": "I9CDV",
        "timestamps": [
            17.2,
            23.8
        ]
    },
    "4683D_0": {
        "text": "the person is cleaning off a chair to sit.",
        "vid": "4683D",
        "timestamps": [
            8.7,
            14.9
        ]
    },
    "4683D_1": {
        "text": "person they sit down on a chair.",
        "vid": "4683D",
        "timestamps": [
            8.7,
            14.9
        ]
    },
    "3HRNV_0": {
        "text": "a person is smiling in a study holding a bag.",
        "vid": "3HRNV",
        "timestamps": [
            0.3,
            4.8
        ]
    },
    "K8MZH_0": {
        "text": "a person turns the lights on.",
        "vid": "K8MZH",
        "timestamps": [
            1.7,
            8.0
        ]
    },
    "1TIAK_0": {
        "text": "the person fixes some messy homework papers on the table.",
        "vid": "1TIAK",
        "timestamps": [
            11.4,
            15.8
        ]
    },
    "TJJKK_0": {
        "text": "person eating on the bed.",
        "vid": "TJJKK",
        "timestamps": [
            4.6,
            9.3
        ]
    },
    "TJJKK_1": {
        "text": "the person eats something from off the bed.",
        "vid": "TJJKK",
        "timestamps": [
            4.6,
            9.3
        ]
    },
    "TJJKK_2": {
        "text": "person sitting on a bed with a cell phone.",
        "vid": "TJJKK",
        "timestamps": [
            0.0,
            2.9
        ]
    },
    "TJJKK_3": {
        "text": "person take a picture of the room.",
        "vid": "TJJKK",
        "timestamps": [
            0.3,
            4.7
        ]
    },
    "41F2M_0": {
        "text": "finally the person washes their hands in the sink.",
        "vid": "41F2M",
        "timestamps": [
            11.3,
            22.1
        ]
    },
    "41F2M_1": {
        "text": "this person washer their hands.",
        "vid": "41F2M",
        "timestamps": [
            11.3,
            22.1
        ]
    },
    "41F2M_2": {
        "text": "person puts a book next to a toilet.",
        "vid": "41F2M",
        "timestamps": [
            8.3,
            14.2
        ]
    },
    "SBM3M_0": {
        "text": "person the other is putting shoes in a box.",
        "vid": "SBM3M",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "SBM3M_1": {
        "text": "one person puts shoes in a box.",
        "vid": "SBM3M",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "W0XPU_0": {
        "text": "the person puts the shoes on.",
        "vid": "W0XPU",
        "timestamps": [
            0.3,
            6.5
        ]
    },
    "W0XPU_1": {
        "text": "a person holds a pair of shoes.",
        "vid": "W0XPU",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "W0XPU_2": {
        "text": "person stand up.",
        "vid": "W0XPU",
        "timestamps": [
            19.0,
            24.1
        ]
    },
    "W0XPU_3": {
        "text": "person puts on shoes.",
        "vid": "W0XPU",
        "timestamps": [
            0.3,
            6.5
        ]
    },
    "W0XPU_4": {
        "text": "person eat some food off of a plate.",
        "vid": "W0XPU",
        "timestamps": [
            20.6,
            26.5
        ]
    },
    "87Y64_0": {
        "text": "a person is throwing a book to another person.",
        "vid": "87Y64",
        "timestamps": [
            6.5,
            13.5
        ]
    },
    "87Y64_1": {
        "text": "person run to the other side of the room.",
        "vid": "87Y64",
        "timestamps": [
            0.4,
            6.1
        ]
    },
    "87Y64_2": {
        "text": "a person is sitting on a bed.",
        "vid": "87Y64",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "ZQKVY_0": {
        "text": "a person runs into the bedroom.",
        "vid": "ZQKVY",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "2Y8XQ_0": {
        "text": "person he pours something into a glass.",
        "vid": "2Y8XQ",
        "timestamps": [
            4.5,
            11.8
        ]
    },
    "2Y8XQ_1": {
        "text": "a person pours some water in a glass.",
        "vid": "2Y8XQ",
        "timestamps": [
            4.5,
            11.8
        ]
    },
    "2Y8XQ_2": {
        "text": "the person is sneezing.",
        "vid": "2Y8XQ",
        "timestamps": [
            23.2,
            31.2
        ]
    },
    "2Y8XQ_3": {
        "text": "person drinking glass.",
        "vid": "2Y8XQ",
        "timestamps": [
            15.2,
            22.8
        ]
    },
    "JR6VG_0": {
        "text": "a person goes running by.",
        "vid": "JR6VG",
        "timestamps": [
            12.0,
            17.9
        ]
    },
    "JR6VG_1": {
        "text": "person as the door opens.",
        "vid": "JR6VG",
        "timestamps": [
            8.0,
            15.1
        ]
    },
    "JR6VG_2": {
        "text": "person the door opens.",
        "vid": "JR6VG",
        "timestamps": [
            8.0,
            15.1
        ]
    },
    "JR6VG_3": {
        "text": "another person runs into the room.",
        "vid": "JR6VG",
        "timestamps": [
            12.0,
            17.9
        ]
    },
    "AAQHJ_0": {
        "text": "a person is seen eating.",
        "vid": "AAQHJ",
        "timestamps": [
            4.3,
            16.7
        ]
    },
    "AAQHJ_1": {
        "text": "a person is sitting on a chair.",
        "vid": "AAQHJ",
        "timestamps": [
            5.7,
            15.0
        ]
    },
    "AAQHJ_2": {
        "text": "a person eating something off of a plate.",
        "vid": "AAQHJ",
        "timestamps": [
            4.3,
            16.7
        ]
    },
    "AAQHJ_3": {
        "text": "person grab a pillow to snuggle with.",
        "vid": "AAQHJ",
        "timestamps": [
            16.4,
            26.7
        ]
    },
    "AAQHJ_4": {
        "text": "a person sits in a chair eating.",
        "vid": "AAQHJ",
        "timestamps": [
            4.3,
            16.7
        ]
    },
    "AAQHJ_5": {
        "text": "person holding a pillow.",
        "vid": "AAQHJ",
        "timestamps": [
            0.8,
            11.9
        ]
    },
    "AAQHJ_6": {
        "text": "person eating from a plate of food.",
        "vid": "AAQHJ",
        "timestamps": [
            4.3,
            16.7
        ]
    },
    "GG3K5_0": {
        "text": "person watches the television.",
        "vid": "GG3K5",
        "timestamps": [
            19.5,
            31.0
        ]
    },
    "GG3K5_1": {
        "text": "the person start watching television.",
        "vid": "GG3K5",
        "timestamps": [
            19.5,
            31.0
        ]
    },
    "GG3K5_2": {
        "text": "person watches television.",
        "vid": "GG3K5",
        "timestamps": [
            19.5,
            31.0
        ]
    },
    "GG3K5_3": {
        "text": "person sits on the edge of the bed.",
        "vid": "GG3K5",
        "timestamps": [
            15.3,
            24.6
        ]
    },
    "1XBU2_0": {
        "text": "person is drinking tea from glass mug.",
        "vid": "1XBU2",
        "timestamps": [
            4.3,
            10.9
        ]
    },
    "LLQBB_0": {
        "text": "the person throws the bag down.",
        "vid": "LLQBB",
        "timestamps": [
            13.8,
            21.5
        ]
    },
    "LLQBB_1": {
        "text": "person finally laughing to themselves.",
        "vid": "LLQBB",
        "timestamps": [
            26.1,
            33.0
        ]
    },
    "LLQBB_2": {
        "text": "the person starts laughing as they put the bag down.",
        "vid": "LLQBB",
        "timestamps": [
            26.1,
            33.0
        ]
    },
    "LLQBB_3": {
        "text": "person takes their shoes off.",
        "vid": "LLQBB",
        "timestamps": [
            17.0,
            30.7
        ]
    },
    "LLQBB_4": {
        "text": "a person is holding a bag.",
        "vid": "LLQBB",
        "timestamps": [
            12.0,
            21.7
        ]
    },
    "LLQBB_5": {
        "text": "person take off their shoes.",
        "vid": "LLQBB",
        "timestamps": [
            17.0,
            30.7
        ]
    },
    "BB7WL_0": {
        "text": "a person opens a cabinet.",
        "vid": "BB7WL",
        "timestamps": [
            0.3,
            5.7
        ]
    },
    "ZX37G_0": {
        "text": "the person puts the laptop down on the table.",
        "vid": "ZX37G",
        "timestamps": [
            1.8,
            7.8
        ]
    },
    "RX7TC_0": {
        "text": "a person is eating some food.",
        "vid": "RX7TC",
        "timestamps": [
            0.0,
            11.5
        ]
    },
    "RX7TC_1": {
        "text": "person takes several bites of an unknown food item.",
        "vid": "RX7TC",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "GFK4S_0": {
        "text": "person opens the door.",
        "vid": "GFK4S",
        "timestamps": [
            14.1,
            20.6
        ]
    },
    "GFK4S_1": {
        "text": "person holding a pillow.",
        "vid": "GFK4S",
        "timestamps": [
            0.0,
            13.5
        ]
    },
    "H5CJD_0": {
        "text": "person closes the fridge door.",
        "vid": "H5CJD",
        "timestamps": [
            19.3,
            25.7
        ]
    },
    "F5UVQ_0": {
        "text": "person that turn off the lights.",
        "vid": "F5UVQ",
        "timestamps": [
            32.1,
            38.0
        ]
    },
    "F5UVQ_1": {
        "text": "person wash their hands a little bit.",
        "vid": "F5UVQ",
        "timestamps": [
            23.5,
            38.0
        ]
    },
    "F5UVQ_2": {
        "text": "person turn off a light.",
        "vid": "F5UVQ",
        "timestamps": [
            32.1,
            38.0
        ]
    },
    "MSACP_0": {
        "text": "person they take the batteries out of the camera.",
        "vid": "MSACP",
        "timestamps": [
            0.0,
            2.8
        ]
    },
    "VIN5T_0": {
        "text": "a person is sitting on the floor throwing a pillow.",
        "vid": "VIN5T",
        "timestamps": [
            2.0,
            8.8
        ]
    },
    "D1WYU_0": {
        "text": "the person takes off their shoes.",
        "vid": "D1WYU",
        "timestamps": [
            22.6,
            29.9
        ]
    },
    "D1WYU_1": {
        "text": "person sits down on a chair.",
        "vid": "D1WYU",
        "timestamps": [
            16.9,
            31.0
        ]
    },
    "D1WYU_2": {
        "text": "the person sits down in a chair.",
        "vid": "D1WYU",
        "timestamps": [
            16.9,
            31.0
        ]
    },
    "D1WYU_3": {
        "text": "person takes their shoes off.",
        "vid": "D1WYU",
        "timestamps": [
            22.6,
            29.9
        ]
    },
    "D1WYU_4": {
        "text": "a person is holding a bag walk to a bed.",
        "vid": "D1WYU",
        "timestamps": [
            0.0,
            7.5
        ]
    },
    "IONV9_0": {
        "text": "a laughing person is drinking soda in their basement.",
        "vid": "IONV9",
        "timestamps": [
            4.1,
            9.3
        ]
    },
    "IONV9_1": {
        "text": "person continuing to drink from the bottle.",
        "vid": "IONV9",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "IONV9_2": {
        "text": "person drinking from a glass of water.",
        "vid": "IONV9",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "IDXZK_0": {
        "text": "person eating food from a dish.",
        "vid": "IDXZK",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "IDXZK_1": {
        "text": "person eating a sandwich.",
        "vid": "IDXZK",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "79VVK_0": {
        "text": "person run out of the closet.",
        "vid": "79VVK",
        "timestamps": [
            30.9,
            37.5
        ]
    },
    "79VVK_1": {
        "text": "a person takes a blanket.",
        "vid": "79VVK",
        "timestamps": [
            15.1,
            20.4
        ]
    },
    "YACA8_0": {
        "text": "person putting clothes.",
        "vid": "YACA8",
        "timestamps": [
            3.4,
            11.8
        ]
    },
    "VG7S6_0": {
        "text": "person takes a vacuum.",
        "vid": "VG7S6",
        "timestamps": [
            12.5,
            21.0
        ]
    },
    "VG7S6_1": {
        "text": "person sneezing constantly.",
        "vid": "VG7S6",
        "timestamps": [
            0.9,
            10.8
        ]
    },
    "C46TD_0": {
        "text": "person looks out the window above the sink.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "C46TD_1": {
        "text": "the person washes their hands at the kitchen sink.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            12.1
        ]
    },
    "C46TD_2": {
        "text": "person continuing to look out the window.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "C46TD_3": {
        "text": "a person is washing their hands in the sink.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            12.1
        ]
    },
    "C46TD_4": {
        "text": "a person washes their hands in the kitchen sink.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            12.1
        ]
    },
    "C46TD_5": {
        "text": "person looking out the window.",
        "vid": "C46TD",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "9J0RB_0": {
        "text": "a person is standing in a room watching television.",
        "vid": "9J0RB",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "9J0RB_1": {
        "text": "person drinking something from a glass.",
        "vid": "9J0RB",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "9J0RB_2": {
        "text": "person drinking a glass of milk.",
        "vid": "9J0RB",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "9J0RB_3": {
        "text": "a person is watching a television in their bedroom.",
        "vid": "9J0RB",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "9J0RB_4": {
        "text": "person throws the pillow to the side.",
        "vid": "9J0RB",
        "timestamps": [
            7.7,
            14.6
        ]
    },
    "ZIP18_0": {
        "text": "person eat a sandwich.",
        "vid": "ZIP18",
        "timestamps": [
            25.2,
            31.8
        ]
    },
    "ZIP18_1": {
        "text": "a person turns on a light.",
        "vid": "ZIP18",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "ZIP18_2": {
        "text": "a person turns on a light in their bedroom.",
        "vid": "ZIP18",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "ZIP18_3": {
        "text": "person turns on the light.",
        "vid": "ZIP18",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "ZIP18_4": {
        "text": "person sit on their bed.",
        "vid": "ZIP18",
        "timestamps": [
            21.1,
            26.2
        ]
    },
    "3N1I2_0": {
        "text": "the person puts the sandwich into the refrigerator.",
        "vid": "3N1I2",
        "timestamps": [
            7.9,
            15.1
        ]
    },
    "337O2_0": {
        "text": "person they put them down on the table.",
        "vid": "337O2",
        "timestamps": [
            0.2,
            6.2
        ]
    },
    "LE7PM_0": {
        "text": "person throws some food onto the table.",
        "vid": "LE7PM",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "VJ0LT_0": {
        "text": "person closing the front door.",
        "vid": "VJ0LT",
        "timestamps": [
            23.1,
            33.0
        ]
    },
    "VJ0LT_1": {
        "text": "person pours it into a glass.",
        "vid": "VJ0LT",
        "timestamps": [
            2.5,
            13.4
        ]
    },
    "VJ0LT_2": {
        "text": "person pours a glass of soda.",
        "vid": "VJ0LT",
        "timestamps": [
            2.5,
            13.4
        ]
    },
    "VJ0LT_3": {
        "text": "the person drinks the coke from the glass.",
        "vid": "VJ0LT",
        "timestamps": [
            12.9,
            21.4
        ]
    },
    "VJ0LT_4": {
        "text": "person closes a door outside.",
        "vid": "VJ0LT",
        "timestamps": [
            23.1,
            33.0
        ]
    },
    "TCI7K_0": {
        "text": "person put a item on the table.",
        "vid": "TCI7K",
        "timestamps": [
            3.6,
            10.3
        ]
    },
    "QE4YE_0": {
        "text": "a person is opening a bag.",
        "vid": "QE4YE",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "QE4YE_1": {
        "text": "the person puts the bag on a counter.",
        "vid": "QE4YE",
        "timestamps": [
            4.2,
            9.7
        ]
    },
    "XO8NL_0": {
        "text": "a person throws a pillow into a closet.",
        "vid": "XO8NL",
        "timestamps": [
            3.6,
            12.5
        ]
    },
    "XO8NL_1": {
        "text": "a person is holding a pillow.",
        "vid": "XO8NL",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "XO8NL_2": {
        "text": "the person throws the pillow into the closet.",
        "vid": "XO8NL",
        "timestamps": [
            3.6,
            12.5
        ]
    },
    "CM6T8_0": {
        "text": "a person is opening their closet looking for a sandwich.",
        "vid": "CM6T8",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "CM6T8_1": {
        "text": "a person opens a door to a closet.",
        "vid": "CM6T8",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "CM6T8_2": {
        "text": "person open up the door.",
        "vid": "CM6T8",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "QI0EL_0": {
        "text": "person watches television.",
        "vid": "QI0EL",
        "timestamps": [
            23.5,
            32.0
        ]
    },
    "QI0EL_1": {
        "text": "person closes the laptop.",
        "vid": "QI0EL",
        "timestamps": [
            18.2,
            22.8
        ]
    },
    "ICQUJ_0": {
        "text": "person starts eating some food.",
        "vid": "ICQUJ",
        "timestamps": [
            14.4,
            22.0
        ]
    },
    "ICQUJ_1": {
        "text": "person pick up a sandwich to eat.",
        "vid": "ICQUJ",
        "timestamps": [
            14.4,
            22.0
        ]
    },
    "I87SH_0": {
        "text": "a person awakens on the floor of their home office.",
        "vid": "I87SH",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "I87SH_1": {
        "text": "person walk near the window open the curtain.",
        "vid": "I87SH",
        "timestamps": [
            18.8,
            32.0
        ]
    },
    "I87SH_2": {
        "text": "the person is laying on the floor.",
        "vid": "I87SH",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "I87SH_3": {
        "text": "person opens the window.",
        "vid": "I87SH",
        "timestamps": [
            18.8,
            32.0
        ]
    },
    "I87SH_4": {
        "text": "person opens a curtain to look out the window.",
        "vid": "I87SH",
        "timestamps": [
            18.8,
            32.0
        ]
    },
    "BDY1V_0": {
        "text": "one person undresses in front of a wardrobe.",
        "vid": "BDY1V",
        "timestamps": [
            3.7,
            19.0
        ]
    },
    "BDY1V_1": {
        "text": "person takes a pillow from the closet.",
        "vid": "BDY1V",
        "timestamps": [
            20.3,
            26.3
        ]
    },
    "BDY1V_2": {
        "text": "person snuggles the pillow.",
        "vid": "BDY1V",
        "timestamps": [
            25.0,
            32.0
        ]
    },
    "AFCDN_0": {
        "text": "person takes a picture of something.",
        "vid": "AFCDN",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "AFCDN_1": {
        "text": "person eats it.",
        "vid": "AFCDN",
        "timestamps": [
            24.9,
            30.0
        ]
    },
    "AFCDN_2": {
        "text": "person began to eat.",
        "vid": "AFCDN",
        "timestamps": [
            24.9,
            30.0
        ]
    },
    "KA09C_0": {
        "text": "the person turns the light off.",
        "vid": "KA09C",
        "timestamps": [
            27.2,
            32.0
        ]
    },
    "KA09C_1": {
        "text": "person turning off the light.",
        "vid": "KA09C",
        "timestamps": [
            27.2,
            32.0
        ]
    },
    "KA09C_2": {
        "text": "person turns off the light.",
        "vid": "KA09C",
        "timestamps": [
            27.2,
            32.0
        ]
    },
    "KA09C_3": {
        "text": "the person turns off the light.",
        "vid": "KA09C",
        "timestamps": [
            27.2,
            32.0
        ]
    },
    "CUSTU_0": {
        "text": "person opens a laptop.",
        "vid": "CUSTU",
        "timestamps": [
            29.4,
            35.0
        ]
    },
    "CUSTU_1": {
        "text": "person opening a laptop.",
        "vid": "CUSTU",
        "timestamps": [
            29.4,
            35.0
        ]
    },
    "CUSTU_2": {
        "text": "the person puts the broom down.",
        "vid": "CUSTU",
        "timestamps": [
            24.4,
            30.3
        ]
    },
    "Q38XP_0": {
        "text": "person eating food.",
        "vid": "Q38XP",
        "timestamps": [
            6.7,
            18.9
        ]
    },
    "SLHDI_0": {
        "text": "person eating something.",
        "vid": "SLHDI",
        "timestamps": [
            21.6,
            26.1
        ]
    },
    "SLHDI_1": {
        "text": "a person by the refrigerator was eating.",
        "vid": "SLHDI",
        "timestamps": [
            21.6,
            26.1
        ]
    },
    "SLHDI_2": {
        "text": "person opening the refrigerator doors.",
        "vid": "SLHDI",
        "timestamps": [
            2.8,
            12.4
        ]
    },
    "SLHDI_3": {
        "text": "a person is closing a door.",
        "vid": "SLHDI",
        "timestamps": [
            1.1,
            6.3
        ]
    },
    "SLHDI_4": {
        "text": "person sneezing into a towel.",
        "vid": "SLHDI",
        "timestamps": [
            26.4,
            31.9
        ]
    },
    "SLHDI_5": {
        "text": "person opens refrigerator.",
        "vid": "SLHDI",
        "timestamps": [
            2.8,
            12.4
        ]
    },
    "SLHDI_6": {
        "text": "person sneezing on a towel.",
        "vid": "SLHDI",
        "timestamps": [
            26.4,
            31.9
        ]
    },
    "XKU2U_0": {
        "text": "a person is sneezing as they dust a nearby mirror.",
        "vid": "XKU2U",
        "timestamps": [
            9.0,
            16.4
        ]
    },
    "XKU2U_1": {
        "text": "person throws the bag.",
        "vid": "XKU2U",
        "timestamps": [
            19.2,
            26.5
        ]
    },
    "XKU2U_2": {
        "text": "person puts it on a table.",
        "vid": "XKU2U",
        "timestamps": [
            19.2,
            26.5
        ]
    },
    "XKU2U_3": {
        "text": "person they begin to put a bag on the table.",
        "vid": "XKU2U",
        "timestamps": [
            19.2,
            26.5
        ]
    },
    "ULD0T_0": {
        "text": "person holding a bag.",
        "vid": "ULD0T",
        "timestamps": [
            5.0,
            14.3
        ]
    },
    "ULD0T_1": {
        "text": "a person walks through a doorway.",
        "vid": "ULD0T",
        "timestamps": [
            0.0,
            2.8
        ]
    },
    "SLT0S_0": {
        "text": "a person is looking in a book holding a pen.",
        "vid": "SLT0S",
        "timestamps": [
            6.9,
            13.0
        ]
    },
    "J3RP9_0": {
        "text": "a person walks through a doorway.",
        "vid": "J3RP9",
        "timestamps": [
            4.6,
            16.7
        ]
    },
    "BI6Y4_0": {
        "text": "a person is cooking something on the stove.",
        "vid": "BI6Y4",
        "timestamps": [
            0.1,
            5.1
        ]
    },
    "BI6Y4_1": {
        "text": "person drinks out of a cup.",
        "vid": "BI6Y4",
        "timestamps": [
            4.6,
            9.8
        ]
    },
    "BI6Y4_2": {
        "text": "person sits down at the table.",
        "vid": "BI6Y4",
        "timestamps": [
            25.3,
            33.1
        ]
    },
    "BI6Y4_3": {
        "text": "person sits on the chair at the dining table.",
        "vid": "BI6Y4",
        "timestamps": [
            25.3,
            33.1
        ]
    },
    "BI6Y4_4": {
        "text": "person cooking at the stove.",
        "vid": "BI6Y4",
        "timestamps": [
            0.1,
            5.1
        ]
    },
    "735W9_0": {
        "text": "person putting a blanket on the table.",
        "vid": "735W9",
        "timestamps": [
            16.8,
            23.8
        ]
    },
    "735W9_1": {
        "text": "person puts it on the table.",
        "vid": "735W9",
        "timestamps": [
            16.8,
            23.8
        ]
    },
    "1FIGA_0": {
        "text": "person puts it onto the shelf.",
        "vid": "1FIGA",
        "timestamps": [
            14.3,
            21.9
        ]
    },
    "1FIGA_1": {
        "text": "the person closes the box.",
        "vid": "1FIGA",
        "timestamps": [
            9.6,
            15.1
        ]
    },
    "1FIGA_2": {
        "text": "person put something in it closes the door.",
        "vid": "1FIGA",
        "timestamps": [
            18.1,
            24.9
        ]
    },
    "1FIGA_3": {
        "text": "person closes the door.",
        "vid": "1FIGA",
        "timestamps": [
            18.1,
            24.9
        ]
    },
    "1FIGA_4": {
        "text": "person puts the book inside.",
        "vid": "1FIGA",
        "timestamps": [
            15.5,
            23.7
        ]
    },
    "1FIGA_5": {
        "text": "person takes it to a cabinet they open the cabinet.",
        "vid": "1FIGA",
        "timestamps": [
            11.8,
            21.2
        ]
    },
    "1FIGA_6": {
        "text": "a person runs into the closet with a box.",
        "vid": "1FIGA",
        "timestamps": [
            9.6,
            15.1
        ]
    },
    "LZ2Y4_0": {
        "text": "person runs to the kitchen.",
        "vid": "LZ2Y4",
        "timestamps": [
            11.8,
            20.1
        ]
    },
    "LZ2Y4_1": {
        "text": "person begin running around.",
        "vid": "LZ2Y4",
        "timestamps": [
            11.8,
            20.1
        ]
    },
    "LZ2Y4_2": {
        "text": "person runs out of the couch.",
        "vid": "LZ2Y4",
        "timestamps": [
            11.8,
            20.1
        ]
    },
    "LZ2Y4_3": {
        "text": "the person puts the cup down.",
        "vid": "LZ2Y4",
        "timestamps": [
            10.0,
            15.5
        ]
    },
    "M4Z0M_0": {
        "text": "a person walks by eating a sandwich.",
        "vid": "M4Z0M",
        "timestamps": [
            0.7,
            8.4
        ]
    },
    "M4Z0M_1": {
        "text": "a person is eating a sandwich in a hallway.",
        "vid": "M4Z0M",
        "timestamps": [
            0.7,
            8.4
        ]
    },
    "YPRUL_0": {
        "text": "person takes a drink from a glass.",
        "vid": "YPRUL",
        "timestamps": [
            22.1,
            32.0
        ]
    },
    "YPRUL_1": {
        "text": "a person is sneezing.",
        "vid": "YPRUL",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "YPRUL_2": {
        "text": "the person closes the door.",
        "vid": "YPRUL",
        "timestamps": [
            15.5,
            26.7
        ]
    },
    "YPRUL_3": {
        "text": "person closes a door.",
        "vid": "YPRUL",
        "timestamps": [
            15.5,
            26.7
        ]
    },
    "K7NRW_0": {
        "text": "another person tries to fix a loose doorknob.",
        "vid": "K7NRW",
        "timestamps": [
            13.2,
            23.7
        ]
    },
    "K7NRW_1": {
        "text": "person eating it.",
        "vid": "K7NRW",
        "timestamps": [
            5.8,
            14.9
        ]
    },
    "K7NRW_2": {
        "text": "person the other continues to eat.",
        "vid": "K7NRW",
        "timestamps": [
            5.8,
            14.9
        ]
    },
    "K7NRW_3": {
        "text": "person eats a sandwich out of a bag.",
        "vid": "K7NRW",
        "timestamps": [
            5.8,
            14.9
        ]
    },
    "K7NRW_4": {
        "text": "another person is fixing a doorknob.",
        "vid": "K7NRW",
        "timestamps": [
            13.2,
            23.7
        ]
    },
    "K7NRW_5": {
        "text": "the eating man watches his friend fix the door.",
        "vid": "K7NRW",
        "timestamps": [
            5.8,
            14.9
        ]
    },
    "K7NRW_6": {
        "text": "a person opens a bag.",
        "vid": "K7NRW",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "KZS5M_0": {
        "text": "person eats some food.",
        "vid": "KZS5M",
        "timestamps": [
            22.0,
            36.8
        ]
    },
    "KZS5M_1": {
        "text": "person eating something.",
        "vid": "KZS5M",
        "timestamps": [
            22.0,
            36.8
        ]
    },
    "KZS5M_2": {
        "text": "watches the tv as the person eats a sandwich.",
        "vid": "KZS5M",
        "timestamps": [
            23.3,
            34.3
        ]
    },
    "KZS5M_3": {
        "text": "person closes the door.",
        "vid": "KZS5M",
        "timestamps": [
            2.1,
            8.5
        ]
    },
    "KZS5M_4": {
        "text": "person turning the light on.",
        "vid": "KZS5M",
        "timestamps": [
            7.3,
            14.9
        ]
    },
    "KZS5M_5": {
        "text": "person closing the door.",
        "vid": "KZS5M",
        "timestamps": [
            2.1,
            8.5
        ]
    },
    "DO48Z_0": {
        "text": "a person is smiling.",
        "vid": "DO48Z",
        "timestamps": [
            0.8,
            9.0
        ]
    },
    "DO48Z_1": {
        "text": "person putting their shoes in a closet.",
        "vid": "DO48Z",
        "timestamps": [
            4.7,
            17.9
        ]
    },
    "DO48Z_2": {
        "text": "the person was smiling.",
        "vid": "DO48Z",
        "timestamps": [
            0.8,
            9.0
        ]
    },
    "DO48Z_3": {
        "text": "person putting shoes on the shelf.",
        "vid": "DO48Z",
        "timestamps": [
            5.7,
            16.4
        ]
    },
    "JNK11_0": {
        "text": "person puts something onto a shelf.",
        "vid": "JNK11",
        "timestamps": [
            1.8,
            7.3
        ]
    },
    "JNK11_1": {
        "text": "a person puts a cup of coffee on the shelf.",
        "vid": "JNK11",
        "timestamps": [
            1.8,
            7.3
        ]
    },
    "TH3M0_0": {
        "text": "person sits on a chair.",
        "vid": "TH3M0",
        "timestamps": [
            18.8,
            25.8
        ]
    },
    "TH3M0_1": {
        "text": "a person opens a door.",
        "vid": "TH3M0",
        "timestamps": [
            0.0,
            4.7
        ]
    },
    "TH3M0_2": {
        "text": "the person sits down in a chair.",
        "vid": "TH3M0",
        "timestamps": [
            18.8,
            25.8
        ]
    },
    "TH3M0_3": {
        "text": "person takes out a broom from a cabinet.",
        "vid": "TH3M0",
        "timestamps": [
            14.5,
            19.3
        ]
    },
    "TH3M0_4": {
        "text": "person put the broom back into the cabinet.",
        "vid": "TH3M0",
        "timestamps": [
            24.5,
            32.2
        ]
    },
    "TH3M0_5": {
        "text": "person sits down in chair.",
        "vid": "TH3M0",
        "timestamps": [
            18.8,
            25.8
        ]
    },
    "2B577_0": {
        "text": "person puts it on a table.",
        "vid": "2B577",
        "timestamps": [
            19.4,
            32.0
        ]
    },
    "2B577_1": {
        "text": "a person cooks on the stove.",
        "vid": "2B577",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "JXTAD_0": {
        "text": "a person is holding a blanket.",
        "vid": "JXTAD",
        "timestamps": [
            17.8,
            34.0
        ]
    },
    "JXTAD_1": {
        "text": "person turning off the light.",
        "vid": "JXTAD",
        "timestamps": [
            23.8,
            34.0
        ]
    },
    "5R7VN_0": {
        "text": "person closing a door on the stairs.",
        "vid": "5R7VN",
        "timestamps": [
            7.1,
            14.2
        ]
    },
    "5R7VN_1": {
        "text": "person closing a door.",
        "vid": "5R7VN",
        "timestamps": [
            7.1,
            14.2
        ]
    },
    "5R7VN_2": {
        "text": "person closing the door.",
        "vid": "5R7VN",
        "timestamps": [
            7.1,
            14.2
        ]
    },
    "5R7VN_3": {
        "text": "the person is throwing shoes.",
        "vid": "5R7VN",
        "timestamps": [
            0.9,
            10.7
        ]
    },
    "5R7VN_4": {
        "text": "a person throws two shoes down the stairs.",
        "vid": "5R7VN",
        "timestamps": [
            0.9,
            10.7
        ]
    },
    "N56QO_0": {
        "text": "person the individual takes a drink from a coffee cup.",
        "vid": "N56QO",
        "timestamps": [
            0.8,
            5.6
        ]
    },
    "N56QO_1": {
        "text": "a person is playing on their laptop.",
        "vid": "N56QO",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "1RD2K_0": {
        "text": "another person comes running in.",
        "vid": "1RD2K",
        "timestamps": [
            1.0,
            8.6
        ]
    },
    "1RD2K_1": {
        "text": "a person closes the door to a house.",
        "vid": "1RD2K",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "TKAUR_0": {
        "text": "person takes a cup of coffee off of the counter.",
        "vid": "TKAUR",
        "timestamps": [
            3.2,
            8.9
        ]
    },
    "TKAUR_1": {
        "text": "person reads a book.",
        "vid": "TKAUR",
        "timestamps": [
            0.0,
            18.7
        ]
    },
    "TKAUR_2": {
        "text": "person reading a book.",
        "vid": "TKAUR",
        "timestamps": [
            0.0,
            18.7
        ]
    },
    "TKAUR_3": {
        "text": "person start dressing for the weather.",
        "vid": "TKAUR",
        "timestamps": [
            27.0,
            40.3
        ]
    },
    "TKAUR_4": {
        "text": "person begins to dress.",
        "vid": "TKAUR",
        "timestamps": [
            27.0,
            40.3
        ]
    },
    "TKAUR_5": {
        "text": "person puts the book down.",
        "vid": "TKAUR",
        "timestamps": [
            14.9,
            19.7
        ]
    },
    "TKAUR_6": {
        "text": "a person reads a book.",
        "vid": "TKAUR",
        "timestamps": [
            0.0,
            18.7
        ]
    },
    "W7EDM_0": {
        "text": "person sits on the bed.",
        "vid": "W7EDM",
        "timestamps": [
            0.4,
            5.2
        ]
    },
    "W7EDM_1": {
        "text": "a person sits on a bed.",
        "vid": "W7EDM",
        "timestamps": [
            0.4,
            5.2
        ]
    },
    "W7EDM_2": {
        "text": "person eats some food.",
        "vid": "W7EDM",
        "timestamps": [
            11.6,
            17.6
        ]
    },
    "W7EDM_3": {
        "text": "a person sits down on a bed.",
        "vid": "W7EDM",
        "timestamps": [
            0.4,
            5.2
        ]
    },
    "W7EDM_4": {
        "text": "person takes off their shoes.",
        "vid": "W7EDM",
        "timestamps": [
            0.8,
            9.1
        ]
    },
    "HSKVH_0": {
        "text": "person turning off a light.",
        "vid": "HSKVH",
        "timestamps": [
            9.2,
            13.5
        ]
    },
    "HSKVH_1": {
        "text": "a person is closing the door.",
        "vid": "HSKVH",
        "timestamps": [
            4.0,
            10.3
        ]
    },
    "TQO6O_0": {
        "text": "the person takes some paper.",
        "vid": "TQO6O",
        "timestamps": [
            15.7,
            25.2
        ]
    },
    "P0CET_0": {
        "text": "a person takes some clothes from a closet.",
        "vid": "P0CET",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "OEM65_0": {
        "text": "a person is sneezing.",
        "vid": "OEM65",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "B6XQZ_0": {
        "text": "person they laugh at something on the screen.",
        "vid": "B6XQZ",
        "timestamps": [
            3.1,
            17.9
        ]
    },
    "B6XQZ_1": {
        "text": "person laughs to themselves multiple times.",
        "vid": "B6XQZ",
        "timestamps": [
            3.1,
            17.9
        ]
    },
    "G2DIN_0": {
        "text": "person puts a box on the closet shelf.",
        "vid": "G2DIN",
        "timestamps": [
            6.6,
            15.5
        ]
    },
    "G2DIN_1": {
        "text": "person takes some clothes out.",
        "vid": "G2DIN",
        "timestamps": [
            23.1,
            33.0
        ]
    },
    "G2DIN_2": {
        "text": "person puts a box of medicine on the shelf.",
        "vid": "G2DIN",
        "timestamps": [
            6.6,
            15.5
        ]
    },
    "G2DIN_3": {
        "text": "a person opens the closet door.",
        "vid": "G2DIN",
        "timestamps": [
            11.5,
            18.8
        ]
    },
    "3LN8C_0": {
        "text": "person take off shoes.",
        "vid": "3LN8C",
        "timestamps": [
            23.0,
            31.9
        ]
    },
    "3LN8C_1": {
        "text": "person they take off their shoes.",
        "vid": "3LN8C",
        "timestamps": [
            23.0,
            31.9
        ]
    },
    "3LN8C_2": {
        "text": "person take off their shoes.",
        "vid": "3LN8C",
        "timestamps": [
            23.0,
            31.9
        ]
    },
    "B0XI9_0": {
        "text": "person they begin drinking the glass of water.",
        "vid": "B0XI9",
        "timestamps": [
            10.7,
            20.9
        ]
    },
    "B0XI9_1": {
        "text": "a person is running across a room.",
        "vid": "B0XI9",
        "timestamps": [
            0.2,
            8.2
        ]
    },
    "B0XI9_2": {
        "text": "a person in their bedroom is running towards their cabinet.",
        "vid": "B0XI9",
        "timestamps": [
            0.2,
            8.2
        ]
    },
    "B0XI9_3": {
        "text": "person start sneezing.",
        "vid": "B0XI9",
        "timestamps": [
            18.6,
            33.0
        ]
    },
    "V8IGX_0": {
        "text": "person sit on the sofa.",
        "vid": "V8IGX",
        "timestamps": [
            20.2,
            28.0
        ]
    },
    "V8IGX_1": {
        "text": "a person is sneezing as the person opens the door.",
        "vid": "V8IGX",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "V8IGX_2": {
        "text": "person walks through the doorway with a bag.",
        "vid": "V8IGX",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "V8IGX_3": {
        "text": "person proceeds to sit down on the couch.",
        "vid": "V8IGX",
        "timestamps": [
            20.2,
            28.0
        ]
    },
    "V8IGX_4": {
        "text": "person begins sitting on the sofa.",
        "vid": "V8IGX",
        "timestamps": [
            20.2,
            28.0
        ]
    },
    "TCJCJ_0": {
        "text": "a person throws a book on the sofa.",
        "vid": "TCJCJ",
        "timestamps": [
            4.8,
            10.5
        ]
    },
    "TCJCJ_1": {
        "text": "a person reads a book.",
        "vid": "TCJCJ",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "J59UP_0": {
        "text": "a person sits in a chair.",
        "vid": "J59UP",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "J59UP_1": {
        "text": "person sitting in a chair gets up.",
        "vid": "J59UP",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "Z3H4P_0": {
        "text": "person puts some food on a plate.",
        "vid": "Z3H4P",
        "timestamps": [
            20.0,
            29.6
        ]
    },
    "W65SM_0": {
        "text": "a person is sitting a pouring water into a glass.",
        "vid": "W65SM",
        "timestamps": [
            5.7,
            16.2
        ]
    },
    "BIQGN_0": {
        "text": "a person is smiling.",
        "vid": "BIQGN",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "BIQGN_1": {
        "text": "person closes the door.",
        "vid": "BIQGN",
        "timestamps": [
            12.5,
            17.8
        ]
    },
    "BIQGN_2": {
        "text": "a smiling person walks into a bathroom.",
        "vid": "BIQGN",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "BIQGN_3": {
        "text": "the person puts a towel on a shelf.",
        "vid": "BIQGN",
        "timestamps": [
            15.8,
            21.2
        ]
    },
    "IKYAW_0": {
        "text": "person closes the door.",
        "vid": "IKYAW",
        "timestamps": [
            4.8,
            12.8
        ]
    },
    "IKYAW_1": {
        "text": "a person is smiling in the doorway of the pantry.",
        "vid": "IKYAW",
        "timestamps": [
            0.0,
            3.1
        ]
    },
    "7V4NJ_0": {
        "text": "person throws the book.",
        "vid": "7V4NJ",
        "timestamps": [
            17.1,
            22.3
        ]
    },
    "7V4NJ_1": {
        "text": "person throw the book at a door.",
        "vid": "7V4NJ",
        "timestamps": [
            17.1,
            22.3
        ]
    },
    "XGS3K_0": {
        "text": "person opens a sliding glass door.",
        "vid": "XGS3K",
        "timestamps": [
            12.6,
            20.5
        ]
    },
    "XGS3K_1": {
        "text": "the person puts the picture down on the couch.",
        "vid": "XGS3K",
        "timestamps": [
            1.3,
            9.3
        ]
    },
    "XGS3K_2": {
        "text": "a person is putting a picture on a sofa.",
        "vid": "XGS3K",
        "timestamps": [
            1.3,
            9.3
        ]
    },
    "LXEPT_0": {
        "text": "person sits in a chair.",
        "vid": "LXEPT",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "LXEPT_1": {
        "text": "the person takes a notebook out.",
        "vid": "LXEPT",
        "timestamps": [
            17.4,
            30.9
        ]
    },
    "LXEPT_2": {
        "text": "the person puts a notebook on the table.",
        "vid": "LXEPT",
        "timestamps": [
            6.2,
            14.6
        ]
    },
    "Y2MGC_0": {
        "text": "person begins to eat it.",
        "vid": "Y2MGC",
        "timestamps": [
            18.3,
            33.0
        ]
    },
    "Y2MGC_1": {
        "text": "person start eating food.",
        "vid": "Y2MGC",
        "timestamps": [
            18.3,
            33.0
        ]
    },
    "Y2MGC_2": {
        "text": "a person closes their laptops lid.",
        "vid": "Y2MGC",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "Y2MGC_3": {
        "text": "person the put the laptop down.",
        "vid": "Y2MGC",
        "timestamps": [
            6.7,
            13.1
        ]
    },
    "Y2MGC_4": {
        "text": "the person takes some food out of a box.",
        "vid": "Y2MGC",
        "timestamps": [
            8.1,
            16.3
        ]
    },
    "Y2MGC_5": {
        "text": "person is smiling.",
        "vid": "Y2MGC",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "IWTWJ_0": {
        "text": "person later sits on the couch.",
        "vid": "IWTWJ",
        "timestamps": [
            13.2,
            20.8
        ]
    },
    "IWTWJ_1": {
        "text": "a person is throwing a blanket onto the sofa.",
        "vid": "IWTWJ",
        "timestamps": [
            4.3,
            9.5
        ]
    },
    "IWTWJ_2": {
        "text": "person suddenly run over to the sofa.",
        "vid": "IWTWJ",
        "timestamps": [
            11.6,
            17.3
        ]
    },
    "IWTWJ_3": {
        "text": "the person begins running towards the sofa.",
        "vid": "IWTWJ",
        "timestamps": [
            11.6,
            17.3
        ]
    },
    "5HPZ1_0": {
        "text": "person reads through some pages in a book.",
        "vid": "5HPZ1",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "5HPZ1_1": {
        "text": "person reading a book.",
        "vid": "5HPZ1",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "5HPZ1_2": {
        "text": "person a clicks a nearby light on.",
        "vid": "5HPZ1",
        "timestamps": [
            16.4,
            23.1
        ]
    },
    "5HPZ1_3": {
        "text": "person they turn on the light.",
        "vid": "5HPZ1",
        "timestamps": [
            16.4,
            23.1
        ]
    },
    "5HPZ1_4": {
        "text": "person turns on a light.",
        "vid": "5HPZ1",
        "timestamps": [
            16.4,
            23.1
        ]
    },
    "VNMNF_0": {
        "text": "a person is watching television.",
        "vid": "VNMNF",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "VNMNF_1": {
        "text": "person sits down in a chair.",
        "vid": "VNMNF",
        "timestamps": [
            21.9,
            28.0
        ]
    },
    "9U82D_0": {
        "text": "this person takes their phone out.",
        "vid": "9U82D",
        "timestamps": [
            13.8,
            19.7
        ]
    },
    "9U82D_1": {
        "text": "person they start drinking a glass of coffee.",
        "vid": "9U82D",
        "timestamps": [
            24.5,
            36.0
        ]
    },
    "FTYFA_0": {
        "text": "a person opens a door.",
        "vid": "FTYFA",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "FTYFA_1": {
        "text": "person turns on the light.",
        "vid": "FTYFA",
        "timestamps": [
            4.1,
            8.8
        ]
    },
    "FTYFA_2": {
        "text": "person opens a door.",
        "vid": "FTYFA",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "FTYFA_3": {
        "text": "person turns on a light.",
        "vid": "FTYFA",
        "timestamps": [
            4.1,
            8.8
        ]
    },
    "FTYFA_4": {
        "text": "a person turns on a light.",
        "vid": "FTYFA",
        "timestamps": [
            4.1,
            8.8
        ]
    },
    "GZF5F_0": {
        "text": "person pours another glass out of a pitcher.",
        "vid": "GZF5F",
        "timestamps": [
            4.7,
            11.7
        ]
    },
    "QSVXJ_0": {
        "text": "person decides to throw the towel on the floor.",
        "vid": "QSVXJ",
        "timestamps": [
            12.7,
            18.5
        ]
    },
    "QSVXJ_1": {
        "text": "person another holds a towel.",
        "vid": "QSVXJ",
        "timestamps": [
            5.7,
            17.5
        ]
    },
    "MHAGN_0": {
        "text": "person they open the book.",
        "vid": "MHAGN",
        "timestamps": [
            7.0,
            12.6
        ]
    },
    "MHAGN_1": {
        "text": "person running away.",
        "vid": "MHAGN",
        "timestamps": [
            14.1,
            22.0
        ]
    },
    "MHAGN_2": {
        "text": "person run out of the room.",
        "vid": "MHAGN",
        "timestamps": [
            14.1,
            22.0
        ]
    },
    "OZ02A_0": {
        "text": "person closed the curtains on the window.",
        "vid": "OZ02A",
        "timestamps": [
            10.5,
            16.1
        ]
    },
    "OZ02A_1": {
        "text": "person closes a window blind.",
        "vid": "OZ02A",
        "timestamps": [
            10.5,
            16.1
        ]
    },
    "OZ02A_2": {
        "text": "person a light is turned on.",
        "vid": "OZ02A",
        "timestamps": [
            2.9,
            11.8
        ]
    },
    "OZ02A_3": {
        "text": "the person turned on the light in the dining room.",
        "vid": "OZ02A",
        "timestamps": [
            2.9,
            11.8
        ]
    },
    "ODM20_0": {
        "text": "person look out the window.",
        "vid": "ODM20",
        "timestamps": [
            21.5,
            30.0
        ]
    },
    "ODM20_1": {
        "text": "person begins laughing.",
        "vid": "ODM20",
        "timestamps": [
            22.4,
            30.0
        ]
    },
    "ODM20_2": {
        "text": "the person looks out the window.",
        "vid": "ODM20",
        "timestamps": [
            21.5,
            30.0
        ]
    },
    "ODM20_3": {
        "text": "person drinking a cup of coffee.",
        "vid": "ODM20",
        "timestamps": [
            5.5,
            13.6
        ]
    },
    "MUE2B_0": {
        "text": "person looking at the things at bathroom window.",
        "vid": "MUE2B",
        "timestamps": [
            16.5,
            24.0
        ]
    },
    "MUE2B_1": {
        "text": "person turned on the light.",
        "vid": "MUE2B",
        "timestamps": [
            1.8,
            6.7
        ]
    },
    "MUE2B_2": {
        "text": "person looking out the window that is behind the toilet.",
        "vid": "MUE2B",
        "timestamps": [
            16.5,
            24.0
        ]
    },
    "MUE2B_3": {
        "text": "the person turns on the light.",
        "vid": "MUE2B",
        "timestamps": [
            1.8,
            6.7
        ]
    },
    "MUE2B_4": {
        "text": "the person opens the door to the bathroom.",
        "vid": "MUE2B",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "MUE2B_5": {
        "text": "person they walked over to the window to look outside.",
        "vid": "MUE2B",
        "timestamps": [
            16.5,
            24.0
        ]
    },
    "7RXMM_0": {
        "text": "a person sits in a chair.",
        "vid": "7RXMM",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "7RXMM_1": {
        "text": "the person sits on a chair next to a sink.",
        "vid": "7RXMM",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "ETDTU_0": {
        "text": "the person begins holding a mirror.",
        "vid": "ETDTU",
        "timestamps": [
            0.0,
            4.7
        ]
    },
    "9EEGQ_0": {
        "text": "another person fixes the door.",
        "vid": "9EEGQ",
        "timestamps": [
            7.6,
            14.3
        ]
    },
    "9EEGQ_1": {
        "text": "person fixing pantry door.",
        "vid": "9EEGQ",
        "timestamps": [
            7.6,
            14.3
        ]
    },
    "9EEGQ_2": {
        "text": "person is putting dishes on shelf.",
        "vid": "9EEGQ",
        "timestamps": [
            14.1,
            23.6
        ]
    },
    "LV4U7_0": {
        "text": "a person is holding a broom.",
        "vid": "LV4U7",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "LV4U7_1": {
        "text": "person standing in the open doorway of a pantry.",
        "vid": "LV4U7",
        "timestamps": [
            2.8,
            10.8
        ]
    },
    "LV4U7_2": {
        "text": "a person in a pantry is holding a broom.",
        "vid": "LV4U7",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "LV4U7_3": {
        "text": "a person holding a broom opens a pantry door.",
        "vid": "LV4U7",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "I6TPS_0": {
        "text": "person cooking something in the pan.",
        "vid": "I6TPS",
        "timestamps": [
            17.2,
            32.0
        ]
    },
    "ZDWM7_0": {
        "text": "person eating a sandwich.",
        "vid": "ZDWM7",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "ZDWM7_1": {
        "text": "person talking on the phone.",
        "vid": "ZDWM7",
        "timestamps": [
            0.0,
            9.3
        ]
    },
    "ZDWM7_2": {
        "text": "a person walks into a room holding a sandwich.",
        "vid": "ZDWM7",
        "timestamps": [
            0.0,
            14.3
        ]
    },
    "2AG8W_0": {
        "text": "person throwing their clothes into the closet.",
        "vid": "2AG8W",
        "timestamps": [
            4.0,
            8.7
        ]
    },
    "2AG8W_1": {
        "text": "person start running through the hallway.",
        "vid": "2AG8W",
        "timestamps": [
            7.2,
            12.0
        ]
    },
    "2AG8W_2": {
        "text": "person runs down a hallway.",
        "vid": "2AG8W",
        "timestamps": [
            7.2,
            12.0
        ]
    },
    "EFADI_0": {
        "text": "that same person takes some medicine off a shelf.",
        "vid": "EFADI",
        "timestamps": [
            5.2,
            11.0
        ]
    },
    "D4D2T_0": {
        "text": "person eats a sandwich.",
        "vid": "D4D2T",
        "timestamps": [
            13.9,
            25.0
        ]
    },
    "D4D2T_1": {
        "text": "person takes some food out of a box.",
        "vid": "D4D2T",
        "timestamps": [
            9.4,
            15.1
        ]
    },
    "D4D2T_2": {
        "text": "person eats it.",
        "vid": "D4D2T",
        "timestamps": [
            13.9,
            25.0
        ]
    },
    "D4D2T_3": {
        "text": "person opens a box.",
        "vid": "D4D2T",
        "timestamps": [
            2.8,
            12.9
        ]
    },
    "3C1ZN_0": {
        "text": "person puts the pillow down.",
        "vid": "3C1ZN",
        "timestamps": [
            24.4,
            28.8
        ]
    },
    "XJA7Z_0": {
        "text": "person pours a glass of water.",
        "vid": "XJA7Z",
        "timestamps": [
            1.1,
            9.4
        ]
    },
    "XJA7Z_1": {
        "text": "the person was pouring a bottle of beer.",
        "vid": "XJA7Z",
        "timestamps": [
            1.1,
            9.4
        ]
    },
    "XJA7Z_2": {
        "text": "person drinking from the glass of water.",
        "vid": "XJA7Z",
        "timestamps": [
            7.4,
            16.0
        ]
    },
    "XJA7Z_3": {
        "text": "a person pours water into a glass.",
        "vid": "XJA7Z",
        "timestamps": [
            1.1,
            9.4
        ]
    },
    "VD58Y_0": {
        "text": "person puts the laptop aside.",
        "vid": "VD58Y",
        "timestamps": [
            10.1,
            16.9
        ]
    },
    "VD58Y_1": {
        "text": "person start sneezing as they get off the bed.",
        "vid": "VD58Y",
        "timestamps": [
            13.9,
            21.1
        ]
    },
    "8HW76_0": {
        "text": "a person is laughing.",
        "vid": "8HW76",
        "timestamps": [
            4.7,
            12.3
        ]
    },
    "NKE77_0": {
        "text": "person puts it down on the table.",
        "vid": "NKE77",
        "timestamps": [
            8.2,
            14.8
        ]
    },
    "NKE77_1": {
        "text": "the person puts the cup down.",
        "vid": "NKE77",
        "timestamps": [
            10.0,
            15.6
        ]
    },
    "NBKCK_0": {
        "text": "person turns on the light.",
        "vid": "NBKCK",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "NBKCK_1": {
        "text": "the person turns on a light.",
        "vid": "NBKCK",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "N2WXN_0": {
        "text": "a person is awakening on top of their blanket.",
        "vid": "N2WXN",
        "timestamps": [
            7.1,
            19.9
        ]
    },
    "X2JBJ_0": {
        "text": "person smiling at the book.",
        "vid": "X2JBJ",
        "timestamps": [
            6.0,
            18.0
        ]
    },
    "DPLMM_0": {
        "text": "person shuts the light off.",
        "vid": "DPLMM",
        "timestamps": [
            10.6,
            16.0
        ]
    },
    "DPLMM_1": {
        "text": "person turns off the light as he exits.",
        "vid": "DPLMM",
        "timestamps": [
            10.6,
            16.0
        ]
    },
    "0SFYS_0": {
        "text": "a person turns on the light.",
        "vid": "0SFYS",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "1F706_0": {
        "text": "person a girl runs into the room.",
        "vid": "1F706",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "1F706_1": {
        "text": "a person runs down the hall.",
        "vid": "1F706",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "1F706_2": {
        "text": "a person runs to the doorway of the pantry.",
        "vid": "1F706",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "1F706_3": {
        "text": "person closes the door.",
        "vid": "1F706",
        "timestamps": [
            25.2,
            31.0
        ]
    },
    "1F706_4": {
        "text": "person opens a pantry door.",
        "vid": "1F706",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "XXS99_0": {
        "text": "person looks at a picture hanging on the wall.",
        "vid": "XXS99",
        "timestamps": [
            19.0,
            30.0
        ]
    },
    "XXS99_1": {
        "text": "the person takes the book.",
        "vid": "XXS99",
        "timestamps": [
            15.9,
            24.6
        ]
    },
    "XXS99_2": {
        "text": "person open book.",
        "vid": "XXS99",
        "timestamps": [
            13.4,
            18.7
        ]
    },
    "727IZ_0": {
        "text": "a person opens a cabinet.",
        "vid": "727IZ",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "727IZ_1": {
        "text": "person sits on a chair to look at them.",
        "vid": "727IZ",
        "timestamps": [
            14.2,
            20.1
        ]
    },
    "727IZ_2": {
        "text": "a person is opening a cabinet.",
        "vid": "727IZ",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "727IZ_3": {
        "text": "person sits in a nearby computer chair.",
        "vid": "727IZ",
        "timestamps": [
            14.2,
            20.1
        ]
    },
    "N86ED_0": {
        "text": "person starts to eat them.",
        "vid": "N86ED",
        "timestamps": [
            0.0,
            8.5
        ]
    },
    "N86ED_1": {
        "text": "person eating a sandwich.",
        "vid": "N86ED",
        "timestamps": [
            1.7,
            11.5
        ]
    },
    "N86ED_2": {
        "text": "person eating some cookies out of a box.",
        "vid": "N86ED",
        "timestamps": [
            0.0,
            8.5
        ]
    },
    "N86ED_3": {
        "text": "the person opens a box of cookies.",
        "vid": "N86ED",
        "timestamps": [
            8.5,
            14.4
        ]
    },
    "NACLT_0": {
        "text": "person runs out.",
        "vid": "NACLT",
        "timestamps": [
            12.6,
            21.0
        ]
    },
    "NACLT_1": {
        "text": "person puts the shoes under the table.",
        "vid": "NACLT",
        "timestamps": [
            6.4,
            12.2
        ]
    },
    "KGO3W_0": {
        "text": "person drinks out of a glass.",
        "vid": "KGO3W",
        "timestamps": [
            17.1,
            25.8
        ]
    },
    "KGO3W_1": {
        "text": "person they turn on a light.",
        "vid": "KGO3W",
        "timestamps": [
            7.5,
            14.5
        ]
    },
    "KGO3W_2": {
        "text": "a person turns on the light.",
        "vid": "KGO3W",
        "timestamps": [
            7.5,
            14.5
        ]
    },
    "SCFIN_0": {
        "text": "person open the refrigerator.",
        "vid": "SCFIN",
        "timestamps": [
            8.7,
            22.0
        ]
    },
    "SCFIN_1": {
        "text": "person opens up the refrigerator door.",
        "vid": "SCFIN",
        "timestamps": [
            5.4,
            19.4
        ]
    },
    "TRHT1_0": {
        "text": "person sitting on a chair watching television when suddenly rises.",
        "vid": "TRHT1",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "TRHT1_1": {
        "text": "person sitting on a couch.",
        "vid": "TRHT1",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "A9YQJ_0": {
        "text": "person they fix their hair.",
        "vid": "A9YQJ",
        "timestamps": [
            22.8,
            34.0
        ]
    },
    "A9YQJ_1": {
        "text": "person fixes their hair.",
        "vid": "A9YQJ",
        "timestamps": [
            22.8,
            34.0
        ]
    },
    "A9YQJ_2": {
        "text": "person start fixing their hair.",
        "vid": "A9YQJ",
        "timestamps": [
            22.8,
            34.0
        ]
    },
    "8RU1Q_0": {
        "text": "a person opens a door.",
        "vid": "8RU1Q",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "8RU1Q_1": {
        "text": "a person opens the door.",
        "vid": "8RU1Q",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "J5DOP_0": {
        "text": "person walks into the kitchen to open the refrigerator door.",
        "vid": "J5DOP",
        "timestamps": [
            26.2,
            31.0
        ]
    },
    "J5DOP_1": {
        "text": "person putting their shoes on.",
        "vid": "J5DOP",
        "timestamps": [
            0.0,
            11.3
        ]
    },
    "J5DOP_2": {
        "text": "person putting on shoes.",
        "vid": "J5DOP",
        "timestamps": [
            0.0,
            11.3
        ]
    },
    "J5DOP_3": {
        "text": "person opening the door.",
        "vid": "J5DOP",
        "timestamps": [
            25.8,
            31.0
        ]
    },
    "5TYXL_0": {
        "text": "person takes the broom.",
        "vid": "5TYXL",
        "timestamps": [
            25.1,
            31.4
        ]
    },
    "FV8CK_0": {
        "text": "person taking a drink from a bottle of water.",
        "vid": "FV8CK",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "H46LQ_0": {
        "text": "person they stand up.",
        "vid": "H46LQ",
        "timestamps": [
            23.5,
            29.1
        ]
    },
    "WUTHF_0": {
        "text": "a person runs in.",
        "vid": "WUTHF",
        "timestamps": [
            0.8,
            6.4
        ]
    },
    "WUTHF_1": {
        "text": "a person runs into a room.",
        "vid": "WUTHF",
        "timestamps": [
            0.8,
            6.4
        ]
    },
    "WUTHF_2": {
        "text": "one person runs through.",
        "vid": "WUTHF",
        "timestamps": [
            0.8,
            6.4
        ]
    },
    "1NJOQ_0": {
        "text": "a person walks through the doorway.",
        "vid": "1NJOQ",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "1NJOQ_1": {
        "text": "person they open the cabinet.",
        "vid": "1NJOQ",
        "timestamps": [
            14.6,
            20.7
        ]
    },
    "1NJOQ_2": {
        "text": "person opens drawers on cabinet.",
        "vid": "1NJOQ",
        "timestamps": [
            14.6,
            20.7
        ]
    },
    "1NJOQ_3": {
        "text": "person takes out a bottle of medicine.",
        "vid": "1NJOQ",
        "timestamps": [
            30.7,
            36.0
        ]
    },
    "1NJOQ_4": {
        "text": "the person opens a cabinet.",
        "vid": "1NJOQ",
        "timestamps": [
            14.6,
            20.7
        ]
    },
    "LDNE2_0": {
        "text": "person takes a book from the table.",
        "vid": "LDNE2",
        "timestamps": [
            23.0,
            33.0
        ]
    },
    "13XM4_0": {
        "text": "the person puts it on the table.",
        "vid": "13XM4",
        "timestamps": [
            6.5,
            11.9
        ]
    },
    "13XM4_1": {
        "text": "person start laughing.",
        "vid": "13XM4",
        "timestamps": [
            18.0,
            22.2
        ]
    },
    "13XM4_2": {
        "text": "person puts it on a table.",
        "vid": "13XM4",
        "timestamps": [
            6.5,
            11.9
        ]
    },
    "13XM4_3": {
        "text": "person puts some food inside.",
        "vid": "13XM4",
        "timestamps": [
            7.1,
            11.5
        ]
    },
    "2443O_0": {
        "text": "the person takes out their phone.",
        "vid": "2443O",
        "timestamps": [
            10.7,
            18.0
        ]
    },
    "2443O_1": {
        "text": "person takes out a phone.",
        "vid": "2443O",
        "timestamps": [
            10.7,
            18.0
        ]
    },
    "3R4DD_0": {
        "text": "person sit down in a chair.",
        "vid": "3R4DD",
        "timestamps": [
            24.7,
            34.0
        ]
    },
    "3R4DD_1": {
        "text": "person sits in a chair.",
        "vid": "3R4DD",
        "timestamps": [
            24.7,
            34.0
        ]
    },
    "3R4DD_2": {
        "text": "person sit in a chair.",
        "vid": "3R4DD",
        "timestamps": [
            24.7,
            34.0
        ]
    },
    "SUG5S_0": {
        "text": "person they stand up.",
        "vid": "SUG5S",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "SUG5S_1": {
        "text": "person washes their hands.",
        "vid": "SUG5S",
        "timestamps": [
            9.7,
            17.1
        ]
    },
    "SUG5S_2": {
        "text": "there is a person sitting on a bed.",
        "vid": "SUG5S",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "SUG5S_3": {
        "text": "a person is sitting on a bed.",
        "vid": "SUG5S",
        "timestamps": [
            0.0,
            3.7
        ]
    },
    "SUG5S_4": {
        "text": "person wash their hands.",
        "vid": "SUG5S",
        "timestamps": [
            9.7,
            17.1
        ]
    },
    "X4BQG_0": {
        "text": "person opens a cabinet.",
        "vid": "X4BQG",
        "timestamps": [
            5.7,
            14.8
        ]
    },
    "X4BQG_1": {
        "text": "the person opens a cabinet.",
        "vid": "X4BQG",
        "timestamps": [
            5.7,
            14.8
        ]
    },
    "X4BQG_2": {
        "text": "person puts some paper inside.",
        "vid": "X4BQG",
        "timestamps": [
            1.3,
            14.3
        ]
    },
    "OETY6_0": {
        "text": "person drinking from a cup.",
        "vid": "OETY6",
        "timestamps": [
            8.6,
            18.1
        ]
    },
    "OETY6_1": {
        "text": "a person sits in a chair next to a table.",
        "vid": "OETY6",
        "timestamps": [
            28.7,
            32.0
        ]
    },
    "4UXE3_0": {
        "text": "person putting a glass in the sink.",
        "vid": "4UXE3",
        "timestamps": [
            25.6,
            31.1
        ]
    },
    "4UXE3_1": {
        "text": "person putting a cup in the sink.",
        "vid": "4UXE3",
        "timestamps": [
            25.6,
            31.1
        ]
    },
    "LFDQF_0": {
        "text": "person drinking a glass of water.",
        "vid": "LFDQF",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "LFDQF_1": {
        "text": "the person is drinking a glass of water.",
        "vid": "LFDQF",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "Y0MCG_0": {
        "text": "a person puts a pillow down on the sofa.",
        "vid": "Y0MCG",
        "timestamps": [
            4.9,
            10.8
        ]
    },
    "5EEXF_0": {
        "text": "a person opens a cabinet.",
        "vid": "5EEXF",
        "timestamps": [
            1.0,
            7.0
        ]
    },
    "5EEXF_1": {
        "text": "person is opening a cabinet.",
        "vid": "5EEXF",
        "timestamps": [
            1.0,
            7.0
        ]
    },
    "5EEXF_2": {
        "text": "the person opens a closet door.",
        "vid": "5EEXF",
        "timestamps": [
            1.0,
            7.0
        ]
    },
    "5EEXF_3": {
        "text": "person opens a closet door.",
        "vid": "5EEXF",
        "timestamps": [
            1.0,
            7.0
        ]
    },
    "5EEXF_4": {
        "text": "person puts the towel away.",
        "vid": "5EEXF",
        "timestamps": [
            16.9,
            23.8
        ]
    },
    "5EEXF_5": {
        "text": "person open their closet put the blanket inside it.",
        "vid": "5EEXF",
        "timestamps": [
            1.0,
            7.0
        ]
    },
    "5EEXF_6": {
        "text": "the person takes a towel from the cabinet.",
        "vid": "5EEXF",
        "timestamps": [
            2.4,
            8.7
        ]
    },
    "5EEXF_7": {
        "text": "person takes out a blanket.",
        "vid": "5EEXF",
        "timestamps": [
            2.2,
            7.7
        ]
    },
    "YFJ9U_0": {
        "text": "person puts on shoes.",
        "vid": "YFJ9U",
        "timestamps": [
            2.2,
            13.1
        ]
    },
    "4YBN9_0": {
        "text": "one person opens a bag on a small desk.",
        "vid": "4YBN9",
        "timestamps": [
            2.7,
            15.7
        ]
    },
    "4YBN9_1": {
        "text": "person open a door.",
        "vid": "4YBN9",
        "timestamps": [
            21.7,
            29.4
        ]
    },
    "XRU9O_0": {
        "text": "person eats a sandwich.",
        "vid": "XRU9O",
        "timestamps": [
            8.7,
            21.9
        ]
    },
    "XRU9O_1": {
        "text": "a person is standing against a wall eating a sandwich.",
        "vid": "XRU9O",
        "timestamps": [
            8.7,
            21.9
        ]
    },
    "XRU9O_2": {
        "text": "person eating a sandwich.",
        "vid": "XRU9O",
        "timestamps": [
            8.7,
            21.9
        ]
    },
    "PC7H2_0": {
        "text": "person sits down on couch.",
        "vid": "PC7H2",
        "timestamps": [
            4.7,
            18.2
        ]
    },
    "PC7H2_1": {
        "text": "person sits on the couch.",
        "vid": "PC7H2",
        "timestamps": [
            4.7,
            18.2
        ]
    },
    "PC7H2_2": {
        "text": "a person sits down at a table.",
        "vid": "PC7H2",
        "timestamps": [
            4.7,
            17.7
        ]
    },
    "PC7H2_3": {
        "text": "a person is sitting at the table.",
        "vid": "PC7H2",
        "timestamps": [
            4.7,
            17.7
        ]
    },
    "E002I_0": {
        "text": "person snuggling up to a pillow.",
        "vid": "E002I",
        "timestamps": [
            4.1,
            13.4
        ]
    },
    "E002I_1": {
        "text": "a person runs into the bedroom.",
        "vid": "E002I",
        "timestamps": [
            0.3,
            7.3
        ]
    },
    "E002I_2": {
        "text": "person goes back to close the door.",
        "vid": "E002I",
        "timestamps": [
            12.9,
            19.7
        ]
    },
    "E002I_3": {
        "text": "person closes the door.",
        "vid": "E002I",
        "timestamps": [
            12.9,
            19.7
        ]
    },
    "E002I_4": {
        "text": "a person runs into a room.",
        "vid": "E002I",
        "timestamps": [
            0.3,
            7.3
        ]
    },
    "E002I_5": {
        "text": "person closes a door.",
        "vid": "E002I",
        "timestamps": [
            12.9,
            19.7
        ]
    },
    "E002I_6": {
        "text": "person lies down on the bed.",
        "vid": "E002I",
        "timestamps": [
            4.7,
            14.1
        ]
    },
    "E002I_7": {
        "text": "person lies down on a bed.",
        "vid": "E002I",
        "timestamps": [
            4.7,
            14.1
        ]
    },
    "E002I_8": {
        "text": "the person gets up to close the door.",
        "vid": "E002I",
        "timestamps": [
            12.9,
            19.7
        ]
    },
    "5GHV3_0": {
        "text": "a person is putting clothes on.",
        "vid": "5GHV3",
        "timestamps": [
            0.0,
            9.2
        ]
    },
    "5GHV3_1": {
        "text": "a person is dressing by the bed.",
        "vid": "5GHV3",
        "timestamps": [
            0.4,
            13.4
        ]
    },
    "TDGNE_0": {
        "text": "person eating an occasional bite from the pan.",
        "vid": "TDGNE",
        "timestamps": [
            3.5,
            8.6
        ]
    },
    "TDGNE_1": {
        "text": "person open the door to the refrigerator.",
        "vid": "TDGNE",
        "timestamps": [
            22.9,
            29.0
        ]
    },
    "1P7GJ_0": {
        "text": "person they open a door to grab a broom.",
        "vid": "1P7GJ",
        "timestamps": [
            16.4,
            23.6
        ]
    },
    "MB281_0": {
        "text": "person turning the light off.",
        "vid": "MB281",
        "timestamps": [
            19.5,
            28.9
        ]
    },
    "MB281_1": {
        "text": "person turn off the light.",
        "vid": "MB281",
        "timestamps": [
            19.5,
            28.9
        ]
    },
    "MB281_2": {
        "text": "person turns off the light.",
        "vid": "MB281",
        "timestamps": [
            19.5,
            28.9
        ]
    },
    "MB281_3": {
        "text": "person puts it down on the shelf.",
        "vid": "MB281",
        "timestamps": [
            14.3,
            19.8
        ]
    },
    "7E2AJ_0": {
        "text": "person they stand up.",
        "vid": "7E2AJ",
        "timestamps": [
            0.7,
            5.8
        ]
    },
    "7E2AJ_1": {
        "text": "a person is awakening on the floor.",
        "vid": "7E2AJ",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "7E2AJ_2": {
        "text": "person start undressing by taking their jacket off.",
        "vid": "7E2AJ",
        "timestamps": [
            7.0,
            12.4
        ]
    },
    "7E2AJ_3": {
        "text": "person eats sandwich that is seating on side of sink.",
        "vid": "7E2AJ",
        "timestamps": [
            12.1,
            17.0
        ]
    },
    "7E2AJ_4": {
        "text": "person laying on bathroom floor.",
        "vid": "7E2AJ",
        "timestamps": [
            0.0,
            3.1
        ]
    },
    "ZZ3HT_0": {
        "text": "person put it back closed the shelf.",
        "vid": "ZZ3HT",
        "timestamps": [
            7.0,
            11.3
        ]
    },
    "ZZ3HT_1": {
        "text": "person walk over to a cabinet take a towel out.",
        "vid": "ZZ3HT",
        "timestamps": [
            2.4,
            8.0
        ]
    },
    "ZZ3HT_2": {
        "text": "person closing the closet door.",
        "vid": "ZZ3HT",
        "timestamps": [
            8.2,
            16.4
        ]
    },
    "0J471_0": {
        "text": "person they stand up.",
        "vid": "0J471",
        "timestamps": [
            7.4,
            17.2
        ]
    },
    "0J471_1": {
        "text": "person running up.",
        "vid": "0J471",
        "timestamps": [
            13.0,
            23.0
        ]
    },
    "0J471_2": {
        "text": "person runs back.",
        "vid": "0J471",
        "timestamps": [
            13.0,
            23.0
        ]
    },
    "0J471_3": {
        "text": "person begin running.",
        "vid": "0J471",
        "timestamps": [
            13.0,
            23.0
        ]
    },
    "HG7C2_0": {
        "text": "a person is undressing in the doorway.",
        "vid": "HG7C2",
        "timestamps": [
            0.0,
            13.5
        ]
    },
    "HG7C2_1": {
        "text": "the person starts smiling.",
        "vid": "HG7C2",
        "timestamps": [
            21.9,
            30.9
        ]
    },
    "HG7C2_2": {
        "text": "person holding a broom.",
        "vid": "HG7C2",
        "timestamps": [
            17.7,
            31.0
        ]
    },
    "S5KQ1_0": {
        "text": "a person opens a box.",
        "vid": "S5KQ1",
        "timestamps": [
            3.0,
            8.2
        ]
    },
    "S5KQ1_1": {
        "text": "person throws a broom down.",
        "vid": "S5KQ1",
        "timestamps": [
            11.7,
            17.1
        ]
    },
    "S5KQ1_2": {
        "text": "person puts down the box.",
        "vid": "S5KQ1",
        "timestamps": [
            11.3,
            16.7
        ]
    },
    "S5KQ1_3": {
        "text": "a person closes a box.",
        "vid": "S5KQ1",
        "timestamps": [
            8.4,
            13.8
        ]
    },
    "YIIFF_0": {
        "text": "person began getting dressed.",
        "vid": "YIIFF",
        "timestamps": [
            19.1,
            31.0
        ]
    },
    "YIIFF_1": {
        "text": "a person is tidying up a shelf.",
        "vid": "YIIFF",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "IIL9C_0": {
        "text": "person eating a cookie.",
        "vid": "IIL9C",
        "timestamps": [
            0.0,
            13.2
        ]
    },
    "IIL9C_1": {
        "text": "person take out the bottle of medicine.",
        "vid": "IIL9C",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "IIL9C_2": {
        "text": "there is a person laying on the sofa eating something.",
        "vid": "IIL9C",
        "timestamps": [
            0.0,
            13.2
        ]
    },
    "IIL9C_3": {
        "text": "person takes a bottle of medicine from their shirt pocket.",
        "vid": "IIL9C",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "SBI6Z_0": {
        "text": "person pours a drink into a glass.",
        "vid": "SBI6Z",
        "timestamps": [
            11.8,
            20.6
        ]
    },
    "9J7EW_0": {
        "text": "person sits in a chair.",
        "vid": "9J7EW",
        "timestamps": [
            3.9,
            18.2
        ]
    },
    "9J7EW_1": {
        "text": "person they sit on a chair.",
        "vid": "9J7EW",
        "timestamps": [
            3.9,
            18.2
        ]
    },
    "9J7EW_2": {
        "text": "there is a person holding a bag.",
        "vid": "9J7EW",
        "timestamps": [
            11.1,
            24.5
        ]
    },
    "9J7EW_3": {
        "text": "person takes off their shoes.",
        "vid": "9J7EW",
        "timestamps": [
            18.2,
            25.4
        ]
    },
    "DLOS7_0": {
        "text": "the person opens a pink laptop.",
        "vid": "DLOS7",
        "timestamps": [
            13.8,
            20.9
        ]
    },
    "DLOS7_1": {
        "text": "person they sit down holding a laptop.",
        "vid": "DLOS7",
        "timestamps": [
            11.7,
            16.9
        ]
    },
    "DLOS7_2": {
        "text": "person begins fixing the light that was not working.",
        "vid": "DLOS7",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "DLOS7_3": {
        "text": "person a persno is fixing a light.",
        "vid": "DLOS7",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "1F4JZ_0": {
        "text": "one person takes some medicine.",
        "vid": "1F4JZ",
        "timestamps": [
            2.0,
            8.7
        ]
    },
    "YHXU9_0": {
        "text": "person throws it on the floor.",
        "vid": "YHXU9",
        "timestamps": [
            14.2,
            18.7
        ]
    },
    "KS5JT_0": {
        "text": "person turned on the light.",
        "vid": "KS5JT",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "KS5JT_1": {
        "text": "person turns on the light.",
        "vid": "KS5JT",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "KS5JT_2": {
        "text": "a person turns on the light.",
        "vid": "KS5JT",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "HQ8BB_0": {
        "text": "person turns on the light.",
        "vid": "HQ8BB",
        "timestamps": [
            2.5,
            9.2
        ]
    },
    "HQ8BB_1": {
        "text": "the person opens the door.",
        "vid": "HQ8BB",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "HQ8BB_2": {
        "text": "person turning the light on.",
        "vid": "HQ8BB",
        "timestamps": [
            2.5,
            9.2
        ]
    },
    "AGGSE_0": {
        "text": "the person is sneezing.",
        "vid": "AGGSE",
        "timestamps": [
            8.9,
            15.0
        ]
    },
    "3W1GP_0": {
        "text": "person takes out a laptop.",
        "vid": "3W1GP",
        "timestamps": [
            25.2,
            31.3
        ]
    },
    "3W1GP_1": {
        "text": "a person opens the door.",
        "vid": "3W1GP",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "3W1GP_2": {
        "text": "a person opens a door.",
        "vid": "3W1GP",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "3W1GP_3": {
        "text": "person open a bag.",
        "vid": "3W1GP",
        "timestamps": [
            14.0,
            31.0
        ]
    },
    "3W1GP_4": {
        "text": "person closes the door.",
        "vid": "3W1GP",
        "timestamps": [
            2.9,
            8.7
        ]
    },
    "3W1GP_5": {
        "text": "person walks through the doorway carrying a bag.",
        "vid": "3W1GP",
        "timestamps": [
            0.0,
            2.5
        ]
    },
    "3W1GP_6": {
        "text": "person they put the bag on the ground.",
        "vid": "3W1GP",
        "timestamps": [
            32.2,
            36.0
        ]
    },
    "3W1GP_7": {
        "text": "person open the bag.",
        "vid": "3W1GP",
        "timestamps": [
            14.0,
            31.0
        ]
    },
    "OQSXX_0": {
        "text": "person puts a towel on their shoulder.",
        "vid": "OQSXX",
        "timestamps": [
            8.6,
            15.6
        ]
    },
    "OQSXX_1": {
        "text": "one person is sitting on the sofa.",
        "vid": "OQSXX",
        "timestamps": [
            0.0,
            7.6
        ]
    },
    "OQSXX_2": {
        "text": "a person sits on a couch.",
        "vid": "OQSXX",
        "timestamps": [
            0.0,
            7.6
        ]
    },
    "ZXHCH_0": {
        "text": "person sits down in a chair.",
        "vid": "ZXHCH",
        "timestamps": [
            19.2,
            23.5
        ]
    },
    "ZXHCH_1": {
        "text": "the person takes their books out of their bag.",
        "vid": "ZXHCH",
        "timestamps": [
            3.2,
            7.4
        ]
    },
    "ZXHCH_2": {
        "text": "person open up the books.",
        "vid": "ZXHCH",
        "timestamps": [
            4.7,
            10.8
        ]
    },
    "3MV13_0": {
        "text": "the person starts walking to the doorway.",
        "vid": "3MV13",
        "timestamps": [
            16.3,
            25.3
        ]
    },
    "65ULK_0": {
        "text": "person starts dressing in front of a mirror.",
        "vid": "65ULK",
        "timestamps": [
            16.0,
            31.0
        ]
    },
    "RMKOC_0": {
        "text": "person holds a plastic bag.",
        "vid": "RMKOC",
        "timestamps": [
            0.0,
            12.0
        ]
    },
    "RMKOC_1": {
        "text": "person takes a towel to wrap a mug.",
        "vid": "RMKOC",
        "timestamps": [
            7.4,
            13.8
        ]
    },
    "8O07M_0": {
        "text": "person opens the door.",
        "vid": "8O07M",
        "timestamps": [
            16.2,
            26.7
        ]
    },
    "8O07M_1": {
        "text": "person opens a door.",
        "vid": "8O07M",
        "timestamps": [
            16.2,
            26.7
        ]
    },
    "BEAAA_0": {
        "text": "person eating food in a hallway.",
        "vid": "BEAAA",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "BEAAA_1": {
        "text": "the person undresses their jacket.",
        "vid": "BEAAA",
        "timestamps": [
            0.7,
            10.9
        ]
    },
    "BEAAA_2": {
        "text": "person sitting in a chair eating.",
        "vid": "BEAAA",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "BEAAA_3": {
        "text": "person eating a sandwich.",
        "vid": "BEAAA",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "BEAAA_4": {
        "text": "a person is sitting on a chair eating food.",
        "vid": "BEAAA",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "BEAAA_5": {
        "text": "a person is undressing.",
        "vid": "BEAAA",
        "timestamps": [
            0.7,
            10.9
        ]
    },
    "BEAAA_6": {
        "text": "person continues eating the food.",
        "vid": "BEAAA",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "T96JC_0": {
        "text": "person takes a vacuum.",
        "vid": "T96JC",
        "timestamps": [
            4.8,
            14.4
        ]
    },
    "0QAZ7_0": {
        "text": "person closing the door.",
        "vid": "0QAZ7",
        "timestamps": [
            25.3,
            31.0
        ]
    },
    "0QAZ7_1": {
        "text": "person finally opening a door leaving.",
        "vid": "0QAZ7",
        "timestamps": [
            23.4,
            29.2
        ]
    },
    "FRGXE_0": {
        "text": "person drinking a glass of orange juice.",
        "vid": "FRGXE",
        "timestamps": [
            2.1,
            8.6
        ]
    },
    "FRGXE_1": {
        "text": "person takes out a box of cookies from the nightstand.",
        "vid": "FRGXE",
        "timestamps": [
            19.6,
            23.0
        ]
    },
    "3T785_0": {
        "text": "a person putting a towel on their head.",
        "vid": "3T785",
        "timestamps": [
            2.1,
            8.0
        ]
    },
    "3T785_1": {
        "text": "one person puts a towel on their head.",
        "vid": "3T785",
        "timestamps": [
            2.1,
            8.0
        ]
    },
    "4NHRT_0": {
        "text": "the person takes a bag off of a shelf.",
        "vid": "4NHRT",
        "timestamps": [
            1.9,
            8.7
        ]
    },
    "4NHRT_1": {
        "text": "person runs back down the stairs.",
        "vid": "4NHRT",
        "timestamps": [
            5.4,
            13.0
        ]
    },
    "ONVGA_0": {
        "text": "person eating from a plate.",
        "vid": "ONVGA",
        "timestamps": [
            4.9,
            11.6
        ]
    },
    "WT46G_0": {
        "text": "person holding a coffee cup.",
        "vid": "WT46G",
        "timestamps": [
            0.9,
            7.2
        ]
    },
    "WT46G_1": {
        "text": "first person is awakening from long nap.",
        "vid": "WT46G",
        "timestamps": [
            4.6,
            13.1
        ]
    },
    "WT46G_2": {
        "text": "person watching television.",
        "vid": "WT46G",
        "timestamps": [
            4.9,
            16.6
        ]
    },
    "8V8HC_0": {
        "text": "a person is running through an entryway.",
        "vid": "8V8HC",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "8V8HC_1": {
        "text": "the person takes a pillow off a sofa.",
        "vid": "8V8HC",
        "timestamps": [
            1.7,
            7.1
        ]
    },
    "8V8HC_2": {
        "text": "person they both run in the house very quickly.",
        "vid": "8V8HC",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "D7W4E_0": {
        "text": "a person puts a cup into a  cupboard.",
        "vid": "D7W4E",
        "timestamps": [
            6.5,
            15.7
        ]
    },
    "D7W4E_1": {
        "text": "a person puts a coffee cup on a shelf.",
        "vid": "D7W4E",
        "timestamps": [
            6.5,
            13.7
        ]
    },
    "D7W4E_2": {
        "text": "person sneezing on it.",
        "vid": "D7W4E",
        "timestamps": [
            20.9,
            29.1
        ]
    },
    "Q3Z4V_0": {
        "text": "person drinks from a glass.",
        "vid": "Q3Z4V",
        "timestamps": [
            16.8,
            24.6
        ]
    },
    "ZYJJF_0": {
        "text": "a person puts clothes on a desk.",
        "vid": "ZYJJF",
        "timestamps": [
            1.5,
            11.7
        ]
    },
    "T9N9R_0": {
        "text": "the person was laughing.",
        "vid": "T9N9R",
        "timestamps": [
            10.5,
            15.7
        ]
    },
    "74WSB_0": {
        "text": "person they start smiling because they are being somewhat irresponsible.",
        "vid": "74WSB",
        "timestamps": [
            11.2,
            20.9
        ]
    },
    "5D85P_0": {
        "text": "person closes the laptop screen shortly.",
        "vid": "5D85P",
        "timestamps": [
            4.2,
            8.6
        ]
    },
    "VVQYB_0": {
        "text": "another person is laughing.",
        "vid": "VVQYB",
        "timestamps": [
            9.6,
            15.5
        ]
    },
    "P3CLM_0": {
        "text": "person close the book.",
        "vid": "P3CLM",
        "timestamps": [
            29.1,
            41.0
        ]
    },
    "P3CLM_1": {
        "text": "person they close the book.",
        "vid": "P3CLM",
        "timestamps": [
            29.1,
            41.0
        ]
    },
    "AWR2R_0": {
        "text": "a person is standing in the bedroom holding a broom.",
        "vid": "AWR2R",
        "timestamps": [
            2.7,
            11.7
        ]
    },
    "2KGV3_0": {
        "text": "person takes another bite of their food.",
        "vid": "2KGV3",
        "timestamps": [
            2.6,
            7.2
        ]
    },
    "2KGV3_1": {
        "text": "person eating a sandwich.",
        "vid": "2KGV3",
        "timestamps": [
            2.6,
            13.1
        ]
    },
    "2KGV3_2": {
        "text": "the person puts the book down to continue eating.",
        "vid": "2KGV3",
        "timestamps": [
            2.6,
            13.1
        ]
    },
    "2KGV3_3": {
        "text": "a person is sitting on the couch eating a sandwich.",
        "vid": "2KGV3",
        "timestamps": [
            2.6,
            13.1
        ]
    },
    "2KGV3_4": {
        "text": "the person is doing their homework as the person eats.",
        "vid": "2KGV3",
        "timestamps": [
            2.6,
            13.1
        ]
    },
    "2KGV3_5": {
        "text": "person they put down the book.",
        "vid": "2KGV3",
        "timestamps": [
            18.2,
            23.9
        ]
    },
    "D0AGO_0": {
        "text": "person pours coke into glass.",
        "vid": "D0AGO",
        "timestamps": [
            0.7,
            16.3
        ]
    },
    "D0AGO_1": {
        "text": "person pour a glass of soda.",
        "vid": "D0AGO",
        "timestamps": [
            0.7,
            16.3
        ]
    },
    "D0AGO_2": {
        "text": "person seen pouring a can of soda into a glass.",
        "vid": "D0AGO",
        "timestamps": [
            0.7,
            16.3
        ]
    },
    "D0AGO_3": {
        "text": "person pours some into a glass.",
        "vid": "D0AGO",
        "timestamps": [
            0.7,
            16.3
        ]
    },
    "EF7Q9_0": {
        "text": "person begins washing their hands.",
        "vid": "EF7Q9",
        "timestamps": [
            6.8,
            13.4
        ]
    },
    "EF7Q9_1": {
        "text": "person washes hands.",
        "vid": "EF7Q9",
        "timestamps": [
            6.8,
            13.4
        ]
    },
    "EF7Q9_2": {
        "text": "person they take the glass.",
        "vid": "EF7Q9",
        "timestamps": [
            14.0,
            20.5
        ]
    },
    "G2AMK_0": {
        "text": "person closing the door to it behind them.",
        "vid": "G2AMK",
        "timestamps": [
            24.0,
            28.0
        ]
    },
    "FG9NT_0": {
        "text": "person eats whats in the dish.",
        "vid": "FG9NT",
        "timestamps": [
            11.5,
            20.9
        ]
    },
    "FG9NT_1": {
        "text": "person eats from a bowl.",
        "vid": "FG9NT",
        "timestamps": [
            11.5,
            20.9
        ]
    },
    "LLTBQ_0": {
        "text": "a person opens a door.",
        "vid": "LLTBQ",
        "timestamps": [
            0.3,
            6.7
        ]
    },
    "LLTBQ_1": {
        "text": "person holding a towel.",
        "vid": "LLTBQ",
        "timestamps": [
            6.7,
            13.2
        ]
    },
    "LLTBQ_2": {
        "text": "a person opens the bedroom door.",
        "vid": "LLTBQ",
        "timestamps": [
            0.3,
            6.7
        ]
    },
    "HS14N_0": {
        "text": "person closes the cabinet.",
        "vid": "HS14N",
        "timestamps": [
            10.9,
            16.3
        ]
    },
    "HS14N_1": {
        "text": "a person runs into the kitchen.",
        "vid": "HS14N",
        "timestamps": [
            2.7,
            8.5
        ]
    },
    "HS14N_2": {
        "text": "person opens the cabinet.",
        "vid": "HS14N",
        "timestamps": [
            4.5,
            16.6
        ]
    },
    "HS14N_3": {
        "text": "the person takes a dish from the top shelf.",
        "vid": "HS14N",
        "timestamps": [
            5.9,
            14.1
        ]
    },
    "HS14N_4": {
        "text": "person opens a cabinet.",
        "vid": "HS14N",
        "timestamps": [
            4.5,
            16.6
        ]
    },
    "L2502_0": {
        "text": "person fixes their hair in a mirror.",
        "vid": "L2502",
        "timestamps": [
            14.2,
            31.1
        ]
    },
    "L2502_1": {
        "text": "person begins to undress.",
        "vid": "L2502",
        "timestamps": [
            29.4,
            35.0
        ]
    },
    "GT43R_0": {
        "text": "person turns off the light again.",
        "vid": "GT43R",
        "timestamps": [
            2.1,
            9.3
        ]
    },
    "GT43R_1": {
        "text": "the person takes a box of tissues from the shelf.",
        "vid": "GT43R",
        "timestamps": [
            12.6,
            25.5
        ]
    },
    "GT43R_2": {
        "text": "the person turns on a light.",
        "vid": "GT43R",
        "timestamps": [
            2.1,
            9.3
        ]
    },
    "X95D0_0": {
        "text": "person drinking a glass of water.",
        "vid": "X95D0",
        "timestamps": [
            17.2,
            32.0
        ]
    },
    "DV6CH_0": {
        "text": "person they begin smiling.",
        "vid": "DV6CH",
        "timestamps": [
            24.2,
            30.6
        ]
    },
    "DV6CH_1": {
        "text": "a person opens their closet.",
        "vid": "DV6CH",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "DV6CH_2": {
        "text": "person opens closet.",
        "vid": "DV6CH",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "DV6CH_3": {
        "text": "person is seen putting clothes in their closet.",
        "vid": "DV6CH",
        "timestamps": [
            14.4,
            27.4
        ]
    },
    "DV6CH_4": {
        "text": "this person opened up their closet.",
        "vid": "DV6CH",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "HI4NV_0": {
        "text": "person holding some food on some dishes.",
        "vid": "HI4NV",
        "timestamps": [
            3.4,
            18.3
        ]
    },
    "HI4NV_1": {
        "text": "the person is also holding some food.",
        "vid": "HI4NV",
        "timestamps": [
            3.4,
            18.3
        ]
    },
    "96ATI_0": {
        "text": "a person is sneezing.",
        "vid": "96ATI",
        "timestamps": [
            5.8,
            15.9
        ]
    },
    "B4XZD_0": {
        "text": "person starts sneezing.",
        "vid": "B4XZD",
        "timestamps": [
            5.1,
            9.6
        ]
    },
    "ICOX1_0": {
        "text": "a person in their recreation room turns on the light.",
        "vid": "ICOX1",
        "timestamps": [
            16.9,
            23.8
        ]
    },
    "ICOX1_1": {
        "text": "person awakening o the sofa under a blanket sneezes.",
        "vid": "ICOX1",
        "timestamps": [
            7.9,
            15.8
        ]
    },
    "ICOX1_2": {
        "text": "person turns the light on.",
        "vid": "ICOX1",
        "timestamps": [
            16.9,
            23.8
        ]
    },
    "QQGU3_0": {
        "text": "a person opens a cabinet.",
        "vid": "QQGU3",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "QQGU3_1": {
        "text": "a person takes a box.",
        "vid": "QQGU3",
        "timestamps": [
            15.2,
            19.0
        ]
    },
    "QQGU3_2": {
        "text": "the person opens the doors to the cupboard.",
        "vid": "QQGU3",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "QQGU3_3": {
        "text": "person opens the box.",
        "vid": "QQGU3",
        "timestamps": [
            10.3,
            18.5
        ]
    },
    "QQGU3_4": {
        "text": "person holds a box.",
        "vid": "QQGU3",
        "timestamps": [
            7.7,
            15.0
        ]
    },
    "QQGU3_5": {
        "text": "a person opens a small cabinet door.",
        "vid": "QQGU3",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "Z2KJ5_0": {
        "text": "person takes food out of a bag.",
        "vid": "Z2KJ5",
        "timestamps": [
            4.9,
            16.0
        ]
    },
    "7EJUR_0": {
        "text": "person watching television on their laptop.",
        "vid": "7EJUR",
        "timestamps": [
            0.4,
            10.3
        ]
    },
    "7EJUR_1": {
        "text": "a person is cooking as the person watches television.",
        "vid": "7EJUR",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "7EJUR_2": {
        "text": "a person is cooking some food.",
        "vid": "7EJUR",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "7EJUR_3": {
        "text": "person takes some food from it.",
        "vid": "7EJUR",
        "timestamps": [
            10.6,
            16.9
        ]
    },
    "7EJUR_4": {
        "text": "person watching a video on a laptop.",
        "vid": "7EJUR",
        "timestamps": [
            0.4,
            10.3
        ]
    },
    "FFYL6_0": {
        "text": "a person puts a broom into the closet.",
        "vid": "FFYL6",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "FFYL6_1": {
        "text": "person takes out a box.",
        "vid": "FFYL6",
        "timestamps": [
            5.2,
            10.9
        ]
    },
    "FFYL6_2": {
        "text": "a person puts a broom away in a closet.",
        "vid": "FFYL6",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "FFYL6_3": {
        "text": "person takes a box out of the same  closet.",
        "vid": "FFYL6",
        "timestamps": [
            5.2,
            10.9
        ]
    },
    "FFYL6_4": {
        "text": "a person puts a broom inside a closet.",
        "vid": "FFYL6",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "FFYL6_5": {
        "text": "the person takes a box out.",
        "vid": "FFYL6",
        "timestamps": [
            5.2,
            10.9
        ]
    },
    "FFYL6_6": {
        "text": "person they pretend to start sneezing.",
        "vid": "FFYL6",
        "timestamps": [
            9.9,
            15.0
        ]
    },
    "YN3AA_0": {
        "text": "person eats a sandwich.",
        "vid": "YN3AA",
        "timestamps": [
            12.1,
            27.0
        ]
    },
    "YN3AA_1": {
        "text": "person they turn on the light.",
        "vid": "YN3AA",
        "timestamps": [
            9.5,
            13.5
        ]
    },
    "YE6UZ_0": {
        "text": "person she takes her phone from a drawer.",
        "vid": "YE6UZ",
        "timestamps": [
            15.0,
            23.0
        ]
    },
    "KMZDA_0": {
        "text": "person puts the dish on the table.",
        "vid": "KMZDA",
        "timestamps": [
            24.2,
            30.8
        ]
    },
    "LSCMZ_0": {
        "text": "person holding a pair of shoes.",
        "vid": "LSCMZ",
        "timestamps": [
            0.0,
            7.6
        ]
    },
    "LSCMZ_1": {
        "text": "the person takes a phone from somewhere.",
        "vid": "LSCMZ",
        "timestamps": [
            13.7,
            19.0
        ]
    },
    "5INX3_0": {
        "text": "person dressing by putting a jacket on.",
        "vid": "5INX3",
        "timestamps": [
            32.5,
            46.0
        ]
    },
    "F3M1Q_0": {
        "text": "person taking a drink out of a cup.",
        "vid": "F3M1Q",
        "timestamps": [
            9.4,
            16.4
        ]
    },
    "F3M1Q_1": {
        "text": "person throws them on the floor.",
        "vid": "F3M1Q",
        "timestamps": [
            0.7,
            6.0
        ]
    },
    "F3M1Q_2": {
        "text": "a person takes off their shoes.",
        "vid": "F3M1Q",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "F3M1Q_3": {
        "text": "person takes a drink from a glass nearby.",
        "vid": "F3M1Q",
        "timestamps": [
            9.4,
            16.4
        ]
    },
    "F3M1Q_4": {
        "text": "a person takes their shoes off in the kitchen.",
        "vid": "F3M1Q",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "IKJGO_0": {
        "text": "the person puts the book down.",
        "vid": "IKJGO",
        "timestamps": [
            22.5,
            28.4
        ]
    },
    "SR8IK_0": {
        "text": "person takes a drink from a glass.",
        "vid": "SR8IK",
        "timestamps": [
            4.6,
            14.9
        ]
    },
    "SR8IK_1": {
        "text": "person drinking a glass of water.",
        "vid": "SR8IK",
        "timestamps": [
            4.6,
            14.9
        ]
    },
    "SR8IK_2": {
        "text": "person take a drink from a cup on the table.",
        "vid": "SR8IK",
        "timestamps": [
            4.6,
            14.9
        ]
    },
    "WX711_0": {
        "text": "person drinking out of a cup.",
        "vid": "WX711",
        "timestamps": [
            14.8,
            22.5
        ]
    },
    "VNQTH_0": {
        "text": "a person puts clothes into their closet on a shelf.",
        "vid": "VNQTH",
        "timestamps": [
            1.6,
            6.6
        ]
    },
    "VNQTH_1": {
        "text": "person puts it on a shelf.",
        "vid": "VNQTH",
        "timestamps": [
            1.6,
            6.6
        ]
    },
    "VNQTH_2": {
        "text": "a person is putting clothes on the shelf.",
        "vid": "VNQTH",
        "timestamps": [
            1.6,
            6.6
        ]
    },
    "VNQTH_3": {
        "text": "person takes out their cell phone.",
        "vid": "VNQTH",
        "timestamps": [
            6.0,
            10.3
        ]
    },
    "VNQTH_4": {
        "text": "person starts laughing.",
        "vid": "VNQTH",
        "timestamps": [
            7.4,
            11.0
        ]
    },
    "BQA97_0": {
        "text": "person open a laptop.",
        "vid": "BQA97",
        "timestamps": [
            0.4,
            7.2
        ]
    },
    "99B6U_0": {
        "text": "this person puts some papers in the bag.",
        "vid": "99B6U",
        "timestamps": [
            16.9,
            22.5
        ]
    },
    "99B6U_1": {
        "text": "a person runs down the stairs with a book.",
        "vid": "99B6U",
        "timestamps": [
            0.9,
            14.2
        ]
    },
    "99B6U_2": {
        "text": "person puts the books into his backpack.",
        "vid": "99B6U",
        "timestamps": [
            16.6,
            23.8
        ]
    },
    "99B6U_3": {
        "text": "person puts the book into it.",
        "vid": "99B6U",
        "timestamps": [
            16.6,
            23.8
        ]
    },
    "RO8Y6_0": {
        "text": "person close the door.",
        "vid": "RO8Y6",
        "timestamps": [
            1.4,
            8.5
        ]
    },
    "JTXAM_0": {
        "text": "person turn off the light.",
        "vid": "JTXAM",
        "timestamps": [
            16.6,
            25.0
        ]
    },
    "JTXAM_1": {
        "text": "person closed the book.",
        "vid": "JTXAM",
        "timestamps": [
            13.8,
            19.1
        ]
    },
    "P6JGZ_0": {
        "text": "person opening a cabinet.",
        "vid": "P6JGZ",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "P6JGZ_1": {
        "text": "person closes the door.",
        "vid": "P6JGZ",
        "timestamps": [
            6.3,
            11.6
        ]
    },
    "P6JGZ_2": {
        "text": "person closed the cabinets.",
        "vid": "P6JGZ",
        "timestamps": [
            6.1,
            11.3
        ]
    },
    "P6JGZ_3": {
        "text": "the person opened some cabinets.",
        "vid": "P6JGZ",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "KO2MY_0": {
        "text": "a person is standing in the dining room laughing.",
        "vid": "KO2MY",
        "timestamps": [
            2.5,
            10.9
        ]
    },
    "KO2MY_1": {
        "text": "a person laughs to themselves.",
        "vid": "KO2MY",
        "timestamps": [
            2.5,
            10.9
        ]
    },
    "PNRFK_0": {
        "text": "a person is dressing by a flight of stairs.",
        "vid": "PNRFK",
        "timestamps": [
            0.0,
            13.3
        ]
    },
    "PNRFK_1": {
        "text": "a person gets dressed in some clothes.",
        "vid": "PNRFK",
        "timestamps": [
            0.0,
            13.3
        ]
    },
    "26RQN_0": {
        "text": "the person starts washing a table.",
        "vid": "26RQN",
        "timestamps": [
            22.0,
            35.0
        ]
    },
    "EJY5V_0": {
        "text": "person looks out the window.",
        "vid": "EJY5V",
        "timestamps": [
            17.2,
            22.0
        ]
    },
    "J1KLV_0": {
        "text": "the person opens the door at the top.",
        "vid": "J1KLV",
        "timestamps": [
            16.2,
            26.4
        ]
    },
    "J1KLV_1": {
        "text": "person closes the door behind them.",
        "vid": "J1KLV",
        "timestamps": [
            23.5,
            30.0
        ]
    },
    "OXCDM_0": {
        "text": "another person comes running into the entryway holding a box.",
        "vid": "OXCDM",
        "timestamps": [
            6.5,
            15.5
        ]
    },
    "ENOLD_0": {
        "text": "person watching television.",
        "vid": "ENOLD",
        "timestamps": [
            0.0,
            6.7
        ]
    },
    "FRSBQ_0": {
        "text": "the same person than starts undressing next to the cabinet.",
        "vid": "FRSBQ",
        "timestamps": [
            20.3,
            33.0
        ]
    },
    "0FM93_0": {
        "text": "person closing the door behind them.",
        "vid": "0FM93",
        "timestamps": [
            23.0,
            39.0
        ]
    },
    "0FM93_1": {
        "text": "person slowly closes the door.",
        "vid": "0FM93",
        "timestamps": [
            23.0,
            39.0
        ]
    },
    "0FM93_2": {
        "text": "person closes a door.",
        "vid": "0FM93",
        "timestamps": [
            23.0,
            39.0
        ]
    },
    "3G1OQ_0": {
        "text": "person walks towards the mirror to fix their hair.",
        "vid": "3G1OQ",
        "timestamps": [
            22.7,
            28.0
        ]
    },
    "3G1OQ_1": {
        "text": "person fix their hair in the mirror.",
        "vid": "3G1OQ",
        "timestamps": [
            22.7,
            28.0
        ]
    },
    "MRZ44_0": {
        "text": "person eating a sandwich.",
        "vid": "MRZ44",
        "timestamps": [
            9.6,
            15.3
        ]
    },
    "MRZ44_1": {
        "text": "person eating something.",
        "vid": "MRZ44",
        "timestamps": [
            9.6,
            15.3
        ]
    },
    "KTDG0_0": {
        "text": "person is closing door to closet.",
        "vid": "KTDG0",
        "timestamps": [
            5.7,
            11.1
        ]
    },
    "W97NR_0": {
        "text": "person takes a drink of a glass of water.",
        "vid": "W97NR",
        "timestamps": [
            15.8,
            29.0
        ]
    },
    "81R72_0": {
        "text": "person close the open door to their right.",
        "vid": "81R72",
        "timestamps": [
            22.9,
            29.8
        ]
    },
    "81R72_1": {
        "text": "person closing the doorknob.",
        "vid": "81R72",
        "timestamps": [
            22.9,
            29.8
        ]
    },
    "13IS9_0": {
        "text": "person they stand up.",
        "vid": "13IS9",
        "timestamps": [
            12.2,
            22.2
        ]
    },
    "13IS9_1": {
        "text": "person putting their shoes on.",
        "vid": "13IS9",
        "timestamps": [
            3.0,
            14.2
        ]
    },
    "13IS9_2": {
        "text": "a person puts some shoes on.",
        "vid": "13IS9",
        "timestamps": [
            3.0,
            14.2
        ]
    },
    "13IS9_3": {
        "text": "a person is sitting down putting on their shoes.",
        "vid": "13IS9",
        "timestamps": [
            3.0,
            14.2
        ]
    },
    "VHD24_0": {
        "text": "person they begin pouring themselves some medicine from a bottle.",
        "vid": "VHD24",
        "timestamps": [
            18.2,
            23.4
        ]
    },
    "LQMXW_0": {
        "text": "a person is walking in a room holding towel.",
        "vid": "LQMXW",
        "timestamps": [
            0.0,
            16.8
        ]
    },
    "LQMXW_1": {
        "text": "person put the towel on the chair.",
        "vid": "LQMXW",
        "timestamps": [
            11.2,
            18.4
        ]
    },
    "SAO1A_0": {
        "text": "person takes a drink from a cup.",
        "vid": "SAO1A",
        "timestamps": [
            3.1,
            8.8
        ]
    },
    "FLLUJ_0": {
        "text": "person closes a window.",
        "vid": "FLLUJ",
        "timestamps": [
            12.9,
            26.8
        ]
    },
    "FLLUJ_1": {
        "text": "person closes the window.",
        "vid": "FLLUJ",
        "timestamps": [
            12.9,
            26.8
        ]
    },
    "FLLUJ_2": {
        "text": "person tried to close the window.",
        "vid": "FLLUJ",
        "timestamps": [
            12.9,
            26.8
        ]
    },
    "REWLB_0": {
        "text": "person eating food from a plate.",
        "vid": "REWLB",
        "timestamps": [
            16.9,
            29.0
        ]
    },
    "8TZSC_0": {
        "text": "person fixing their hair.",
        "vid": "8TZSC",
        "timestamps": [
            10.2,
            19.0
        ]
    },
    "2FPB3_0": {
        "text": "a person holds an orange book.",
        "vid": "2FPB3",
        "timestamps": [
            0.0,
            13.3
        ]
    },
    "2FPB3_1": {
        "text": "person put the book down.",
        "vid": "2FPB3",
        "timestamps": [
            8.0,
            15.8
        ]
    },
    "2FPB3_2": {
        "text": "a person is sneezing into a book.",
        "vid": "2FPB3",
        "timestamps": [
            3.2,
            10.8
        ]
    },
    "TNDT2_0": {
        "text": "person eating food in a basement.",
        "vid": "TNDT2",
        "timestamps": [
            16.0,
            22.0
        ]
    },
    "TNDT2_1": {
        "text": "person finally eat something.",
        "vid": "TNDT2",
        "timestamps": [
            16.0,
            22.0
        ]
    },
    "TNDT2_2": {
        "text": "person open laptop.",
        "vid": "TNDT2",
        "timestamps": [
            4.5,
            12.1
        ]
    },
    "TNDT2_3": {
        "text": "person opening a laptop.",
        "vid": "TNDT2",
        "timestamps": [
            4.5,
            12.1
        ]
    },
    "TNDT2_4": {
        "text": "person eating food from a plate.",
        "vid": "TNDT2",
        "timestamps": [
            16.0,
            22.0
        ]
    },
    "GHJ3Q_0": {
        "text": "this person puts the pillow down.",
        "vid": "GHJ3Q",
        "timestamps": [
            5.2,
            10.4
        ]
    },
    "GHJ3Q_1": {
        "text": "person puts the pillow down.",
        "vid": "GHJ3Q",
        "timestamps": [
            5.2,
            10.4
        ]
    },
    "X8JVY_0": {
        "text": "person closes the door.",
        "vid": "X8JVY",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "X8JVY_1": {
        "text": "the person is opening a bag.",
        "vid": "X8JVY",
        "timestamps": [
            3.0,
            8.9
        ]
    },
    "X8JVY_2": {
        "text": "a person is closing a door.",
        "vid": "X8JVY",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "QVBTC_0": {
        "text": "there is a person looking out a bathroom window.",
        "vid": "QVBTC",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "QVBTC_1": {
        "text": "a person smiles as they watch something out the window.",
        "vid": "QVBTC",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "OVFVJ_0": {
        "text": "person begins undressing.",
        "vid": "OVFVJ",
        "timestamps": [
            22.1,
            34.0
        ]
    },
    "OVFVJ_1": {
        "text": "person takes a towel from the cabinet.",
        "vid": "OVFVJ",
        "timestamps": [
            12.5,
            26.8
        ]
    },
    "4GLAP_0": {
        "text": "a person throws some shoes down.",
        "vid": "4GLAP",
        "timestamps": [
            16.1,
            20.7
        ]
    },
    "MLHCK_0": {
        "text": "a person runs in place.",
        "vid": "MLHCK",
        "timestamps": [
            0.0,
            7.9
        ]
    },
    "NJANX_0": {
        "text": "a person is tidying the shelf.",
        "vid": "NJANX",
        "timestamps": [
            11.4,
            17.4
        ]
    },
    "BQZ52_0": {
        "text": "a person opens the closet.",
        "vid": "BQZ52",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "BQZ52_1": {
        "text": "person opens the door bends down.",
        "vid": "BQZ52",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "IUETR_0": {
        "text": "a person opens a door.",
        "vid": "IUETR",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "IUETR_1": {
        "text": "person opens up the door go into the bedroom sneeze.",
        "vid": "IUETR",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "IUETR_2": {
        "text": "person walks through the doorway.",
        "vid": "IUETR",
        "timestamps": [
            1.9,
            8.1
        ]
    },
    "IUETR_3": {
        "text": "a person opens the door.",
        "vid": "IUETR",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "KZR42_0": {
        "text": "person she takes a bottle of something out.",
        "vid": "KZR42",
        "timestamps": [
            8.4,
            16.7
        ]
    },
    "FVINY_0": {
        "text": "a person is sitting on a chair reading a book.",
        "vid": "FVINY",
        "timestamps": [
            0.0,
            14.6
        ]
    },
    "FVINY_1": {
        "text": "a person is looking at a book.",
        "vid": "FVINY",
        "timestamps": [
            0.0,
            14.6
        ]
    },
    "FVINY_2": {
        "text": "a person sat on a chair reading a book.",
        "vid": "FVINY",
        "timestamps": [
            0.0,
            14.6
        ]
    },
    "3OLX3_0": {
        "text": "person puts it on a table.",
        "vid": "3OLX3",
        "timestamps": [
            15.1,
            22.1
        ]
    },
    "POACA_0": {
        "text": "person looking a a book.",
        "vid": "POACA",
        "timestamps": [
            25.2,
            31.0
        ]
    },
    "R971Z_0": {
        "text": "person they stand up.",
        "vid": "R971Z",
        "timestamps": [
            14.0,
            23.4
        ]
    },
    "R971Z_1": {
        "text": "person fixing their hair.",
        "vid": "R971Z",
        "timestamps": [
            20.7,
            30.6
        ]
    },
    "R971Z_2": {
        "text": "person puts on the shoes.",
        "vid": "R971Z",
        "timestamps": [
            11.1,
            19.8
        ]
    },
    "R971Z_3": {
        "text": "person smile at themselves in the mirror.",
        "vid": "R971Z",
        "timestamps": [
            19.4,
            25.0
        ]
    },
    "R971Z_4": {
        "text": "a person opens a closet.",
        "vid": "R971Z",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "R971Z_5": {
        "text": "a person opens up a closet.",
        "vid": "R971Z",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "R971Z_6": {
        "text": "a person opens the door to a walk-in closet.",
        "vid": "R971Z",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "R971Z_7": {
        "text": "person adjusts their hair holding a mirror.",
        "vid": "R971Z",
        "timestamps": [
            19.6,
            32.8
        ]
    },
    "VXOE4_0": {
        "text": "a person is in a pantry standing on a chair.",
        "vid": "VXOE4",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "VXOE4_1": {
        "text": "person start working on their laptop.",
        "vid": "VXOE4",
        "timestamps": [
            11.0,
            26.6
        ]
    },
    "JT537_0": {
        "text": "person put the broom down.",
        "vid": "JT537",
        "timestamps": [
            16.9,
            23.1
        ]
    },
    "JT537_1": {
        "text": "person put down broom.",
        "vid": "JT537",
        "timestamps": [
            16.9,
            23.1
        ]
    },
    "W5P6B_0": {
        "text": "a person sits in a chair.",
        "vid": "W5P6B",
        "timestamps": [
            9.3,
            17.3
        ]
    },
    "U9NI5_0": {
        "text": "person turned the lights on.",
        "vid": "U9NI5",
        "timestamps": [
            11.3,
            16.6
        ]
    },
    "U9NI5_1": {
        "text": "a person is standing in the kitchen eating a sandwich.",
        "vid": "U9NI5",
        "timestamps": [
            13.0,
            22.3
        ]
    },
    "U9NI5_2": {
        "text": "person watches themselves eat.",
        "vid": "U9NI5",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "U9NI5_3": {
        "text": "person drinking from a cup.",
        "vid": "U9NI5",
        "timestamps": [
            3.3,
            11.2
        ]
    },
    "U9NI5_4": {
        "text": "the person was eating a sandwich.",
        "vid": "U9NI5",
        "timestamps": [
            13.0,
            22.3
        ]
    },
    "U9NI5_5": {
        "text": "person the runs to a mirror on the wall.",
        "vid": "U9NI5",
        "timestamps": [
            9.4,
            16.5
        ]
    },
    "WP5RH_0": {
        "text": "a person runs through a doorway.",
        "vid": "WP5RH",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "WP5RH_1": {
        "text": "person runs into kitchen.",
        "vid": "WP5RH",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "WP5RH_2": {
        "text": "a person is running in place under a doorway.",
        "vid": "WP5RH",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "WP5RH_3": {
        "text": "person run out room.",
        "vid": "WP5RH",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "E89S9_0": {
        "text": "a person is sitting on a chair.",
        "vid": "E89S9",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "E89S9_1": {
        "text": "the person sits in a chair.",
        "vid": "E89S9",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "0KZYF_0": {
        "text": "person opens the door.",
        "vid": "0KZYF",
        "timestamps": [
            5.8,
            12.3
        ]
    },
    "0KZYF_1": {
        "text": "a person is eating a sandwich.",
        "vid": "0KZYF",
        "timestamps": [
            2.3,
            7.8
        ]
    },
    "0KZYF_2": {
        "text": "person eating something off of a plate.",
        "vid": "0KZYF",
        "timestamps": [
            2.3,
            7.8
        ]
    },
    "0KZYF_3": {
        "text": "proceeds to keep eating in a happy manner.",
        "vid": "0KZYF",
        "timestamps": [
            2.3,
            7.8
        ]
    },
    "0KZYF_4": {
        "text": "person continuing to eat the sandwich.",
        "vid": "0KZYF",
        "timestamps": [
            2.3,
            7.8
        ]
    },
    "0KZYF_5": {
        "text": "person eating a sandwich.",
        "vid": "0KZYF",
        "timestamps": [
            2.3,
            7.8
        ]
    },
    "0KZYF_6": {
        "text": "a person walks in holding dishes.",
        "vid": "0KZYF",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "0KZYF_7": {
        "text": "the person starts smiling.",
        "vid": "0KZYF",
        "timestamps": [
            25.8,
            32.0
        ]
    },
    "0KZYF_8": {
        "text": "person opens a door.",
        "vid": "0KZYF",
        "timestamps": [
            5.8,
            12.3
        ]
    },
    "LD9EC_0": {
        "text": "another person is sitting on the floor.",
        "vid": "LD9EC",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "T56KO_0": {
        "text": "the person begins undressing.",
        "vid": "T56KO",
        "timestamps": [
            21.2,
            28.1
        ]
    },
    "T56KO_1": {
        "text": "person takes off some clothes.",
        "vid": "T56KO",
        "timestamps": [
            8.1,
            15.4
        ]
    },
    "KT2SV_0": {
        "text": "a person awakens in their bedroom laying on a pillow.",
        "vid": "KT2SV",
        "timestamps": [
            15.0,
            25.3
        ]
    },
    "VE6GK_0": {
        "text": "person sitting down to open a book to read.",
        "vid": "VE6GK",
        "timestamps": [
            24.7,
            32.0
        ]
    },
    "VE6GK_1": {
        "text": "person read a book.",
        "vid": "VE6GK",
        "timestamps": [
            24.7,
            32.0
        ]
    },
    "HXUI5_0": {
        "text": "the person takes out their phone.",
        "vid": "HXUI5",
        "timestamps": [
            34.0,
            39.0
        ]
    },
    "HXUI5_1": {
        "text": "a person dresses up in a jacket.",
        "vid": "HXUI5",
        "timestamps": [
            13.4,
            28.7
        ]
    },
    "HXUI5_2": {
        "text": "person fixing their hair.",
        "vid": "HXUI5",
        "timestamps": [
            29.2,
            36.1
        ]
    },
    "HXUI5_3": {
        "text": "a person puts on shoes.",
        "vid": "HXUI5",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "HXUI5_4": {
        "text": "person takes out a phone.",
        "vid": "HXUI5",
        "timestamps": [
            34.0,
            39.0
        ]
    },
    "HXUI5_5": {
        "text": "person fixes their hair.",
        "vid": "HXUI5",
        "timestamps": [
            29.2,
            36.1
        ]
    },
    "HXUI5_6": {
        "text": "a person is putting on some shoes.",
        "vid": "HXUI5",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "HXUI5_7": {
        "text": "a person is also dressing.",
        "vid": "HXUI5",
        "timestamps": [
            13.4,
            28.7
        ]
    },
    "TR652_0": {
        "text": "the person takes a pillow from the shelf.",
        "vid": "TR652",
        "timestamps": [
            8.7,
            15.6
        ]
    },
    "TR652_1": {
        "text": "person reading book.",
        "vid": "TR652",
        "timestamps": [
            0.0,
            11.6
        ]
    },
    "TR652_2": {
        "text": "a person is reading a book in the laundry room.",
        "vid": "TR652",
        "timestamps": [
            0.0,
            11.6
        ]
    },
    "3HLP7_0": {
        "text": "a person closes the door.",
        "vid": "3HLP7",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "3HLP7_1": {
        "text": "a person closes the door to the room.",
        "vid": "3HLP7",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "XPXWY_0": {
        "text": "person opens the door.",
        "vid": "XPXWY",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "XPXWY_1": {
        "text": "person opened the door.",
        "vid": "XPXWY",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "XPXWY_2": {
        "text": "a person opened a pantry door.",
        "vid": "XPXWY",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "XPXWY_3": {
        "text": "a person opens a pantry door.",
        "vid": "XPXWY",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "XPXWY_4": {
        "text": "person pours the liquid in it into a cup.",
        "vid": "XPXWY",
        "timestamps": [
            21.9,
            28.3
        ]
    },
    "XPXWY_5": {
        "text": "a person starts sneezing into their phone.",
        "vid": "XPXWY",
        "timestamps": [
            4.1,
            15.6
        ]
    },
    "FK143_0": {
        "text": "person they take the medicine.",
        "vid": "FK143",
        "timestamps": [
            31.2,
            37.0
        ]
    },
    "FK143_1": {
        "text": "the person takes out a bottle of medicine.",
        "vid": "FK143",
        "timestamps": [
            31.2,
            37.0
        ]
    },
    "FK143_2": {
        "text": "a person is opening a closet door.",
        "vid": "FK143",
        "timestamps": [
            0.0,
            11.2
        ]
    },
    "FK143_3": {
        "text": "person pours some into a small cup.",
        "vid": "FK143",
        "timestamps": [
            20.2,
            27.6
        ]
    },
    "FK143_4": {
        "text": "person take out some medicine.",
        "vid": "FK143",
        "timestamps": [
            31.2,
            37.0
        ]
    },
    "JEB7V_0": {
        "text": "person sitting on bed looks out window.",
        "vid": "JEB7V",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "JEB7V_1": {
        "text": "person starts eating.",
        "vid": "JEB7V",
        "timestamps": [
            4.2,
            11.5
        ]
    },
    "JEB7V_2": {
        "text": "a person is sitting down eating.",
        "vid": "JEB7V",
        "timestamps": [
            4.2,
            11.5
        ]
    },
    "JEB7V_3": {
        "text": "person looks at box puts food in mouth multiple times.",
        "vid": "JEB7V",
        "timestamps": [
            23.1,
            28.2
        ]
    },
    "JEB7V_4": {
        "text": "a person is eating on the bed.",
        "vid": "JEB7V",
        "timestamps": [
            4.2,
            11.5
        ]
    },
    "YMJ6E_0": {
        "text": "person opens the door.",
        "vid": "YMJ6E",
        "timestamps": [
            1.4,
            9.4
        ]
    },
    "YMJ6E_1": {
        "text": "a person opens the door.",
        "vid": "YMJ6E",
        "timestamps": [
            1.4,
            9.4
        ]
    },
    "47RAA_0": {
        "text": "person takes out the phone.",
        "vid": "47RAA",
        "timestamps": [
            17.2,
            33.4
        ]
    },
    "47RAA_1": {
        "text": "the person takes out their phone.",
        "vid": "47RAA",
        "timestamps": [
            17.2,
            33.4
        ]
    },
    "E5ZF5_0": {
        "text": "person eats some food.",
        "vid": "E5ZF5",
        "timestamps": [
            6.0,
            12.3
        ]
    },
    "E5ZF5_1": {
        "text": "person snuggles up with a blanket.",
        "vid": "E5ZF5",
        "timestamps": [
            22.6,
            37.0
        ]
    },
    "E5ZF5_2": {
        "text": "person begin snuggling with a blanket on the couch.",
        "vid": "E5ZF5",
        "timestamps": [
            22.6,
            37.0
        ]
    },
    "E5ZF5_3": {
        "text": "the person took a drink from a cup.",
        "vid": "E5ZF5",
        "timestamps": [
            13.7,
            20.9
        ]
    },
    "E5ZF5_4": {
        "text": "person they put their food away.",
        "vid": "E5ZF5",
        "timestamps": [
            10.5,
            17.2
        ]
    },
    "E5ZF5_5": {
        "text": "person eating food.",
        "vid": "E5ZF5",
        "timestamps": [
            6.0,
            12.3
        ]
    },
    "C6C7Q_0": {
        "text": "a person awakens from a deep sleep.",
        "vid": "C6C7Q",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "C6C7Q_1": {
        "text": "person they flip on a nightstand light.",
        "vid": "C6C7Q",
        "timestamps": [
            11.0,
            16.2
        ]
    },
    "C6C7Q_2": {
        "text": "person flip the light off.",
        "vid": "C6C7Q",
        "timestamps": [
            11.0,
            16.2
        ]
    },
    "C6C7Q_3": {
        "text": "person turns on a light.",
        "vid": "C6C7Q",
        "timestamps": [
            11.0,
            16.2
        ]
    },
    "C6C7Q_4": {
        "text": "person they snuggle back into their blanket.",
        "vid": "C6C7Q",
        "timestamps": [
            23.1,
            32.7
        ]
    },
    "D0Y4L_0": {
        "text": "person closes the door.",
        "vid": "D0Y4L",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "D0Y4L_1": {
        "text": "a person closes the door to outside.",
        "vid": "D0Y4L",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "HSWPR_0": {
        "text": "the person is playing with the switch for the light.",
        "vid": "HSWPR",
        "timestamps": [
            6.4,
            12.8
        ]
    },
    "HSWPR_1": {
        "text": "a person is putting a glass on a bedside shelf.",
        "vid": "HSWPR",
        "timestamps": [
            2.3,
            6.6
        ]
    },
    "BIJYC_0": {
        "text": "person that they start talking on their cell phone.",
        "vid": "BIJYC",
        "timestamps": [
            20.6,
            36.0
        ]
    },
    "BIJYC_1": {
        "text": "person next talking on a phone in a bedroom.",
        "vid": "BIJYC",
        "timestamps": [
            20.6,
            36.0
        ]
    },
    "BIJYC_2": {
        "text": "person begin running in place.",
        "vid": "BIJYC",
        "timestamps": [
            24.8,
            36.0
        ]
    },
    "BIJYC_3": {
        "text": "person running in place.",
        "vid": "BIJYC",
        "timestamps": [
            24.8,
            36.0
        ]
    },
    "BIJYC_4": {
        "text": "person beginning to run in place.",
        "vid": "BIJYC",
        "timestamps": [
            24.8,
            36.0
        ]
    },
    "BIJYC_5": {
        "text": "person continues running as he talks on it.",
        "vid": "BIJYC",
        "timestamps": [
            24.8,
            36.0
        ]
    },
    "7MRKY_0": {
        "text": "the person closes a laptop that is sitting open.",
        "vid": "7MRKY",
        "timestamps": [
            29.9,
            36.1
        ]
    },
    "7MRKY_1": {
        "text": "person close a laptop.",
        "vid": "7MRKY",
        "timestamps": [
            29.9,
            36.1
        ]
    },
    "7MRKY_2": {
        "text": "person closes a laptop.",
        "vid": "7MRKY",
        "timestamps": [
            29.9,
            36.1
        ]
    },
    "FQ2Q3_0": {
        "text": "person watching television instead.",
        "vid": "FQ2Q3",
        "timestamps": [
            11.9,
            16.0
        ]
    },
    "2KMGY_0": {
        "text": "a person was sitting on the floor.",
        "vid": "2KMGY",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "2KMGY_1": {
        "text": "person takes a cup from a table.",
        "vid": "2KMGY",
        "timestamps": [
            5.9,
            11.5
        ]
    },
    "W019T_0": {
        "text": "person start cooking.",
        "vid": "W019T",
        "timestamps": [
            14.1,
            26.8
        ]
    },
    "R5WMI_0": {
        "text": "a person takes some pictures on a camera.",
        "vid": "R5WMI",
        "timestamps": [
            2.5,
            7.2
        ]
    },
    "5OV3M_0": {
        "text": "person drinking water from a glass.",
        "vid": "5OV3M",
        "timestamps": [
            18.2,
            25.0
        ]
    },
    "Q0IHP_0": {
        "text": "person takes a drink from a glass.",
        "vid": "Q0IHP",
        "timestamps": [
            22.7,
            32.5
        ]
    },
    "Q0IHP_1": {
        "text": "person proceeds to take a drink from a cup.",
        "vid": "Q0IHP",
        "timestamps": [
            22.7,
            32.5
        ]
    },
    "Q0IHP_2": {
        "text": "person adjusts the heat.",
        "vid": "Q0IHP",
        "timestamps": [
            16.0,
            21.9
        ]
    },
    "Q0IHP_3": {
        "text": "the person takes a drink from a glass of juice.",
        "vid": "Q0IHP",
        "timestamps": [
            22.7,
            32.5
        ]
    },
    "136V6_0": {
        "text": "a person is walking through a doorway.",
        "vid": "136V6",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "136V6_1": {
        "text": "person reading a book.",
        "vid": "136V6",
        "timestamps": [
            13.7,
            26.7
        ]
    },
    "136V6_2": {
        "text": "person decompressing for a few minutes by reading a book.",
        "vid": "136V6",
        "timestamps": [
            13.7,
            26.7
        ]
    },
    "136V6_3": {
        "text": "the person puts the book down.",
        "vid": "136V6",
        "timestamps": [
            26.0,
            31.0
        ]
    },
    "136V6_4": {
        "text": "person closed the door behind them.",
        "vid": "136V6",
        "timestamps": [
            1.1,
            8.3
        ]
    },
    "4BIMI_0": {
        "text": "a person is laughing as they kick off their shoes.",
        "vid": "4BIMI",
        "timestamps": [
            4.9,
            22.4
        ]
    },
    "4BIMI_1": {
        "text": "person takes a cup.",
        "vid": "4BIMI",
        "timestamps": [
            18.8,
            23.7
        ]
    },
    "4BIMI_2": {
        "text": "person opens the pantry door.",
        "vid": "4BIMI",
        "timestamps": [
            3.8,
            8.7
        ]
    },
    "4BIMI_3": {
        "text": "a person laughs to themselves.",
        "vid": "4BIMI",
        "timestamps": [
            4.9,
            22.4
        ]
    },
    "0Z1PC_0": {
        "text": "person puts the pillow in there.",
        "vid": "0Z1PC",
        "timestamps": [
            18.0,
            25.1
        ]
    },
    "0Z1PC_1": {
        "text": "the person opens a closet door.",
        "vid": "0Z1PC",
        "timestamps": [
            10.4,
            17.7
        ]
    },
    "0Z1PC_2": {
        "text": "person opens the doors of a closet.",
        "vid": "0Z1PC",
        "timestamps": [
            10.4,
            17.7
        ]
    },
    "0Z1PC_3": {
        "text": "person is holding a pillow.",
        "vid": "0Z1PC",
        "timestamps": [
            3.4,
            9.4
        ]
    },
    "0Z1PC_4": {
        "text": "the person is also tidying up the closet.",
        "vid": "0Z1PC",
        "timestamps": [
            11.8,
            28.8
        ]
    },
    "0Z1PC_5": {
        "text": "person closes the closet doors.",
        "vid": "0Z1PC",
        "timestamps": [
            25.0,
            32.5
        ]
    },
    "0Z1PC_6": {
        "text": "person puts a pillow.",
        "vid": "0Z1PC",
        "timestamps": [
            18.0,
            25.1
        ]
    },
    "AF5BS_0": {
        "text": "person they put down the phone.",
        "vid": "AF5BS",
        "timestamps": [
            13.4,
            18.8
        ]
    },
    "2ZICJ_0": {
        "text": "person close a cabinet.",
        "vid": "2ZICJ",
        "timestamps": [
            27.3,
            33.6
        ]
    },
    "2ZICJ_1": {
        "text": "person they open up a refrigerator.",
        "vid": "2ZICJ",
        "timestamps": [
            4.5,
            12.4
        ]
    },
    "2ZICJ_2": {
        "text": "person opens a refrigerator door.",
        "vid": "2ZICJ",
        "timestamps": [
            4.5,
            12.4
        ]
    },
    "2ZICJ_3": {
        "text": "person stand up.",
        "vid": "2ZICJ",
        "timestamps": [
            28.7,
            36.0
        ]
    },
    "2ZICJ_4": {
        "text": "person closes the cabinet door where the mug is.",
        "vid": "2ZICJ",
        "timestamps": [
            27.3,
            33.6
        ]
    },
    "CYCEV_0": {
        "text": "another person is looking out the window.",
        "vid": "CYCEV",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "CYCEV_1": {
        "text": "person holding some food.",
        "vid": "CYCEV",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "CYCEV_2": {
        "text": "the person holding the tray drinks from the cup.",
        "vid": "CYCEV",
        "timestamps": [
            2.3,
            9.7
        ]
    },
    "02DPI_0": {
        "text": "person drinking a glass of water.",
        "vid": "02DPI",
        "timestamps": [
            23.4,
            30.5
        ]
    },
    "02DPI_1": {
        "text": "person watching something on a laptop.",
        "vid": "02DPI",
        "timestamps": [
            19.7,
            26.0
        ]
    },
    "02DPI_2": {
        "text": "the person is also watching television.",
        "vid": "02DPI",
        "timestamps": [
            0.0,
            15.2
        ]
    },
    "02DPI_3": {
        "text": "person drinking water from a glass.",
        "vid": "02DPI",
        "timestamps": [
            23.4,
            30.5
        ]
    },
    "X9LP4_0": {
        "text": "person reads a book.",
        "vid": "X9LP4",
        "timestamps": [
            16.7,
            30.7
        ]
    },
    "X9LP4_1": {
        "text": "a person takes a mini vacuum.",
        "vid": "X9LP4",
        "timestamps": [
            0.0,
            3.1
        ]
    },
    "8SXHK_0": {
        "text": "person they put the laptop down.",
        "vid": "8SXHK",
        "timestamps": [
            13.8,
            19.8
        ]
    },
    "8SXHK_1": {
        "text": "a person sits typing on a laptop computer.",
        "vid": "8SXHK",
        "timestamps": [
            13.8,
            19.8
        ]
    },
    "8SXHK_2": {
        "text": "the person puts the laptop down.",
        "vid": "8SXHK",
        "timestamps": [
            13.8,
            19.8
        ]
    },
    "9ZE0J_0": {
        "text": "a person runs up stairs.",
        "vid": "9ZE0J",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "9ZE0J_1": {
        "text": "a person runs up a staircase.",
        "vid": "9ZE0J",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "9ZE0J_2": {
        "text": "starts to talk to another person holding a towel.",
        "vid": "9ZE0J",
        "timestamps": [
            5.9,
            20.6
        ]
    },
    "9ZE0J_3": {
        "text": "one person runs up the stairs eating.",
        "vid": "9ZE0J",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "9ZE0J_4": {
        "text": "person putting a towel or cloth around their neck.",
        "vid": "9ZE0J",
        "timestamps": [
            12.5,
            19.0
        ]
    },
    "ZB5J4_0": {
        "text": "person they open the refrigerator.",
        "vid": "ZB5J4",
        "timestamps": [
            25.7,
            41.0
        ]
    },
    "QVD5B_0": {
        "text": "a person is in the entryway holding a bag.",
        "vid": "QVD5B",
        "timestamps": [
            0.0,
            14.8
        ]
    },
    "QUAFE_0": {
        "text": "person putting a bag on the shelf.",
        "vid": "QUAFE",
        "timestamps": [
            13.9,
            20.5
        ]
    },
    "QUAFE_1": {
        "text": "person a girl is taking clothes out a a washer.",
        "vid": "QUAFE",
        "timestamps": [
            0.7,
            14.6
        ]
    },
    "QUAFE_2": {
        "text": "a person is washing clothes.",
        "vid": "QUAFE",
        "timestamps": [
            0.7,
            14.6
        ]
    },
    "QMKZV_0": {
        "text": "a person undresses.",
        "vid": "QMKZV",
        "timestamps": [
            4.4,
            12.1
        ]
    },
    "QMKZV_1": {
        "text": "person put clothes away.",
        "vid": "QMKZV",
        "timestamps": [
            12.7,
            22.4
        ]
    },
    "QMKZV_2": {
        "text": "person starts undressing.",
        "vid": "QMKZV",
        "timestamps": [
            4.4,
            12.1
        ]
    },
    "QMKZV_3": {
        "text": "person begins to undress.",
        "vid": "QMKZV",
        "timestamps": [
            4.4,
            12.1
        ]
    },
    "CSPSU_0": {
        "text": "person drinking a glass of water.",
        "vid": "CSPSU",
        "timestamps": [
            0.8,
            7.6
        ]
    },
    "CSPSU_1": {
        "text": "a person drinking from a disposable cup.",
        "vid": "CSPSU",
        "timestamps": [
            0.8,
            7.6
        ]
    },
    "1440M_0": {
        "text": "person opening a closet door.",
        "vid": "1440M",
        "timestamps": [
            17.5,
            27.0
        ]
    },
    "1440M_1": {
        "text": "person start closing the door.",
        "vid": "1440M",
        "timestamps": [
            17.5,
            27.0
        ]
    },
    "1440M_2": {
        "text": "person closes a closet door.",
        "vid": "1440M",
        "timestamps": [
            17.5,
            27.0
        ]
    },
    "HA8S9_0": {
        "text": "person throws their shoes under a desk.",
        "vid": "HA8S9",
        "timestamps": [
            8.2,
            14.9
        ]
    },
    "WRCO6_0": {
        "text": "a person is smiling at a picture.",
        "vid": "WRCO6",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "KWHPI_0": {
        "text": "the person closes the open door behind them.",
        "vid": "KWHPI",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "KWHPI_1": {
        "text": "a person throws a bag onto a chair.",
        "vid": "KWHPI",
        "timestamps": [
            1.8,
            6.0
        ]
    },
    "L8CC0_0": {
        "text": "person so they start laughing.",
        "vid": "L8CC0",
        "timestamps": [
            26.9,
            37.0
        ]
    },
    "WPU76_0": {
        "text": "a woman takes a cup off a table.",
        "vid": "WPU76",
        "timestamps": [
            0.0,
            9.3
        ]
    },
    "WPU76_1": {
        "text": "person starts running.",
        "vid": "WPU76",
        "timestamps": [
            2.1,
            9.3
        ]
    },
    "CH41S_0": {
        "text": "a person is putting a broom in the closet.",
        "vid": "CH41S",
        "timestamps": [
            2.3,
            10.3
        ]
    },
    "AZPOX_0": {
        "text": "a person is holding a towel.",
        "vid": "AZPOX",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "DCRI5_0": {
        "text": "a person opens a closet door.",
        "vid": "DCRI5",
        "timestamps": [
            0.4,
            5.5
        ]
    },
    "DCRI5_1": {
        "text": "person puts something on the top shelf.",
        "vid": "DCRI5",
        "timestamps": [
            3.8,
            9.1
        ]
    },
    "DCRI5_2": {
        "text": "a man opens his closet door.",
        "vid": "DCRI5",
        "timestamps": [
            0.4,
            5.5
        ]
    },
    "K9EAZ_0": {
        "text": "a person is running the vacuum.",
        "vid": "K9EAZ",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "MVPPS_0": {
        "text": "a person pours a drink into a cup.",
        "vid": "MVPPS",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "OHOFG_0": {
        "text": "a person is eating some food.",
        "vid": "OHOFG",
        "timestamps": [
            22.3,
            33.0
        ]
    },
    "OHOFG_1": {
        "text": "a person sits on a chair by a table.",
        "vid": "OHOFG",
        "timestamps": [
            1.0,
            7.5
        ]
    },
    "OHOFG_2": {
        "text": "person sitting down in a chair.",
        "vid": "OHOFG",
        "timestamps": [
            1.0,
            7.5
        ]
    },
    "OHOFG_3": {
        "text": "person starts eating food from a plate.",
        "vid": "OHOFG",
        "timestamps": [
            22.3,
            33.0
        ]
    },
    "OHOFG_4": {
        "text": "person eat a snack.",
        "vid": "OHOFG",
        "timestamps": [
            22.3,
            33.0
        ]
    },
    "OHOFG_5": {
        "text": "the person is working at a desk eating from dishes.",
        "vid": "OHOFG",
        "timestamps": [
            22.3,
            33.0
        ]
    },
    "EW8GX_0": {
        "text": "person walks through a doorway.",
        "vid": "EW8GX",
        "timestamps": [
            15.4,
            20.7
        ]
    },
    "AEKYE_0": {
        "text": "person watching  themself in a mirror.",
        "vid": "AEKYE",
        "timestamps": [
            9.8,
            18.7
        ]
    },
    "AEKYE_1": {
        "text": "person finally eating a sandwich in a living room.",
        "vid": "AEKYE",
        "timestamps": [
            19.9,
            34.0
        ]
    },
    "AEKYE_2": {
        "text": "person snuggling with a pillow.",
        "vid": "AEKYE",
        "timestamps": [
            0.0,
            11.5
        ]
    },
    "AEKYE_3": {
        "text": "person eats the food.",
        "vid": "AEKYE",
        "timestamps": [
            19.5,
            34.0
        ]
    },
    "GCI2J_0": {
        "text": "the person takes a pair of running shoes from nearby.",
        "vid": "GCI2J",
        "timestamps": [
            8.3,
            19.3
        ]
    },
    "GCI2J_1": {
        "text": "person take shoes from the floor.",
        "vid": "GCI2J",
        "timestamps": [
            8.3,
            19.3
        ]
    },
    "GCI2J_2": {
        "text": "person takes some pictures.",
        "vid": "GCI2J",
        "timestamps": [
            6.1,
            14.1
        ]
    },
    "GCI2J_3": {
        "text": "a person holds a camera up.",
        "vid": "GCI2J",
        "timestamps": [
            0.0,
            11.8
        ]
    },
    "GCI2J_4": {
        "text": "the person puts the camera down.",
        "vid": "GCI2J",
        "timestamps": [
            8.3,
            17.3
        ]
    },
    "GN0M8_0": {
        "text": "person walk through a open doorway.",
        "vid": "GN0M8",
        "timestamps": [
            21.0,
            26.0
        ]
    },
    "N6FZ7_0": {
        "text": "a person runs into the living room.",
        "vid": "N6FZ7",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "N6FZ7_1": {
        "text": "person throws the blanket on the ground.",
        "vid": "N6FZ7",
        "timestamps": [
            8.2,
            12.8
        ]
    },
    "N6FZ7_2": {
        "text": "a person throws a blanket on the floor.",
        "vid": "N6FZ7",
        "timestamps": [
            7.6,
            13.7
        ]
    },
    "N6FZ7_3": {
        "text": "person throws the blanket onto the floor.",
        "vid": "N6FZ7",
        "timestamps": [
            7.6,
            13.7
        ]
    },
    "N6FZ7_4": {
        "text": "person runs over to use a vacuum.",
        "vid": "N6FZ7",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "N6FZ7_5": {
        "text": "a person runs into a room.",
        "vid": "N6FZ7",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "9YOI8_0": {
        "text": "person opening a window.",
        "vid": "9YOI8",
        "timestamps": [
            4.8,
            11.9
        ]
    },
    "9YOI8_1": {
        "text": "a person opens the window in the laundry room.",
        "vid": "9YOI8",
        "timestamps": [
            4.8,
            11.9
        ]
    },
    "9YOI8_2": {
        "text": "person close the window.",
        "vid": "9YOI8",
        "timestamps": [
            24.6,
            30.3
        ]
    },
    "9YOI8_3": {
        "text": "person take a drink from the cup they are holding.",
        "vid": "9YOI8",
        "timestamps": [
            14.8,
            22.7
        ]
    },
    "9YOI8_4": {
        "text": "person drinking from the cup.",
        "vid": "9YOI8",
        "timestamps": [
            14.8,
            22.7
        ]
    },
    "9YOI8_5": {
        "text": "person closes the window.",
        "vid": "9YOI8",
        "timestamps": [
            24.6,
            30.3
        ]
    },
    "9YOI8_6": {
        "text": "person opens the window.",
        "vid": "9YOI8",
        "timestamps": [
            4.8,
            11.9
        ]
    },
    "RJD1Z_0": {
        "text": "a person is grasping a light to turn it on.",
        "vid": "RJD1Z",
        "timestamps": [
            0.0,
            11.2
        ]
    },
    "WF89D_0": {
        "text": "a person takes a drink from a cup.",
        "vid": "WF89D",
        "timestamps": [
            6.6,
            12.6
        ]
    },
    "WF89D_1": {
        "text": "the person laughs.",
        "vid": "WF89D",
        "timestamps": [
            1.0,
            7.2
        ]
    },
    "FDDDG_0": {
        "text": "a person is in the kitchen cooking food.",
        "vid": "FDDDG",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "FDDDG_1": {
        "text": "person takes a phone.",
        "vid": "FDDDG",
        "timestamps": [
            1.8,
            6.3
        ]
    },
    "FDDDG_2": {
        "text": "a person is cooking at a stove.",
        "vid": "FDDDG",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "OB660_0": {
        "text": "person they throw off the blanket.",
        "vid": "OB660",
        "timestamps": [
            7.4,
            12.3
        ]
    },
    "OB660_1": {
        "text": "person runs to look out the window.",
        "vid": "OB660",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "OB660_2": {
        "text": "person throws a blanket off of them.",
        "vid": "OB660",
        "timestamps": [
            7.4,
            12.3
        ]
    },
    "OB660_3": {
        "text": "person run over to the window to look outside.",
        "vid": "OB660",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "OB660_4": {
        "text": "person runs to the window.",
        "vid": "OB660",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "7LWW3_0": {
        "text": "person looking at a book.",
        "vid": "7LWW3",
        "timestamps": [
            1.8,
            23.6
        ]
    },
    "7LWW3_1": {
        "text": "the person takes the food somewhere.",
        "vid": "7LWW3",
        "timestamps": [
            20.2,
            27.8
        ]
    },
    "MVX03_0": {
        "text": "person they take their shoes off.",
        "vid": "MVX03",
        "timestamps": [
            16.4,
            25.2
        ]
    },
    "TRVEA_0": {
        "text": "a person sits on a bed with a pillow.",
        "vid": "TRVEA",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "TRVEA_1": {
        "text": "this person throws the pillow on the floor.",
        "vid": "TRVEA",
        "timestamps": [
            3.6,
            9.2
        ]
    },
    "TRVEA_2": {
        "text": "a person throws a pillow.",
        "vid": "TRVEA",
        "timestamps": [
            3.6,
            9.2
        ]
    },
    "TRVEA_3": {
        "text": "person throwing the pillow on the floor.",
        "vid": "TRVEA",
        "timestamps": [
            3.6,
            9.2
        ]
    },
    "TRVEA_4": {
        "text": "a person sits on their bed with a pillow.",
        "vid": "TRVEA",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "W0YVE_0": {
        "text": "a person runs up to a glass door.",
        "vid": "W0YVE",
        "timestamps": [
            4.4,
            10.0
        ]
    },
    "W0YVE_1": {
        "text": "the person puts the sandwich down.",
        "vid": "W0YVE",
        "timestamps": [
            7.5,
            14.1
        ]
    },
    "W0YVE_2": {
        "text": "a person runs into the entryway.",
        "vid": "W0YVE",
        "timestamps": [
            4.4,
            10.0
        ]
    },
    "KE5EM_0": {
        "text": "person opens it up to take some clothes out.",
        "vid": "KE5EM",
        "timestamps": [
            4.6,
            9.3
        ]
    },
    "KE5EM_1": {
        "text": "a person is holding a bag of clothes.",
        "vid": "KE5EM",
        "timestamps": [
            4.8,
            10.3
        ]
    },
    "KE5EM_2": {
        "text": "person sitting down in a chair with a backpack.",
        "vid": "KE5EM",
        "timestamps": [
            0.9,
            7.1
        ]
    },
    "KE5EM_3": {
        "text": "person begins sneezing.",
        "vid": "KE5EM",
        "timestamps": [
            6.3,
            10.9
        ]
    },
    "FNBYE_0": {
        "text": "a person is also eating.",
        "vid": "FNBYE",
        "timestamps": [
            20.5,
            31.8
        ]
    },
    "FNBYE_1": {
        "text": "person open a box.",
        "vid": "FNBYE",
        "timestamps": [
            14.7,
            21.2
        ]
    },
    "FNBYE_2": {
        "text": "person eating a sandwich.",
        "vid": "FNBYE",
        "timestamps": [
            20.5,
            31.8
        ]
    },
    "FNBYE_3": {
        "text": "person takes a glass.",
        "vid": "FNBYE",
        "timestamps": [
            6.5,
            10.8
        ]
    },
    "FNBYE_4": {
        "text": "person opening a box.",
        "vid": "FNBYE",
        "timestamps": [
            14.7,
            21.2
        ]
    },
    "FNBYE_5": {
        "text": "person eat a sandwich stand up.",
        "vid": "FNBYE",
        "timestamps": [
            20.5,
            31.8
        ]
    },
    "KFLI0_0": {
        "text": "person turns the light off.",
        "vid": "KFLI0",
        "timestamps": [
            5.0,
            9.0
        ]
    },
    "KFLI0_1": {
        "text": "person turning off the light.",
        "vid": "KFLI0",
        "timestamps": [
            5.0,
            9.0
        ]
    },
    "OJYDD_0": {
        "text": "person pouring a glass of water from on the table.",
        "vid": "OJYDD",
        "timestamps": [
            21.1,
            33.2
        ]
    },
    "OJYDD_1": {
        "text": "person pouring a glass of wine in a living room.",
        "vid": "OJYDD",
        "timestamps": [
            21.1,
            33.2
        ]
    },
    "HNPX7_0": {
        "text": "person put the bag away.",
        "vid": "HNPX7",
        "timestamps": [
            25.2,
            31.0
        ]
    },
    "HNPX7_1": {
        "text": "the person sat in a hall opening a plastic bag.",
        "vid": "HNPX7",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "5SBEY_0": {
        "text": "person sits down on another bed.",
        "vid": "5SBEY",
        "timestamps": [
            12.0,
            16.0
        ]
    },
    "5SBEY_1": {
        "text": "person throws a bag down.",
        "vid": "5SBEY",
        "timestamps": [
            4.7,
            9.7
        ]
    },
    "5SBEY_2": {
        "text": "person takes a drink out of a cup.",
        "vid": "5SBEY",
        "timestamps": [
            11.9,
            16.0
        ]
    },
    "PAW5E_0": {
        "text": "the second person laughs.",
        "vid": "PAW5E",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "PAW5E_1": {
        "text": "one person runs away with a food item.",
        "vid": "PAW5E",
        "timestamps": [
            10.5,
            15.1
        ]
    },
    "PAW5E_2": {
        "text": "person running away.",
        "vid": "PAW5E",
        "timestamps": [
            10.5,
            15.1
        ]
    },
    "PAW5E_3": {
        "text": "the person at the stove laughs.",
        "vid": "PAW5E",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "MYBRN_0": {
        "text": "person closes some cupboard doors.",
        "vid": "MYBRN",
        "timestamps": [
            11.8,
            21.0
        ]
    },
    "MYBRN_1": {
        "text": "person closed some cabinets.",
        "vid": "MYBRN",
        "timestamps": [
            12.1,
            21.0
        ]
    },
    "MYBRN_2": {
        "text": "person closes a cabinet door.",
        "vid": "MYBRN",
        "timestamps": [
            12.1,
            21.0
        ]
    },
    "8D6PU_0": {
        "text": "a person is walking through a doorway.",
        "vid": "8D6PU",
        "timestamps": [
            1.0,
            6.6
        ]
    },
    "VW4UD_0": {
        "text": "person puts the dishes into the sink.",
        "vid": "VW4UD",
        "timestamps": [
            9.3,
            13.9
        ]
    },
    "VW4UD_1": {
        "text": "a person is sitting in the kitchen eating.",
        "vid": "VW4UD",
        "timestamps": [
            0.0,
            13.4
        ]
    },
    "VW4UD_2": {
        "text": "person puts their dishes in the sink.",
        "vid": "VW4UD",
        "timestamps": [
            9.3,
            13.9
        ]
    },
    "VW4UD_3": {
        "text": "person a is eating at a table in the kitchen.",
        "vid": "VW4UD",
        "timestamps": [
            0.0,
            13.4
        ]
    },
    "PBEUF_0": {
        "text": "person pour something in another glass.",
        "vid": "PBEUF",
        "timestamps": [
            0.8,
            7.7
        ]
    },
    "PBEUF_1": {
        "text": "a person is pouring a drink into a glass.",
        "vid": "PBEUF",
        "timestamps": [
            0.8,
            7.7
        ]
    },
    "SM4AO_0": {
        "text": "a person is holding a bag.",
        "vid": "SM4AO",
        "timestamps": [
            2.5,
            7.6
        ]
    },
    "BQOLV_0": {
        "text": "a person undresses in their closet.",
        "vid": "BQOLV",
        "timestamps": [
            0.0,
            11.7
        ]
    },
    "BQOLV_1": {
        "text": "person putting their clothes on the floor.",
        "vid": "BQOLV",
        "timestamps": [
            0.2,
            11.7
        ]
    },
    "51N2C_0": {
        "text": "person they start closing the door.",
        "vid": "51N2C",
        "timestamps": [
            15.7,
            20.4
        ]
    },
    "T63X2_0": {
        "text": "person start laughing.",
        "vid": "T63X2",
        "timestamps": [
            22.2,
            36.0
        ]
    },
    "HI75B_0": {
        "text": "person opens a cabinet under the stairs.",
        "vid": "HI75B",
        "timestamps": [
            3.9,
            10.4
        ]
    },
    "HI75B_1": {
        "text": "person with a flashlight.",
        "vid": "HI75B",
        "timestamps": [
            5.0,
            10.0
        ]
    },
    "HI75B_2": {
        "text": "person they put a flash light into it.",
        "vid": "HI75B",
        "timestamps": [
            5.0,
            10.0
        ]
    },
    "KWJ5O_0": {
        "text": "person takes a look out the window.",
        "vid": "KWJ5O",
        "timestamps": [
            30.8,
            35.0
        ]
    },
    "U33ZS_0": {
        "text": "person takes their laptop from inside.",
        "vid": "U33ZS",
        "timestamps": [
            0.5,
            9.1
        ]
    },
    "U33ZS_1": {
        "text": "a person opens a bag.",
        "vid": "U33ZS",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "4CAB5_0": {
        "text": "a person is cooking on a stove.",
        "vid": "4CAB5",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "4CAB5_1": {
        "text": "a person is cooking in the stove in the kitchen.",
        "vid": "4CAB5",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "4CAB5_2": {
        "text": "the person turns the overhead light on.",
        "vid": "4CAB5",
        "timestamps": [
            6.7,
            13.0
        ]
    },
    "4CAB5_3": {
        "text": "person they turn on a light.",
        "vid": "4CAB5",
        "timestamps": [
            6.7,
            13.0
        ]
    },
    "MZZK2_0": {
        "text": "the person puts the book down on the table.",
        "vid": "MZZK2",
        "timestamps": [
            17.7,
            23.1
        ]
    },
    "MZZK2_1": {
        "text": "person laying on the floor.",
        "vid": "MZZK2",
        "timestamps": [
            21.2,
            32.0
        ]
    },
    "MZZK2_2": {
        "text": "a person is standing in the garage holding a book.",
        "vid": "MZZK2",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "MZZK2_3": {
        "text": "person lays down on the floor.",
        "vid": "MZZK2",
        "timestamps": [
            21.2,
            32.0
        ]
    },
    "MZZK2_4": {
        "text": "the person undresses.",
        "vid": "MZZK2",
        "timestamps": [
            8.4,
            21.0
        ]
    },
    "MZZK2_5": {
        "text": "person turns the light off.",
        "vid": "MZZK2",
        "timestamps": [
            6.6,
            10.9
        ]
    },
    "MZZK2_6": {
        "text": "person turns off the light.",
        "vid": "MZZK2",
        "timestamps": [
            6.6,
            10.9
        ]
    },
    "MZZK2_7": {
        "text": "the person turns the light off.",
        "vid": "MZZK2",
        "timestamps": [
            6.6,
            10.9
        ]
    },
    "L0QNM_0": {
        "text": "the person is watching television.",
        "vid": "L0QNM",
        "timestamps": [
            0.0,
            12.2
        ]
    },
    "L0QNM_1": {
        "text": "person starts undressing.",
        "vid": "L0QNM",
        "timestamps": [
            17.5,
            28.5
        ]
    },
    "L0QNM_2": {
        "text": "person watching television.",
        "vid": "L0QNM",
        "timestamps": [
            0.0,
            12.2
        ]
    },
    "2TAT3_0": {
        "text": "person drinking from a glass of water.",
        "vid": "2TAT3",
        "timestamps": [
            7.7,
            16.3
        ]
    },
    "4RKKP_0": {
        "text": "the person puts it back into the box.",
        "vid": "4RKKP",
        "timestamps": [
            25.4,
            31.0
        ]
    },
    "I75CL_0": {
        "text": "a person opens a door.",
        "vid": "I75CL",
        "timestamps": [
            0.0,
            6.9
        ]
    },
    "I75CL_1": {
        "text": "person eating a sandwich.",
        "vid": "I75CL",
        "timestamps": [
            10.9,
            18.2
        ]
    },
    "I75CL_2": {
        "text": "a person is opening a door holding groceries.",
        "vid": "I75CL",
        "timestamps": [
            0.0,
            6.9
        ]
    },
    "I75CL_3": {
        "text": "person closes the door behind them with their shoe.",
        "vid": "I75CL",
        "timestamps": [
            2.7,
            9.4
        ]
    },
    "9MNZ5_0": {
        "text": "person opens a book over their head.",
        "vid": "9MNZ5",
        "timestamps": [
            40.1,
            50.1
        ]
    },
    "9MNZ5_1": {
        "text": "person starts eating them.",
        "vid": "9MNZ5",
        "timestamps": [
            26.9,
            41.2
        ]
    },
    "9MNZ5_2": {
        "text": "person begin eating those chips.",
        "vid": "9MNZ5",
        "timestamps": [
            26.9,
            41.2
        ]
    },
    "9MNZ5_3": {
        "text": "person start reading the book.",
        "vid": "9MNZ5",
        "timestamps": [
            43.0,
            53.0
        ]
    },
    "9MNZ5_4": {
        "text": "person pick up some food eat it from bowl.",
        "vid": "9MNZ5",
        "timestamps": [
            26.9,
            41.2
        ]
    },
    "9MNZ5_5": {
        "text": "person they hold a book up.",
        "vid": "9MNZ5",
        "timestamps": [
            41.4,
            53.0
        ]
    },
    "9MNZ5_6": {
        "text": "person eats crackers.",
        "vid": "9MNZ5",
        "timestamps": [
            26.9,
            41.2
        ]
    },
    "E6RD3_0": {
        "text": "a person laughing at the dining table.",
        "vid": "E6RD3",
        "timestamps": [
            0.0,
            7.6
        ]
    },
    "E6RD3_1": {
        "text": "person takes a broom.",
        "vid": "E6RD3",
        "timestamps": [
            19.8,
            26.0
        ]
    },
    "E6RD3_2": {
        "text": "person kicks open a door.",
        "vid": "E6RD3",
        "timestamps": [
            22.9,
            28.0
        ]
    },
    "ECW3E_0": {
        "text": "a person opens a closet door.",
        "vid": "ECW3E",
        "timestamps": [
            1.4,
            10.4
        ]
    },
    "ECW3E_1": {
        "text": "person opens the closet.",
        "vid": "ECW3E",
        "timestamps": [
            1.4,
            10.4
        ]
    },
    "ECW3E_2": {
        "text": "person takes a pink laptop from a shelf opens.",
        "vid": "ECW3E",
        "timestamps": [
            14.7,
            20.5
        ]
    },
    "K8OB6_0": {
        "text": "another person walks into the room drinking from a cup.",
        "vid": "K8OB6",
        "timestamps": [
            20.2,
            30.2
        ]
    },
    "K8OB6_1": {
        "text": "person eating a sandwich.",
        "vid": "K8OB6",
        "timestamps": [
            19.7,
            33.0
        ]
    },
    "PTAZ9_0": {
        "text": "person they stand up.",
        "vid": "PTAZ9",
        "timestamps": [
            12.6,
            17.2
        ]
    },
    "PTAZ9_1": {
        "text": "person eating a sandwich.",
        "vid": "PTAZ9",
        "timestamps": [
            1.5,
            16.0
        ]
    },
    "PTAZ9_2": {
        "text": "person open a cabinet door.",
        "vid": "PTAZ9",
        "timestamps": [
            13.4,
            19.5
        ]
    },
    "PTAZ9_3": {
        "text": "person close the cabinet door.",
        "vid": "PTAZ9",
        "timestamps": [
            18.8,
            24.2
        ]
    },
    "JMPKP_0": {
        "text": "person closes the door.",
        "vid": "JMPKP",
        "timestamps": [
            6.9,
            14.5
        ]
    },
    "JMPKP_1": {
        "text": "a person is putting their shoes in a closet.",
        "vid": "JMPKP",
        "timestamps": [
            5.1,
            9.8
        ]
    },
    "JMPKP_2": {
        "text": "person they put the shoes away.",
        "vid": "JMPKP",
        "timestamps": [
            5.1,
            9.8
        ]
    },
    "JS3TB_0": {
        "text": "person eating a roll or bagel.",
        "vid": "JS3TB",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "JS3TB_1": {
        "text": "person eating a sandwich.",
        "vid": "JS3TB",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "JS3TB_2": {
        "text": "person laugh as they continue to eat their sandwich.",
        "vid": "JS3TB",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "QRSRE_0": {
        "text": "one person runs in past the chair.",
        "vid": "QRSRE",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "QRSRE_1": {
        "text": "person opens the closet door.",
        "vid": "QRSRE",
        "timestamps": [
            2.1,
            12.2
        ]
    },
    "QRSRE_2": {
        "text": "takes a drink as the person opens the closet door.",
        "vid": "QRSRE",
        "timestamps": [
            2.1,
            12.2
        ]
    },
    "QRSRE_3": {
        "text": "the person is drinking a bottle of water.",
        "vid": "QRSRE",
        "timestamps": [
            3.9,
            8.4
        ]
    },
    "QACLT_0": {
        "text": "a person is opening a cabinet in the laundry room.",
        "vid": "QACLT",
        "timestamps": [
            3.5,
            8.8
        ]
    },
    "QACLT_1": {
        "text": "person takes a cellphone from their pocket.",
        "vid": "QACLT",
        "timestamps": [
            8.9,
            18.1
        ]
    },
    "QACLT_2": {
        "text": "person opens some cabinet doors.",
        "vid": "QACLT",
        "timestamps": [
            3.5,
            8.8
        ]
    },
    "3IS9Y_0": {
        "text": "person closed a wooden box twice.",
        "vid": "3IS9Y",
        "timestamps": [
            21.3,
            27.7
        ]
    },
    "3IS9Y_1": {
        "text": "person opened the box adn llooked in to it.",
        "vid": "3IS9Y",
        "timestamps": [
            18.0,
            23.4
        ]
    },
    "3IS9Y_2": {
        "text": "person puts the picture down on a box.",
        "vid": "3IS9Y",
        "timestamps": [
            29.8,
            35.0
        ]
    },
    "NUKJ0_0": {
        "text": "person drinks from a cup of coffee.",
        "vid": "NUKJ0",
        "timestamps": [
            22.8,
            30.3
        ]
    },
    "1QP1S_0": {
        "text": "a person eats some food.",
        "vid": "1QP1S",
        "timestamps": [
            8.3,
            14.9
        ]
    },
    "1QP1S_1": {
        "text": "a person is eating a sandwich.",
        "vid": "1QP1S",
        "timestamps": [
            8.3,
            14.9
        ]
    },
    "1QP1S_2": {
        "text": "person laughing at a picture.",
        "vid": "1QP1S",
        "timestamps": [
            21.9,
            35.0
        ]
    },
    "1QP1S_3": {
        "text": "one person awakens.",
        "vid": "1QP1S",
        "timestamps": [
            14.8,
            21.2
        ]
    },
    "1QP1S_4": {
        "text": "a person eats some sort of fruit.",
        "vid": "1QP1S",
        "timestamps": [
            8.3,
            14.9
        ]
    },
    "1QP1S_5": {
        "text": "another person is eating something from a bag.",
        "vid": "1QP1S",
        "timestamps": [
            8.3,
            14.9
        ]
    },
    "1QP1S_6": {
        "text": "another person awakens.",
        "vid": "1QP1S",
        "timestamps": [
            14.8,
            21.2
        ]
    },
    "OVFR0_0": {
        "text": "person that they opened a door.",
        "vid": "OVFR0",
        "timestamps": [
            11.3,
            17.3
        ]
    },
    "OVFR0_1": {
        "text": "a person was looking at a book.",
        "vid": "OVFR0",
        "timestamps": [
            0.0,
            8.5
        ]
    },
    "CDULZ_0": {
        "text": "person holding a bag of groceries.",
        "vid": "CDULZ",
        "timestamps": [
            20.6,
            31.0
        ]
    },
    "O3HV7_0": {
        "text": "person they put their glasses on.",
        "vid": "O3HV7",
        "timestamps": [
            20.2,
            27.3
        ]
    },
    "O3HV7_1": {
        "text": "a person awakens.",
        "vid": "O3HV7",
        "timestamps": [
            4.8,
            14.0
        ]
    },
    "O3HV7_2": {
        "text": "person drinking from a coffee cup.",
        "vid": "O3HV7",
        "timestamps": [
            16.0,
            24.4
        ]
    },
    "O3HV7_3": {
        "text": "person putting glasses on.",
        "vid": "O3HV7",
        "timestamps": [
            20.2,
            27.3
        ]
    },
    "7O6FK_0": {
        "text": "a person throws a blanket down the stairs.",
        "vid": "7O6FK",
        "timestamps": [
            3.1,
            10.3
        ]
    },
    "7O6FK_1": {
        "text": "a person throws a blanket down some stairs.",
        "vid": "7O6FK",
        "timestamps": [
            3.1,
            10.3
        ]
    },
    "7O6FK_2": {
        "text": "person takes a picture from the wall.",
        "vid": "7O6FK",
        "timestamps": [
            9.3,
            14.5
        ]
    },
    "7O6FK_3": {
        "text": "person running down the stairs.",
        "vid": "7O6FK",
        "timestamps": [
            11.1,
            20.0
        ]
    },
    "7O6FK_4": {
        "text": "a person throws a blanket on the floor.",
        "vid": "7O6FK",
        "timestamps": [
            4.0,
            9.6
        ]
    },
    "7O6FK_5": {
        "text": "person takes a picture frame off a wall.",
        "vid": "7O6FK",
        "timestamps": [
            9.3,
            14.5
        ]
    },
    "DJVKE_0": {
        "text": "person is also eating something next to him.",
        "vid": "DJVKE",
        "timestamps": [
            14.1,
            26.5
        ]
    },
    "DJVKE_1": {
        "text": "person eat it.",
        "vid": "DJVKE",
        "timestamps": [
            14.1,
            26.5
        ]
    },
    "DJVKE_2": {
        "text": "person eating a snack.",
        "vid": "DJVKE",
        "timestamps": [
            14.1,
            26.5
        ]
    },
    "F9VSQ_0": {
        "text": "person starts sneezing furiously.",
        "vid": "F9VSQ",
        "timestamps": [
            7.0,
            15.7
        ]
    },
    "F9VSQ_1": {
        "text": "a person is smiling at a camera.",
        "vid": "F9VSQ",
        "timestamps": [
            0.0,
            7.3
        ]
    },
    "F9VSQ_2": {
        "text": "person sneezing into a cup of coffee in an entryway.",
        "vid": "F9VSQ",
        "timestamps": [
            7.0,
            15.7
        ]
    },
    "MKMFK_0": {
        "text": "a person drinks from a cup.",
        "vid": "MKMFK",
        "timestamps": [
            0.4,
            6.0
        ]
    },
    "MKMFK_1": {
        "text": "person drinking out of a cup.",
        "vid": "MKMFK",
        "timestamps": [
            0.4,
            6.0
        ]
    },
    "ZTWJB_0": {
        "text": "a person throws a broom ferociously at the floor.",
        "vid": "ZTWJB",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "ZTWJB_1": {
        "text": "person throws the broom onto the ground.",
        "vid": "ZTWJB",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "JIUH7_0": {
        "text": "person they put the bottle in the trash.",
        "vid": "JIUH7",
        "timestamps": [
            15.2,
            21.8
        ]
    },
    "JIUH7_1": {
        "text": "a person walks down stairs drinking from a glass bottle.",
        "vid": "JIUH7",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "JIUH7_2": {
        "text": "person drinking from a water bottle.",
        "vid": "JIUH7",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "JIUH7_3": {
        "text": "person put the bottle in the garbage.",
        "vid": "JIUH7",
        "timestamps": [
            15.2,
            21.8
        ]
    },
    "JIUH7_4": {
        "text": "person drinking a bottle of water.",
        "vid": "JIUH7",
        "timestamps": [
            0.0,
            10.0
        ]
    },
    "DSI0N_0": {
        "text": "the person is closing the door.",
        "vid": "DSI0N",
        "timestamps": [
            3.4,
            10.7
        ]
    },
    "DSI0N_1": {
        "text": "person stand there talking on their phone.",
        "vid": "DSI0N",
        "timestamps": [
            7.2,
            11.9
        ]
    },
    "DSI0N_2": {
        "text": "person talking on the phone.",
        "vid": "DSI0N",
        "timestamps": [
            7.2,
            11.9
        ]
    },
    "YT2C3_0": {
        "text": "a person opens the doors of a pantry.",
        "vid": "YT2C3",
        "timestamps": [
            0.7,
            10.2
        ]
    },
    "YT2C3_1": {
        "text": "person takes out phone.",
        "vid": "YT2C3",
        "timestamps": [
            6.5,
            12.5
        ]
    },
    "YT2C3_2": {
        "text": "the person takes a paper towel from the shelf.",
        "vid": "YT2C3",
        "timestamps": [
            14.6,
            21.3
        ]
    },
    "YT2C3_3": {
        "text": "person holding their phone.",
        "vid": "YT2C3",
        "timestamps": [
            6.7,
            17.4
        ]
    },
    "YT2C3_4": {
        "text": "person opens door.",
        "vid": "YT2C3",
        "timestamps": [
            0.7,
            10.2
        ]
    },
    "YT2C3_5": {
        "text": "a person opens the pantry door.",
        "vid": "YT2C3",
        "timestamps": [
            0.7,
            10.2
        ]
    },
    "3B97C_0": {
        "text": "a person is running into their kitchen holding a laptop.",
        "vid": "3B97C",
        "timestamps": [
            2.1,
            8.5
        ]
    },
    "0E6H9_0": {
        "text": "person drinks from a bottle.",
        "vid": "0E6H9",
        "timestamps": [
            22.6,
            29.5
        ]
    },
    "HIKIC_0": {
        "text": "person opening a door.",
        "vid": "HIKIC",
        "timestamps": [
            17.5,
            23.5
        ]
    },
    "HIKIC_1": {
        "text": "the person opens a box.",
        "vid": "HIKIC",
        "timestamps": [
            0.9,
            7.7
        ]
    },
    "HIKIC_2": {
        "text": "person talking on phone.",
        "vid": "HIKIC",
        "timestamps": [
            11.8,
            22.4
        ]
    },
    "PT4XS_0": {
        "text": "a person is sitting at the table.",
        "vid": "PT4XS",
        "timestamps": [
            16.1,
            20.3
        ]
    },
    "PT4XS_1": {
        "text": "gets up to watch the other person washing dishes.",
        "vid": "PT4XS",
        "timestamps": [
            21.6,
            32.0
        ]
    },
    "PT4XS_2": {
        "text": "a person is sitting at a table.",
        "vid": "PT4XS",
        "timestamps": [
            16.1,
            20.3
        ]
    },
    "PT4XS_3": {
        "text": "a person sits at the kitchen table with a book.",
        "vid": "PT4XS",
        "timestamps": [
            16.1,
            20.3
        ]
    },
    "PT4XS_4": {
        "text": "person where he begins washing dishes.",
        "vid": "PT4XS",
        "timestamps": [
            21.6,
            32.0
        ]
    },
    "VWFJA_0": {
        "text": "person opens the refrigerator.",
        "vid": "VWFJA",
        "timestamps": [
            1.2,
            7.2
        ]
    },
    "XRG9K_0": {
        "text": "person is sitting on floor sneezing.",
        "vid": "XRG9K",
        "timestamps": [
            0.2,
            6.4
        ]
    },
    "XRG9K_1": {
        "text": "person takes something out box.",
        "vid": "XRG9K",
        "timestamps": [
            5.5,
            11.5
        ]
    },
    "XRG9K_2": {
        "text": "person opening a box.",
        "vid": "XRG9K",
        "timestamps": [
            1.7,
            9.4
        ]
    },
    "XRG9K_3": {
        "text": "person opening box.",
        "vid": "XRG9K",
        "timestamps": [
            1.7,
            9.4
        ]
    },
    "XRG9K_4": {
        "text": "one person opens a box.",
        "vid": "XRG9K",
        "timestamps": [
            1.7,
            9.4
        ]
    },
    "7AB3X_0": {
        "text": "person grabs something to drink out of a cup.",
        "vid": "7AB3X",
        "timestamps": [
            17.1,
            24.8
        ]
    },
    "OOKN5_0": {
        "text": "person takes the jacket out of the box.",
        "vid": "OOKN5",
        "timestamps": [
            16.6,
            27.8
        ]
    },
    "OOKN5_1": {
        "text": "person begin dressing.",
        "vid": "OOKN5",
        "timestamps": [
            22.8,
            38.0
        ]
    },
    "F024X_0": {
        "text": "person throws a pillow on a chair.",
        "vid": "F024X",
        "timestamps": [
            8.5,
            14.0
        ]
    },
    "F024X_1": {
        "text": "a person undresses.",
        "vid": "F024X",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "F024X_2": {
        "text": "person puts a pillow on a chair.",
        "vid": "F024X",
        "timestamps": [
            9.0,
            14.0
        ]
    },
    "BJ7YW_0": {
        "text": "person looks out a window.",
        "vid": "BJ7YW",
        "timestamps": [
            8.4,
            15.0
        ]
    },
    "BJ7YW_1": {
        "text": "the person is now washing the glass of the window.",
        "vid": "BJ7YW",
        "timestamps": [
            9.4,
            15.0
        ]
    },
    "FJYWX_0": {
        "text": "person they take off some of their clothes.",
        "vid": "FJYWX",
        "timestamps": [
            24.3,
            33.6
        ]
    },
    "FJYWX_1": {
        "text": "person beginning to undress.",
        "vid": "FJYWX",
        "timestamps": [
            22.8,
            35.1
        ]
    },
    "FJYWX_2": {
        "text": "person put it on the table.",
        "vid": "FJYWX",
        "timestamps": [
            20.5,
            26.6
        ]
    },
    "B47TS_0": {
        "text": "person than stand up.",
        "vid": "B47TS",
        "timestamps": [
            12.4,
            17.9
        ]
    },
    "LRJKT_0": {
        "text": "a person drinks out of a glass.",
        "vid": "LRJKT",
        "timestamps": [
            0.7,
            12.8
        ]
    },
    "4FX6G_0": {
        "text": "a person opens a door.",
        "vid": "4FX6G",
        "timestamps": [
            7.8,
            18.6
        ]
    },
    "4FX6G_1": {
        "text": "a person opens a door with a doorknob.",
        "vid": "4FX6G",
        "timestamps": [
            7.8,
            18.6
        ]
    },
    "4FX6G_2": {
        "text": "person takes some dishes out of the pantry.",
        "vid": "4FX6G",
        "timestamps": [
            16.4,
            27.2
        ]
    },
    "LGPWK_0": {
        "text": "person puts the remote on a shelf.",
        "vid": "LGPWK",
        "timestamps": [
            22.4,
            28.0
        ]
    },
    "EIT66_0": {
        "text": "person putting a blanket in the box.",
        "vid": "EIT66",
        "timestamps": [
            7.5,
            13.0
        ]
    },
    "EIT66_1": {
        "text": "person put a blanket in a box.",
        "vid": "EIT66",
        "timestamps": [
            7.5,
            13.0
        ]
    },
    "EIT66_2": {
        "text": "the person puts the phone in a pocket.",
        "vid": "EIT66",
        "timestamps": [
            2.8,
            8.7
        ]
    },
    "0LHWF_0": {
        "text": "a person sits in a chair.",
        "vid": "0LHWF",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "0LHWF_1": {
        "text": "person holding a book.",
        "vid": "0LHWF",
        "timestamps": [
            2.1,
            16.2
        ]
    },
    "0LHWF_2": {
        "text": "person reading a book.",
        "vid": "0LHWF",
        "timestamps": [
            2.7,
            15.0
        ]
    },
    "0LHWF_3": {
        "text": "person read book.",
        "vid": "0LHWF",
        "timestamps": [
            2.7,
            15.0
        ]
    },
    "RJNAB_0": {
        "text": "a person drinks from a cup.",
        "vid": "RJNAB",
        "timestamps": [
            0.1,
            5.6
        ]
    },
    "RJNAB_1": {
        "text": "person they open a box.",
        "vid": "RJNAB",
        "timestamps": [
            7.2,
            12.1
        ]
    },
    "RJNAB_2": {
        "text": "this person opens a box.",
        "vid": "RJNAB",
        "timestamps": [
            7.2,
            12.1
        ]
    },
    "RJNAB_3": {
        "text": "person drinks from a cup.",
        "vid": "RJNAB",
        "timestamps": [
            0.1,
            5.6
        ]
    },
    "ZL3QP_0": {
        "text": "a person is laughing as the open the pantry.",
        "vid": "ZL3QP",
        "timestamps": [
            2.1,
            9.3
        ]
    },
    "ZL3QP_1": {
        "text": "a person is opening the pantry door.",
        "vid": "ZL3QP",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "ZL3QP_2": {
        "text": "person starts laughing.",
        "vid": "ZL3QP",
        "timestamps": [
            2.1,
            9.3
        ]
    },
    "EURF2_0": {
        "text": "person sitting on bed.",
        "vid": "EURF2",
        "timestamps": [
            22.5,
            29.4
        ]
    },
    "EURF2_1": {
        "text": "person sitting on the bed themselves.",
        "vid": "EURF2",
        "timestamps": [
            22.5,
            29.4
        ]
    },
    "EURF2_2": {
        "text": "the person sits on the bed.",
        "vid": "EURF2",
        "timestamps": [
            22.5,
            29.4
        ]
    },
    "8W829_0": {
        "text": "person puts something on a shelf.",
        "vid": "8W829",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "8W829_1": {
        "text": "a person is putting a sandwich on a tray.",
        "vid": "8W829",
        "timestamps": [
            2.1,
            7.5
        ]
    },
    "8W829_2": {
        "text": "person slowly walks to a doorway.",
        "vid": "8W829",
        "timestamps": [
            17.4,
            29.3
        ]
    },
    "8W829_3": {
        "text": "person puts a sandwich in a basket.",
        "vid": "8W829",
        "timestamps": [
            2.1,
            7.5
        ]
    },
    "OTUV7_0": {
        "text": "person eating from a bag.",
        "vid": "OTUV7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "OTUV7_1": {
        "text": "person eats some chips at a small table.",
        "vid": "OTUV7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "OTUV7_2": {
        "text": "person they are eating a snack.",
        "vid": "OTUV7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "OTUV7_3": {
        "text": "a person is in a office eating food.",
        "vid": "OTUV7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "OTUV7_4": {
        "text": "person stand up.",
        "vid": "OTUV7",
        "timestamps": [
            9.4,
            14.4
        ]
    },
    "2OHTZ_0": {
        "text": "the person takes a couple drinks from a cup.",
        "vid": "2OHTZ",
        "timestamps": [
            6.6,
            15.5
        ]
    },
    "2OHTZ_1": {
        "text": "person taking a drink from a cup of coffee.",
        "vid": "2OHTZ",
        "timestamps": [
            6.6,
            15.5
        ]
    },
    "2OHTZ_2": {
        "text": "a person opens a laptop.",
        "vid": "2OHTZ",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "2OHTZ_3": {
        "text": "a person opens their laptop.",
        "vid": "2OHTZ",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "2OHTZ_4": {
        "text": "person opening a laptop.",
        "vid": "2OHTZ",
        "timestamps": [
            0.0,
            5.3
        ]
    },
    "DMO76_0": {
        "text": "the person runs into the adjacent living room.",
        "vid": "DMO76",
        "timestamps": [
            11.6,
            20.4
        ]
    },
    "DMO76_1": {
        "text": "person they start running around.",
        "vid": "DMO76",
        "timestamps": [
            11.6,
            20.4
        ]
    },
    "DMO76_2": {
        "text": "person they put their phone onto the sofa.",
        "vid": "DMO76",
        "timestamps": [
            17.9,
            22.8
        ]
    },
    "DMO76_3": {
        "text": "this person runs into the other room.",
        "vid": "DMO76",
        "timestamps": [
            11.6,
            20.4
        ]
    },
    "FQS5V_0": {
        "text": "person they stand up.",
        "vid": "FQS5V",
        "timestamps": [
            14.7,
            21.1
        ]
    },
    "FQS5V_1": {
        "text": "the person laughs.",
        "vid": "FQS5V",
        "timestamps": [
            15.0,
            22.0
        ]
    },
    "Y80PJ_0": {
        "text": "a person is opening the refrigerator.",
        "vid": "Y80PJ",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "DHDCF_0": {
        "text": "person walks towards the camera drinking from a glass.",
        "vid": "DHDCF",
        "timestamps": [
            2.1,
            8.8
        ]
    },
    "DHDCF_1": {
        "text": "person drinking a glass of water.",
        "vid": "DHDCF",
        "timestamps": [
            2.1,
            8.8
        ]
    },
    "DHDCF_2": {
        "text": "person drinking water from a glass.",
        "vid": "DHDCF",
        "timestamps": [
            2.1,
            8.8
        ]
    },
    "TS2DM_0": {
        "text": "person holding a cellphone.",
        "vid": "TS2DM",
        "timestamps": [
            0.0,
            13.8
        ]
    },
    "TS2DM_1": {
        "text": "person smiling very happily.",
        "vid": "TS2DM",
        "timestamps": [
            0.0,
            15.7
        ]
    },
    "TS2DM_2": {
        "text": "person still smiling.",
        "vid": "TS2DM",
        "timestamps": [
            0.0,
            15.7
        ]
    },
    "TS2DM_3": {
        "text": "the person walks through a doorway.",
        "vid": "TS2DM",
        "timestamps": [
            3.1,
            10.0
        ]
    },
    "TS2DM_4": {
        "text": "person holding a cell phone.",
        "vid": "TS2DM",
        "timestamps": [
            0.0,
            13.8
        ]
    },
    "TS2DM_5": {
        "text": "person holding the phone.",
        "vid": "TS2DM",
        "timestamps": [
            0.0,
            13.8
        ]
    },
    "OY3LS_0": {
        "text": "the person puts their phone on a table.",
        "vid": "OY3LS",
        "timestamps": [
            28.6,
            37.6
        ]
    },
    "OY3LS_1": {
        "text": "the person sits on a couch.",
        "vid": "OY3LS",
        "timestamps": [
            34.9,
            41.4
        ]
    },
    "OY3LS_2": {
        "text": "a person is standing in their entryway undressing.",
        "vid": "OY3LS",
        "timestamps": [
            7.2,
            23.6
        ]
    },
    "OY3LS_3": {
        "text": "person sit on a couch under a blanket.",
        "vid": "OY3LS",
        "timestamps": [
            34.9,
            41.4
        ]
    },
    "OY3LS_4": {
        "text": "person played with his phone.",
        "vid": "OY3LS",
        "timestamps": [
            22.3,
            33.1
        ]
    },
    "OY3LS_5": {
        "text": "person lied down on the couch.",
        "vid": "OY3LS",
        "timestamps": [
            34.0,
            46.0
        ]
    },
    "OY3LS_6": {
        "text": "person they get undresses.",
        "vid": "OY3LS",
        "timestamps": [
            7.2,
            23.6
        ]
    },
    "OY3LS_7": {
        "text": "person opened the laptop.",
        "vid": "OY3LS",
        "timestamps": [
            2.5,
            10.1
        ]
    },
    "68OG0_0": {
        "text": "person drink a cup of coffee.",
        "vid": "68OG0",
        "timestamps": [
            18.7,
            29.9
        ]
    },
    "68OG0_1": {
        "text": "a person is sneezing.",
        "vid": "68OG0",
        "timestamps": [
            9.3,
            16.6
        ]
    },
    "DGPAW_0": {
        "text": "person opens the door.",
        "vid": "DGPAW",
        "timestamps": [
            10.5,
            16.6
        ]
    },
    "DGPAW_1": {
        "text": "this person puts the picture on a shelf.",
        "vid": "DGPAW",
        "timestamps": [
            5.1,
            13.0
        ]
    },
    "GAOV2_0": {
        "text": "a person is sneezing into a phone.",
        "vid": "GAOV2",
        "timestamps": [
            2.3,
            9.2
        ]
    },
    "GAOV2_1": {
        "text": "person putting a laptop in a bag in a kitchen.",
        "vid": "GAOV2",
        "timestamps": [
            12.0,
            21.5
        ]
    },
    "Q5MDU_0": {
        "text": "person turns the light off.",
        "vid": "Q5MDU",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "Q5MDU_1": {
        "text": "person turns the light on.",
        "vid": "Q5MDU",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "Q5MDU_2": {
        "text": "person turning on a light.",
        "vid": "Q5MDU",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "Q5MDU_3": {
        "text": "person turns on a light.",
        "vid": "Q5MDU",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "IMLN5_0": {
        "text": "person take a drink from a glass.",
        "vid": "IMLN5",
        "timestamps": [
            5.6,
            15.5
        ]
    },
    "4H61U_0": {
        "text": "person dress themselves with it.",
        "vid": "4H61U",
        "timestamps": [
            19.0,
            31.0
        ]
    },
    "BDJ84_0": {
        "text": "person put it onto the shelf.",
        "vid": "BDJ84",
        "timestamps": [
            19.3,
            26.4
        ]
    },
    "CLB72_0": {
        "text": "person takes a pillow from it.",
        "vid": "CLB72",
        "timestamps": [
            15.6,
            23.7
        ]
    },
    "CLB72_1": {
        "text": "person takes a pillow out.",
        "vid": "CLB72",
        "timestamps": [
            15.6,
            23.7
        ]
    },
    "CLB72_2": {
        "text": "person takes a pillow out of the box.",
        "vid": "CLB72",
        "timestamps": [
            15.6,
            23.7
        ]
    },
    "CLB72_3": {
        "text": "person turns on the light to a closet.",
        "vid": "CLB72",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "CLB72_4": {
        "text": "a person turns on the light in a closet.",
        "vid": "CLB72",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "SB8G0_0": {
        "text": "a person is smiling.",
        "vid": "SB8G0",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "SB8G0_1": {
        "text": "a person is sitting on a chair.",
        "vid": "SB8G0",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "SB8G0_2": {
        "text": "person closing the cabinet.",
        "vid": "SB8G0",
        "timestamps": [
            25.4,
            29.5
        ]
    },
    "SB8G0_3": {
        "text": "person sitting in a chair.",
        "vid": "SB8G0",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "SB8G0_4": {
        "text": "person smiling at the camera.",
        "vid": "SB8G0",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "ATV2F_0": {
        "text": "person opens up a laptop.",
        "vid": "ATV2F",
        "timestamps": [
            12.7,
            20.7
        ]
    },
    "ATV2F_1": {
        "text": "person opens her laptop to begin doing her work.",
        "vid": "ATV2F",
        "timestamps": [
            12.7,
            20.7
        ]
    },
    "ATV2F_2": {
        "text": "person a girl is dressing in front of a closet.",
        "vid": "ATV2F",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "ATV2F_3": {
        "text": "person opens the laptop.",
        "vid": "ATV2F",
        "timestamps": [
            12.7,
            20.7
        ]
    },
    "B4TWR_0": {
        "text": "another person is putting clothes in a hall wardrobe.",
        "vid": "B4TWR",
        "timestamps": [
            9.6,
            16.3
        ]
    },
    "B4TWR_1": {
        "text": "person they put them on a shelf.",
        "vid": "B4TWR",
        "timestamps": [
            9.8,
            16.1
        ]
    },
    "CQ435_0": {
        "text": "a person in their dining room is running around.",
        "vid": "CQ435",
        "timestamps": [
            1.3,
            12.8
        ]
    },
    "CQ435_1": {
        "text": "person laughing because they see something funny on the television.",
        "vid": "CQ435",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "TKJCI_0": {
        "text": "person lies down on the bed to review the pictures.",
        "vid": "TKJCI",
        "timestamps": [
            16.3,
            31.0
        ]
    },
    "TKJCI_1": {
        "text": "taking the picture the person lies back in the bed.",
        "vid": "TKJCI",
        "timestamps": [
            16.3,
            31.0
        ]
    },
    "M014B_0": {
        "text": "a person holding a bag of items.",
        "vid": "M014B",
        "timestamps": [
            28.3,
            31.0
        ]
    },
    "M014B_1": {
        "text": "a person drinks milk from a bottle.",
        "vid": "M014B",
        "timestamps": [
            5.7,
            15.0
        ]
    },
    "M014B_2": {
        "text": "person continues cooking.",
        "vid": "M014B",
        "timestamps": [
            14.5,
            24.4
        ]
    },
    "M014B_3": {
        "text": "person holding a bag.",
        "vid": "M014B",
        "timestamps": [
            28.3,
            31.0
        ]
    },
    "W3NN2_0": {
        "text": "person turning the lights off.",
        "vid": "W3NN2",
        "timestamps": [
            26.7,
            31.0
        ]
    },
    "W3NN2_1": {
        "text": "person turned off the light.",
        "vid": "W3NN2",
        "timestamps": [
            26.7,
            31.0
        ]
    },
    "W3NN2_2": {
        "text": "person turns off the light.",
        "vid": "W3NN2",
        "timestamps": [
            26.7,
            31.0
        ]
    },
    "QMHK8_0": {
        "text": "person walks into room holding a bag.",
        "vid": "QMHK8",
        "timestamps": [
            0.0,
            16.7
        ]
    },
    "QMHK8_1": {
        "text": "person closes the door behind them.",
        "vid": "QMHK8",
        "timestamps": [
            0.9,
            14.1
        ]
    },
    "QMHK8_2": {
        "text": "this person puts their shoes.",
        "vid": "QMHK8",
        "timestamps": [
            17.1,
            26.1
        ]
    },
    "QMHK8_3": {
        "text": "person puts a plastic bag on the handle.",
        "vid": "QMHK8",
        "timestamps": [
            9.5,
            17.3
        ]
    },
    "QMHK8_4": {
        "text": "person closes the door.",
        "vid": "QMHK8",
        "timestamps": [
            0.9,
            14.1
        ]
    },
    "QMHK8_5": {
        "text": "person takes the bag off the doorknob.",
        "vid": "QMHK8",
        "timestamps": [
            39.5,
            46.4
        ]
    },
    "QMHK8_6": {
        "text": "person puts bag on shelf.",
        "vid": "QMHK8",
        "timestamps": [
            42.1,
            54.7
        ]
    },
    "QMHK8_7": {
        "text": "person puts shoes in the bag.",
        "vid": "QMHK8",
        "timestamps": [
            17.1,
            26.1
        ]
    },
    "QMHK8_8": {
        "text": "person takes off sweater to put in bag.",
        "vid": "QMHK8",
        "timestamps": [
            39.5,
            46.4
        ]
    },
    "QMHK8_9": {
        "text": "the person undresses (removes socks.",
        "vid": "QMHK8",
        "timestamps": [
            20.1,
            44.4
        ]
    },
    "QMHK8_10": {
        "text": "person puts it on the shelf.",
        "vid": "QMHK8",
        "timestamps": [
            42.1,
            54.7
        ]
    },
    "QMHK8_11": {
        "text": "person puts the bag on a shelf.",
        "vid": "QMHK8",
        "timestamps": [
            42.1,
            54.7
        ]
    },
    "RSFGZ_0": {
        "text": "person they begin undressing by removing their sweater.",
        "vid": "RSFGZ",
        "timestamps": [
            1.6,
            10.2
        ]
    },
    "RSFGZ_1": {
        "text": "a person undresses as they walk down the stairs.",
        "vid": "RSFGZ",
        "timestamps": [
            1.6,
            10.2
        ]
    },
    "8H570_0": {
        "text": "person which he holds as he removes his phone.",
        "vid": "8H570",
        "timestamps": [
            6.8,
            21.3
        ]
    },
    "8H570_1": {
        "text": "a person is eating junk food.",
        "vid": "8H570",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "UR55B_0": {
        "text": "person holding a bag of groceries.",
        "vid": "UR55B",
        "timestamps": [
            18.8,
            33.8
        ]
    },
    "OB9D0_0": {
        "text": "person playing a game on the phone.",
        "vid": "OB9D0",
        "timestamps": [
            23.4,
            33.0
        ]
    },
    "OB9D0_1": {
        "text": "person they start playing with a camera.",
        "vid": "OB9D0",
        "timestamps": [
            23.4,
            33.0
        ]
    },
    "NL9AW_0": {
        "text": "person holding their food.",
        "vid": "NL9AW",
        "timestamps": [
            6.5,
            13.2
        ]
    },
    "NL9AW_1": {
        "text": "person opens the refrigerator.",
        "vid": "NL9AW",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "9BQ7M_0": {
        "text": "person sitting in a chair smiling.",
        "vid": "9BQ7M",
        "timestamps": [
            9.7,
            16.2
        ]
    },
    "FQ8FN_0": {
        "text": "person they put on their shoes.",
        "vid": "FQ8FN",
        "timestamps": [
            14.9,
            25.1
        ]
    },
    "FQ8FN_1": {
        "text": "a person awakens in bed.",
        "vid": "FQ8FN",
        "timestamps": [
            6.6,
            17.0
        ]
    },
    "FQ8FN_2": {
        "text": "person puts their shoes on.",
        "vid": "FQ8FN",
        "timestamps": [
            14.9,
            25.1
        ]
    },
    "FQ8FN_3": {
        "text": "person puts on some shoes.",
        "vid": "FQ8FN",
        "timestamps": [
            14.9,
            25.1
        ]
    },
    "30K2N_0": {
        "text": "a person runs into a garage.",
        "vid": "30K2N",
        "timestamps": [
            5.2,
            10.6
        ]
    },
    "30K2N_1": {
        "text": "person turns on a light.",
        "vid": "30K2N",
        "timestamps": [
            1.7,
            6.7
        ]
    },
    "4K0BP_0": {
        "text": "person drinks a glass of water from the shelf.",
        "vid": "4K0BP",
        "timestamps": [
            8.6,
            17.7
        ]
    },
    "4K0BP_1": {
        "text": "this person drinks from a cup.",
        "vid": "4K0BP",
        "timestamps": [
            8.6,
            17.7
        ]
    },
    "RAGOI_0": {
        "text": "person put the towel on top of a table.",
        "vid": "RAGOI",
        "timestamps": [
            7.4,
            12.0
        ]
    },
    "RAGOI_1": {
        "text": "person as they stand up to grab a towel.",
        "vid": "RAGOI",
        "timestamps": [
            2.7,
            7.2
        ]
    },
    "KNGRY_0": {
        "text": "the person laughed.",
        "vid": "KNGRY",
        "timestamps": [
            13.3,
            18.1
        ]
    },
    "KNGRY_1": {
        "text": "the person walked through the doorway holding a box.",
        "vid": "KNGRY",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "KNGRY_2": {
        "text": "the person appears to laugh.",
        "vid": "KNGRY",
        "timestamps": [
            13.3,
            18.1
        ]
    },
    "0KTWY_0": {
        "text": "person moving to sit on the toilet seat.",
        "vid": "0KTWY",
        "timestamps": [
            0.0,
            10.3
        ]
    },
    "S4P5J_0": {
        "text": "person putting away groceries.",
        "vid": "S4P5J",
        "timestamps": [
            5.9,
            24.8
        ]
    },
    "S4P5J_1": {
        "text": "another person is smiling.",
        "vid": "S4P5J",
        "timestamps": [
            33.7,
            38.5
        ]
    },
    "AB2V6_0": {
        "text": "person opens a laptop up.",
        "vid": "AB2V6",
        "timestamps": [
            20.0,
            25.2
        ]
    },
    "AB2V6_1": {
        "text": "person they stand up.",
        "vid": "AB2V6",
        "timestamps": [
            11.9,
            17.3
        ]
    },
    "AB2V6_2": {
        "text": "a person is on the sofa sneezing.",
        "vid": "AB2V6",
        "timestamps": [
            6.8,
            13.5
        ]
    },
    "AB2V6_3": {
        "text": "person opened the laptop computer.",
        "vid": "AB2V6",
        "timestamps": [
            20.0,
            25.2
        ]
    },
    "YGL6R_0": {
        "text": "person stop to open a window.",
        "vid": "YGL6R",
        "timestamps": [
            21.1,
            28.8
        ]
    },
    "YGL6R_1": {
        "text": "person tidying up the table.",
        "vid": "YGL6R",
        "timestamps": [
            4.8,
            14.8
        ]
    },
    "OT35M_0": {
        "text": "person they put the towel down.",
        "vid": "OT35M",
        "timestamps": [
            4.4,
            9.8
        ]
    },
    "OT35M_1": {
        "text": "person throwing the towel to the floor.",
        "vid": "OT35M",
        "timestamps": [
            4.4,
            9.8
        ]
    },
    "OT35M_2": {
        "text": "person throw it on the floor.",
        "vid": "OT35M",
        "timestamps": [
            4.4,
            9.8
        ]
    },
    "OT35M_3": {
        "text": "person takes a picture of themselves.",
        "vid": "OT35M",
        "timestamps": [
            9.6,
            15.0
        ]
    },
    "OT35M_4": {
        "text": "person take a picture.",
        "vid": "OT35M",
        "timestamps": [
            9.6,
            15.0
        ]
    },
    "OT35M_5": {
        "text": "person take their phone out to take a picture.",
        "vid": "OT35M",
        "timestamps": [
            9.6,
            15.0
        ]
    },
    "OT35M_6": {
        "text": "a person is putting on a towel.",
        "vid": "OT35M",
        "timestamps": [
            4.4,
            9.8
        ]
    },
    "OT35M_7": {
        "text": "a person put a towels around their neck.",
        "vid": "OT35M",
        "timestamps": [
            4.4,
            9.8
        ]
    },
    "1L5D3_0": {
        "text": "person playing on their phone.",
        "vid": "1L5D3",
        "timestamps": [
            18.5,
            32.0
        ]
    },
    "1L5D3_1": {
        "text": "a person takes a pillow from the dresser.",
        "vid": "1L5D3",
        "timestamps": [
            2.9,
            10.0
        ]
    },
    "1L5D3_2": {
        "text": "person snuggling up to the pillow.",
        "vid": "1L5D3",
        "timestamps": [
            2.5,
            16.8
        ]
    },
    "1L5D3_3": {
        "text": "a person takes a pillow off a shelf.",
        "vid": "1L5D3",
        "timestamps": [
            2.9,
            10.0
        ]
    },
    "PGPSJ_0": {
        "text": "person puts down the box.",
        "vid": "PGPSJ",
        "timestamps": [
            21.3,
            27.4
        ]
    },
    "PGPSJ_1": {
        "text": "person closes the box.",
        "vid": "PGPSJ",
        "timestamps": [
            19.1,
            25.3
        ]
    },
    "UR5TU_0": {
        "text": "a person opens a pantry door.",
        "vid": "UR5TU",
        "timestamps": [
            0.4,
            7.4
        ]
    },
    "UR5TU_1": {
        "text": "person closes the cabinet door.",
        "vid": "UR5TU",
        "timestamps": [
            20.2,
            27.1
        ]
    },
    "UR5TU_2": {
        "text": "person a girl opens the pantry door.",
        "vid": "UR5TU",
        "timestamps": [
            0.4,
            7.4
        ]
    },
    "UR5TU_3": {
        "text": "the person closes the door.",
        "vid": "UR5TU",
        "timestamps": [
            20.2,
            27.1
        ]
    },
    "UR5TU_4": {
        "text": "a person opens a closet.",
        "vid": "UR5TU",
        "timestamps": [
            0.8,
            7.7
        ]
    },
    "UR5TU_5": {
        "text": "person closes the door.",
        "vid": "UR5TU",
        "timestamps": [
            20.2,
            27.1
        ]
    },
    "UR5TU_6": {
        "text": "person opens a cabinet in the pantry.",
        "vid": "UR5TU",
        "timestamps": [
            0.8,
            7.7
        ]
    },
    "UR5TU_7": {
        "text": "the person opens up a pantry door holding some clothing.",
        "vid": "UR5TU",
        "timestamps": [
            0.4,
            7.4
        ]
    },
    "R1KMF_0": {
        "text": "person puts it into a bag.",
        "vid": "R1KMF",
        "timestamps": [
            11.1,
            23.3
        ]
    },
    "R1KMF_1": {
        "text": "person opens a door by turning the handle.",
        "vid": "R1KMF",
        "timestamps": [
            20.9,
            25.1
        ]
    },
    "R1KMF_2": {
        "text": "the person takes the bag.",
        "vid": "R1KMF",
        "timestamps": [
            10.3,
            18.5
        ]
    },
    "R1KMF_3": {
        "text": "person opens a door.",
        "vid": "R1KMF",
        "timestamps": [
            20.9,
            25.1
        ]
    },
    "J3RD3_0": {
        "text": "person closes the door.",
        "vid": "J3RD3",
        "timestamps": [
            5.3,
            10.8
        ]
    },
    "J3RD3_1": {
        "text": "a person opens the door to a room.",
        "vid": "J3RD3",
        "timestamps": [
            1.1,
            8.0
        ]
    },
    "J3RD3_2": {
        "text": "a person opens the door.",
        "vid": "J3RD3",
        "timestamps": [
            1.1,
            8.0
        ]
    },
    "1XOQ8_0": {
        "text": "person they start throwing shoes out of the way.",
        "vid": "1XOQ8",
        "timestamps": [
            1.1,
            6.2
        ]
    },
    "GMPHO_0": {
        "text": "person opens a closet door.",
        "vid": "GMPHO",
        "timestamps": [
            1.0,
            9.0
        ]
    },
    "GMPHO_1": {
        "text": "person opening their closet door.",
        "vid": "GMPHO",
        "timestamps": [
            1.0,
            9.0
        ]
    },
    "GMPHO_2": {
        "text": "person walking out the doorway.",
        "vid": "GMPHO",
        "timestamps": [
            34.4,
            41.0
        ]
    },
    "GMPHO_3": {
        "text": "a person opens the closet takes stuff out.",
        "vid": "GMPHO",
        "timestamps": [
            1.0,
            9.8
        ]
    },
    "21O5C_0": {
        "text": "person runs out of room.",
        "vid": "21O5C",
        "timestamps": [
            3.0,
            9.0
        ]
    },
    "21O5C_1": {
        "text": "a person runs through the doorway.",
        "vid": "21O5C",
        "timestamps": [
            3.0,
            9.0
        ]
    },
    "JFBTV_0": {
        "text": "a person opens a closet door.",
        "vid": "JFBTV",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "JFBTV_1": {
        "text": "a person flips a light switch.",
        "vid": "JFBTV",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "JFBTV_2": {
        "text": "the person closes the door.",
        "vid": "JFBTV",
        "timestamps": [
            16.8,
            22.6
        ]
    },
    "JFBTV_3": {
        "text": "a person opens up a closet door.",
        "vid": "JFBTV",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "JFBTV_4": {
        "text": "person opens a door to a closet.",
        "vid": "JFBTV",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "JFBTV_5": {
        "text": "person drinks from a bottle.",
        "vid": "JFBTV",
        "timestamps": [
            21.5,
            30.3
        ]
    },
    "JFBTV_6": {
        "text": "person walks out of the closet closing the door.",
        "vid": "JFBTV",
        "timestamps": [
            16.8,
            22.6
        ]
    },
    "15RTV_0": {
        "text": "person eating a cookie.",
        "vid": "15RTV",
        "timestamps": [
            12.1,
            20.1
        ]
    },
    "15RTV_1": {
        "text": "person putting a pillow in the closet.",
        "vid": "15RTV",
        "timestamps": [
            3.1,
            13.2
        ]
    },
    "3LMTS_0": {
        "text": "person begin talking on the phone.",
        "vid": "3LMTS",
        "timestamps": [
            16.2,
            31.0
        ]
    },
    "3LMTS_1": {
        "text": "person holding the phone in between their shoulder.",
        "vid": "3LMTS",
        "timestamps": [
            16.3,
            31.0
        ]
    },
    "8TSU4_0": {
        "text": "person eating some food.",
        "vid": "8TSU4",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "7835X_0": {
        "text": "a person throws shoes in the corner.",
        "vid": "7835X",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "7835X_1": {
        "text": "person throws a pair of shoes in the corner.",
        "vid": "7835X",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "7835X_2": {
        "text": "person throw shoes into a corner.",
        "vid": "7835X",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "C10FA_0": {
        "text": "person pour it into a glass.",
        "vid": "C10FA",
        "timestamps": [
            16.4,
            32.2
        ]
    },
    "C10FA_1": {
        "text": "person pours some milk into the glass.",
        "vid": "C10FA",
        "timestamps": [
            16.4,
            32.2
        ]
    },
    "C10FA_2": {
        "text": "a person holding a glass opens the refrigerator.",
        "vid": "C10FA",
        "timestamps": [
            9.0,
            21.9
        ]
    },
    "C10FA_3": {
        "text": "person they pour it into the glass.",
        "vid": "C10FA",
        "timestamps": [
            16.4,
            32.2
        ]
    },
    "PXY5Q_0": {
        "text": "person looks at a picture hanging there.",
        "vid": "PXY5Q",
        "timestamps": [
            23.0,
            33.0
        ]
    },
    "PXY5Q_1": {
        "text": "person takes out a glass of water.",
        "vid": "PXY5Q",
        "timestamps": [
            6.4,
            13.3
        ]
    },
    "PXY5Q_2": {
        "text": "the person puts the water down on the table.",
        "vid": "PXY5Q",
        "timestamps": [
            19.0,
            24.6
        ]
    },
    "PXY5Q_3": {
        "text": "a person opens the cabinet.",
        "vid": "PXY5Q",
        "timestamps": [
            4.0,
            10.2
        ]
    },
    "PXY5Q_4": {
        "text": "person looked at a picture on the wall.",
        "vid": "PXY5Q",
        "timestamps": [
            23.0,
            33.0
        ]
    },
    "41T8C_0": {
        "text": "a person is sneezing.",
        "vid": "41T8C",
        "timestamps": [
            5.1,
            11.7
        ]
    },
    "41T8C_1": {
        "text": "person puts the book on the shelf.",
        "vid": "41T8C",
        "timestamps": [
            12.3,
            20.5
        ]
    },
    "RRQEV_0": {
        "text": "the person puts away the blanket.",
        "vid": "RRQEV",
        "timestamps": [
            4.7,
            11.3
        ]
    },
    "GLSU2_0": {
        "text": "the person takes a towel from the cabinet.",
        "vid": "GLSU2",
        "timestamps": [
            14.2,
            19.7
        ]
    },
    "GLSU2_1": {
        "text": "a person walks into the pantry eating a sandwich.",
        "vid": "GLSU2",
        "timestamps": [
            11.2,
            24.1
        ]
    },
    "MXATD_0": {
        "text": "the person opens a cabinet to take detergent.",
        "vid": "MXATD",
        "timestamps": [
            5.3,
            10.8
        ]
    },
    "MXATD_1": {
        "text": "person pour in some dish washing soap.",
        "vid": "MXATD",
        "timestamps": [
            0.6,
            9.0
        ]
    },
    "MXATD_2": {
        "text": "a person puts the dishes away.",
        "vid": "MXATD",
        "timestamps": [
            0.2,
            6.0
        ]
    },
    "MXATD_3": {
        "text": "person puts dishes in a sink.",
        "vid": "MXATD",
        "timestamps": [
            0.2,
            6.0
        ]
    },
    "MXATD_4": {
        "text": "person puts dish soap into the sink.",
        "vid": "MXATD",
        "timestamps": [
            0.2,
            6.0
        ]
    },
    "3VT73_0": {
        "text": "person he takes his cell phone out.",
        "vid": "3VT73",
        "timestamps": [
            10.4,
            15.9
        ]
    },
    "3VT73_1": {
        "text": "the person throws a book.",
        "vid": "3VT73",
        "timestamps": [
            8.4,
            13.1
        ]
    },
    "3VT73_2": {
        "text": "a person sits down as they read a book.",
        "vid": "3VT73",
        "timestamps": [
            2.3,
            11.6
        ]
    },
    "29V7T_0": {
        "text": "person turning on the light.",
        "vid": "29V7T",
        "timestamps": [
            4.4,
            9.4
        ]
    },
    "29V7T_1": {
        "text": "person turns on the light.",
        "vid": "29V7T",
        "timestamps": [
            4.4,
            9.4
        ]
    },
    "29V7T_2": {
        "text": "person they are holding a broom instead of the glasses.",
        "vid": "29V7T",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "BLWIW_0": {
        "text": "person looking out the window.",
        "vid": "BLWIW",
        "timestamps": [
            13.0,
            19.0
        ]
    },
    "LSH63_0": {
        "text": "person put the bag on top of a table.",
        "vid": "LSH63",
        "timestamps": [
            10.0,
            16.9
        ]
    },
    "MCMTH_0": {
        "text": "person begins washing the glass.",
        "vid": "MCMTH",
        "timestamps": [
            21.0,
            35.0
        ]
    },
    "E0OJ8_0": {
        "text": "a person is tidying some books on the table.",
        "vid": "E0OJ8",
        "timestamps": [
            0.0,
            11.8
        ]
    },
    "E9UYZ_0": {
        "text": "person puts the medicine down in the table.",
        "vid": "E9UYZ",
        "timestamps": [
            7.2,
            13.8
        ]
    },
    "G71O7_0": {
        "text": "person they begin laughing when they look at the screen.",
        "vid": "G71O7",
        "timestamps": [
            43.8,
            48.0
        ]
    },
    "3KDI5_0": {
        "text": "working on a laptop in a relaxed manner.",
        "vid": "3KDI5",
        "timestamps": [
            21.9,
            36.0
        ]
    },
    "3KDI5_1": {
        "text": "person starts playing games on a laptop.",
        "vid": "3KDI5",
        "timestamps": [
            21.9,
            36.0
        ]
    },
    "ICQZX_0": {
        "text": "a person opens a closet door.",
        "vid": "ICQZX",
        "timestamps": [
            0.0,
            5.8
        ]
    },
    "ICQZX_1": {
        "text": "the person takes a book from the wardrobe.",
        "vid": "ICQZX",
        "timestamps": [
            12.5,
            18.0
        ]
    },
    "ICQZX_2": {
        "text": "person the take shoes out of the closet stand up.",
        "vid": "ICQZX",
        "timestamps": [
            9.4,
            14.7
        ]
    },
    "448J4_0": {
        "text": "person puts the plate on a table.",
        "vid": "448J4",
        "timestamps": [
            13.8,
            21.9
        ]
    },
    "448J4_1": {
        "text": "a person walks through a doorway carrying a plate.",
        "vid": "448J4",
        "timestamps": [
            1.3,
            7.3
        ]
    },
    "BFH78_0": {
        "text": "person they are holding a towel.",
        "vid": "BFH78",
        "timestamps": [
            21.0,
            32.0
        ]
    },
    "BFH78_1": {
        "text": "the person holds a small towel.",
        "vid": "BFH78",
        "timestamps": [
            21.0,
            32.0
        ]
    },
    "BFH78_2": {
        "text": "person begin smiling.",
        "vid": "BFH78",
        "timestamps": [
            23.8,
            30.7
        ]
    },
    "X37P1_0": {
        "text": "person takes a drink out of the glass.",
        "vid": "X37P1",
        "timestamps": [
            14.1,
            20.7
        ]
    },
    "IDXM0_0": {
        "text": "one person opens a box of shoes.",
        "vid": "IDXM0",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "NB0IB_0": {
        "text": "a person opens their kitchen pantry doors.",
        "vid": "NB0IB",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "NB0IB_1": {
        "text": "a person opens a pantry door.",
        "vid": "NB0IB",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "BW2OT_0": {
        "text": "the person is eating a sandwich.",
        "vid": "BW2OT",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "BW2OT_1": {
        "text": "person eating a sandwich.",
        "vid": "BW2OT",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "CLAWJ_0": {
        "text": "person begin to undress.",
        "vid": "CLAWJ",
        "timestamps": [
            23.7,
            33.0
        ]
    },
    "CLAWJ_1": {
        "text": "person undressing next to the wardrobe in the basement.",
        "vid": "CLAWJ",
        "timestamps": [
            23.7,
            33.0
        ]
    },
    "3QL7J_0": {
        "text": "person getting a bite to eat out of the fridge.",
        "vid": "3QL7J",
        "timestamps": [
            20.9,
            27.8
        ]
    },
    "3QL7J_1": {
        "text": "person eats it.",
        "vid": "3QL7J",
        "timestamps": [
            20.9,
            27.8
        ]
    },
    "3QL7J_2": {
        "text": "person cooks some food on the stove.",
        "vid": "3QL7J",
        "timestamps": [
            0.0,
            15.6
        ]
    },
    "3QL7J_3": {
        "text": "a person is cooking some eggs on a frying pan.",
        "vid": "3QL7J",
        "timestamps": [
            0.0,
            15.6
        ]
    },
    "3QL7J_4": {
        "text": "person looking out the window.",
        "vid": "3QL7J",
        "timestamps": [
            25.8,
            31.6
        ]
    },
    "3QL7J_5": {
        "text": "person looking out of the window.",
        "vid": "3QL7J",
        "timestamps": [
            25.8,
            31.6
        ]
    },
    "3QL7J_6": {
        "text": "person takes some food out of it.",
        "vid": "3QL7J",
        "timestamps": [
            19.1,
            25.8
        ]
    },
    "9LTZT_0": {
        "text": "person drinks something from the glass.",
        "vid": "9LTZT",
        "timestamps": [
            13.6,
            22.9
        ]
    },
    "JVOM3_0": {
        "text": "person holding a flashlight.",
        "vid": "JVOM3",
        "timestamps": [
            4.7,
            9.4
        ]
    },
    "JVOM3_1": {
        "text": "person a flashlight by the doorway.",
        "vid": "JVOM3",
        "timestamps": [
            4.7,
            9.4
        ]
    },
    "JVOM3_2": {
        "text": "person closes the book.",
        "vid": "JVOM3",
        "timestamps": [
            11.4,
            18.0
        ]
    },
    "JVOM3_3": {
        "text": "person begins to undress.",
        "vid": "JVOM3",
        "timestamps": [
            16.9,
            32.0
        ]
    },
    "JVOM3_4": {
        "text": "person holding a book shines a flashlight forward.",
        "vid": "JVOM3",
        "timestamps": [
            4.7,
            9.4
        ]
    },
    "GFPDD_0": {
        "text": "a person walks into the kitchen holding a box.",
        "vid": "GFPDD",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "A59CN_0": {
        "text": "person turns the light on.",
        "vid": "A59CN",
        "timestamps": [
            18.6,
            25.0
        ]
    },
    "A59CN_1": {
        "text": "person turn on the light.",
        "vid": "A59CN",
        "timestamps": [
            18.6,
            25.0
        ]
    },
    "A59CN_2": {
        "text": "person turned on a light.",
        "vid": "A59CN",
        "timestamps": [
            18.6,
            25.0
        ]
    },
    "4PEL7_0": {
        "text": "person sits on the couch.",
        "vid": "4PEL7",
        "timestamps": [
            18.6,
            23.7
        ]
    },
    "4PEL7_1": {
        "text": "person closing the bathroom door behind him.",
        "vid": "4PEL7",
        "timestamps": [
            7.7,
            13.6
        ]
    },
    "4PEL7_2": {
        "text": "the person turns the light off.",
        "vid": "4PEL7",
        "timestamps": [
            6.6,
            11.6
        ]
    },
    "4PEL7_3": {
        "text": "person walks into a room to sit on the couch.",
        "vid": "4PEL7",
        "timestamps": [
            18.6,
            23.7
        ]
    },
    "4PEL7_4": {
        "text": "person cuts off the light.",
        "vid": "4PEL7",
        "timestamps": [
            6.6,
            11.6
        ]
    },
    "MZ3X9_0": {
        "text": "a person takes a phone.",
        "vid": "MZ3X9",
        "timestamps": [
            15.8,
            29.1
        ]
    },
    "MZ3X9_1": {
        "text": "person open the door.",
        "vid": "MZ3X9",
        "timestamps": [
            2.6,
            10.0
        ]
    },
    "MZ3X9_2": {
        "text": "person takes out a broom.",
        "vid": "MZ3X9",
        "timestamps": [
            8.7,
            17.9
        ]
    },
    "MZ3X9_3": {
        "text": "person take out he broom from inside.",
        "vid": "MZ3X9",
        "timestamps": [
            8.7,
            17.9
        ]
    },
    "MZ3X9_4": {
        "text": "person holding the phone.",
        "vid": "MZ3X9",
        "timestamps": [
            17.7,
            27.7
        ]
    },
    "MZ3X9_5": {
        "text": "person opens a door.",
        "vid": "MZ3X9",
        "timestamps": [
            2.6,
            10.0
        ]
    },
    "UUF84_0": {
        "text": "the person takes the medicine.",
        "vid": "UUF84",
        "timestamps": [
            12.2,
            22.8
        ]
    },
    "UUF84_1": {
        "text": "person begins undressing by removing their socks.",
        "vid": "UUF84",
        "timestamps": [
            24.5,
            33.0
        ]
    },
    "UUF84_2": {
        "text": "person takes off their shoes.",
        "vid": "UUF84",
        "timestamps": [
            24.5,
            32.5
        ]
    },
    "UUF84_3": {
        "text": "person eat some food.",
        "vid": "UUF84",
        "timestamps": [
            12.4,
            20.2
        ]
    },
    "4GHHK_0": {
        "text": "a person opens a cabinet.",
        "vid": "4GHHK",
        "timestamps": [
            0.2,
            5.2
        ]
    },
    "LIQS5_0": {
        "text": "a person in the bathroom is smiling.",
        "vid": "LIQS5",
        "timestamps": [
            17.2,
            33.0
        ]
    },
    "LIQS5_1": {
        "text": "the person is also playing with a camera.",
        "vid": "LIQS5",
        "timestamps": [
            30.0,
            33.0
        ]
    },
    "YAFX0_0": {
        "text": "person puts the dirty clothes in the washer.",
        "vid": "YAFX0",
        "timestamps": [
            6.2,
            14.9
        ]
    },
    "YAFX0_1": {
        "text": "a person puts down a large bag.",
        "vid": "YAFX0",
        "timestamps": [
            4.2,
            9.3
        ]
    },
    "YAFX0_2": {
        "text": "person looks out of a window.",
        "vid": "YAFX0",
        "timestamps": [
            9.2,
            26.9
        ]
    },
    "YAFX0_3": {
        "text": "person looks out the window.",
        "vid": "YAFX0",
        "timestamps": [
            9.2,
            26.9
        ]
    },
    "YAFX0_4": {
        "text": "person starts washing the clothes.",
        "vid": "YAFX0",
        "timestamps": [
            18.8,
            29.5
        ]
    },
    "YAFX0_5": {
        "text": "the person looks out the window.",
        "vid": "YAFX0",
        "timestamps": [
            9.2,
            26.9
        ]
    },
    "O87OF_0": {
        "text": "person puts it on a table.",
        "vid": "O87OF",
        "timestamps": [
            0.0,
            10.5
        ]
    },
    "O87OF_1": {
        "text": "person puts jacket on table.",
        "vid": "O87OF",
        "timestamps": [
            0.0,
            10.5
        ]
    },
    "USNON_0": {
        "text": "the person closed the entry door.",
        "vid": "USNON",
        "timestamps": [
            21.5,
            30.3
        ]
    },
    "USNON_1": {
        "text": "person still smiling.",
        "vid": "USNON",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "USNON_2": {
        "text": "person closes the door.",
        "vid": "USNON",
        "timestamps": [
            21.5,
            30.3
        ]
    },
    "USNON_3": {
        "text": "person proceeds to close a door.",
        "vid": "USNON",
        "timestamps": [
            21.5,
            30.3
        ]
    },
    "ZZ4GP_0": {
        "text": "a person is standing at a stove cooking.",
        "vid": "ZZ4GP",
        "timestamps": [
            0.0,
            11.9
        ]
    },
    "ZZ4GP_1": {
        "text": "a person is cooking some food on the stove.",
        "vid": "ZZ4GP",
        "timestamps": [
            0.0,
            11.9
        ]
    },
    "ZZ4GP_2": {
        "text": "a person is cooking at a stove.",
        "vid": "ZZ4GP",
        "timestamps": [
            0.0,
            11.9
        ]
    },
    "ZZ4GP_3": {
        "text": "person he stops cooking.",
        "vid": "ZZ4GP",
        "timestamps": [
            0.0,
            11.9
        ]
    },
    "0HV07_0": {
        "text": "a person walks into a bedroom holding clothes.",
        "vid": "0HV07",
        "timestamps": [
            18.8,
            28.5
        ]
    },
    "5TKIB_0": {
        "text": "the person opens the bag.",
        "vid": "5TKIB",
        "timestamps": [
            18.2,
            23.7
        ]
    },
    "YB67Z_0": {
        "text": "person close the top of the box.",
        "vid": "YB67Z",
        "timestamps": [
            13.7,
            18.9
        ]
    },
    "XSVLL_0": {
        "text": "person runs to a table.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "XSVLL_1": {
        "text": "person runs back to sit down.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "XSVLL_2": {
        "text": "a person runs into the entryway.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "XSVLL_3": {
        "text": "person sits down at the table.",
        "vid": "XSVLL",
        "timestamps": [
            27.0,
            33.0
        ]
    },
    "XSVLL_4": {
        "text": "a person runs around the room.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "XSVLL_5": {
        "text": "a person runs to the door.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "XSVLL_6": {
        "text": "a person runs around the house.",
        "vid": "XSVLL",
        "timestamps": [
            0.0,
            10.8
        ]
    },
    "HJ4B1_0": {
        "text": "person looks over at a picture.",
        "vid": "HJ4B1",
        "timestamps": [
            14.8,
            23.9
        ]
    },
    "HJ4B1_1": {
        "text": "a person awakens in  a bedroom.",
        "vid": "HJ4B1",
        "timestamps": [
            2.1,
            10.7
        ]
    },
    "Z6B6S_0": {
        "text": "person putting the food back on the shelf.",
        "vid": "Z6B6S",
        "timestamps": [
            9.9,
            18.2
        ]
    },
    "UUPJS_0": {
        "text": "a person holding a broom puts it down.",
        "vid": "UUPJS",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "UUPJS_1": {
        "text": "person puts the broom down to pick up a book.",
        "vid": "UUPJS",
        "timestamps": [
            2.6,
            9.1
        ]
    },
    "UUPJS_2": {
        "text": "a person is holding a broom in a laundry room.",
        "vid": "UUPJS",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "UUPJS_3": {
        "text": "person puts the broom down.",
        "vid": "UUPJS",
        "timestamps": [
            2.6,
            9.1
        ]
    },
    "TESF6_0": {
        "text": "person puts a camera into it.",
        "vid": "TESF6",
        "timestamps": [
            17.6,
            22.9
        ]
    },
    "TESF6_1": {
        "text": "person puts it oin the box.",
        "vid": "TESF6",
        "timestamps": [
            2.9,
            10.1
        ]
    },
    "TESF6_2": {
        "text": "a person opens a box.",
        "vid": "TESF6",
        "timestamps": [
            3.2,
            10.8
        ]
    },
    "TESF6_3": {
        "text": "this person holds the box.",
        "vid": "TESF6",
        "timestamps": [
            21.3,
            31.0
        ]
    },
    "TESF6_4": {
        "text": "person he takes out his camera.",
        "vid": "TESF6",
        "timestamps": [
            7.1,
            13.0
        ]
    },
    "TESF6_5": {
        "text": "person putting it in the box.",
        "vid": "TESF6",
        "timestamps": [
            2.9,
            10.1
        ]
    },
    "TESF6_6": {
        "text": "one person at a sofa opens a box.",
        "vid": "TESF6",
        "timestamps": [
            3.2,
            10.8
        ]
    },
    "00607_0": {
        "text": "person put the broom on the floor.",
        "vid": "00607",
        "timestamps": [
            25.9,
            31.7
        ]
    },
    "1LBUG_0": {
        "text": "a person is sneezing by the door.",
        "vid": "1LBUG",
        "timestamps": [
            1.0,
            6.7
        ]
    },
    "XOOPP_0": {
        "text": "person stands on it to put a picture up.",
        "vid": "XOOPP",
        "timestamps": [
            6.7,
            15.2
        ]
    },
    "MIAE4_0": {
        "text": "person sits on a bed for a.",
        "vid": "MIAE4",
        "timestamps": [
            11.4,
            24.5
        ]
    },
    "MIAE4_1": {
        "text": "person walk through a doorway.",
        "vid": "MIAE4",
        "timestamps": [
            3.9,
            8.9
        ]
    },
    "J4QHT_0": {
        "text": "the person takes out a camera.",
        "vid": "J4QHT",
        "timestamps": [
            8.6,
            14.5
        ]
    },
    "J4QHT_1": {
        "text": "a person through a doorway walks to a closet.",
        "vid": "J4QHT",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "J4QHT_2": {
        "text": "a person is seen opening their closet doorway.",
        "vid": "J4QHT",
        "timestamps": [
            1.4,
            6.8
        ]
    },
    "JKWJ6_0": {
        "text": "person takes a bite of a sandwich.",
        "vid": "JKWJ6",
        "timestamps": [
            9.9,
            19.8
        ]
    },
    "JKWJ6_1": {
        "text": "a person is lying on the couch watching television.",
        "vid": "JKWJ6",
        "timestamps": [
            0.0,
            9.5
        ]
    },
    "JKWJ6_2": {
        "text": "the person eats a couple bites of their sandwich.",
        "vid": "JKWJ6",
        "timestamps": [
            13.8,
            23.1
        ]
    },
    "V6RRM_0": {
        "text": "person start undressing.",
        "vid": "V6RRM",
        "timestamps": [
            8.8,
            16.0
        ]
    },
    "W292V_0": {
        "text": "person opens the closet door.",
        "vid": "W292V",
        "timestamps": [
            12.2,
            19.8
        ]
    },
    "W292V_1": {
        "text": "person takes a drink from a red cup.",
        "vid": "W292V",
        "timestamps": [
            6.6,
            14.1
        ]
    },
    "W292V_2": {
        "text": "person open a closet door.",
        "vid": "W292V",
        "timestamps": [
            12.2,
            19.8
        ]
    },
    "W292V_3": {
        "text": "a person is awakening.",
        "vid": "W292V",
        "timestamps": [
            0.0,
            10.6
        ]
    },
    "N8913_0": {
        "text": "the person is also watching television.",
        "vid": "N8913",
        "timestamps": [
            27.3,
            33.0
        ]
    },
    "Y2EID_0": {
        "text": "person closes the door leading back outside.",
        "vid": "Y2EID",
        "timestamps": [
            4.8,
            10.5
        ]
    },
    "Y2EID_1": {
        "text": "a person opens a door.",
        "vid": "Y2EID",
        "timestamps": [
            3.6,
            9.1
        ]
    },
    "Y2EID_2": {
        "text": "person sneezing into it.",
        "vid": "Y2EID",
        "timestamps": [
            14.0,
            19.8
        ]
    },
    "RJZ3I_0": {
        "text": "person runs away down the hall.",
        "vid": "RJZ3I",
        "timestamps": [
            20.4,
            27.0
        ]
    },
    "RJZ3I_1": {
        "text": "person running away.",
        "vid": "RJZ3I",
        "timestamps": [
            20.4,
            27.0
        ]
    },
    "EFUTW_0": {
        "text": "a person is opening the refrigerator.",
        "vid": "EFUTW",
        "timestamps": [
            0.5,
            7.7
        ]
    },
    "EFUTW_1": {
        "text": "a person opens a refrigerator.",
        "vid": "EFUTW",
        "timestamps": [
            0.5,
            7.7
        ]
    },
    "W5YUE_0": {
        "text": "a person takes a pink blanket off of a chair.",
        "vid": "W5YUE",
        "timestamps": [
            7.9,
            16.2
        ]
    },
    "W5YUE_1": {
        "text": "person washing a glass in the sink.",
        "vid": "W5YUE",
        "timestamps": [
            17.5,
            30.9
        ]
    },
    "W5YUE_2": {
        "text": "a person takes a blanket from a chair.",
        "vid": "W5YUE",
        "timestamps": [
            7.9,
            16.2
        ]
    },
    "GYVK9_0": {
        "text": "person starts sneezing.",
        "vid": "GYVK9",
        "timestamps": [
            17.6,
            22.5
        ]
    },
    "GYVK9_1": {
        "text": "person sneezing several times.",
        "vid": "GYVK9",
        "timestamps": [
            17.6,
            22.5
        ]
    },
    "AFIRW_0": {
        "text": "the person takes out their phone.",
        "vid": "AFIRW",
        "timestamps": [
            16.4,
            23.6
        ]
    },
    "AFIRW_1": {
        "text": "person takes out a phone.",
        "vid": "AFIRW",
        "timestamps": [
            16.4,
            23.6
        ]
    },
    "AFIRW_2": {
        "text": "person takes a picture.",
        "vid": "AFIRW",
        "timestamps": [
            20.2,
            33.0
        ]
    },
    "AFIRW_3": {
        "text": "person in bathroom who washes hands.",
        "vid": "AFIRW",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "AFIRW_4": {
        "text": "person washes their hands.",
        "vid": "AFIRW",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "AFIRW_5": {
        "text": "person takes a selfie picture.",
        "vid": "AFIRW",
        "timestamps": [
            20.2,
            33.0
        ]
    },
    "AFIRW_6": {
        "text": "a person washes their hands with soap.",
        "vid": "AFIRW",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "M98YV_0": {
        "text": "person in their right they are holding a sandwich.",
        "vid": "M98YV",
        "timestamps": [
            28.1,
            31.0
        ]
    },
    "MTOFZ_0": {
        "text": "person drink out of the glass.",
        "vid": "MTOFZ",
        "timestamps": [
            19.4,
            30.0
        ]
    },
    "MTOFZ_1": {
        "text": "person drinking from an empty glass.",
        "vid": "MTOFZ",
        "timestamps": [
            19.4,
            30.0
        ]
    },
    "WD12X_0": {
        "text": "a person using a broom to close cabinet doors.",
        "vid": "WD12X",
        "timestamps": [
            2.4,
            7.3
        ]
    },
    "RKJ0C_0": {
        "text": "a person walks into a house laughing.",
        "vid": "RKJ0C",
        "timestamps": [
            0.0,
            14.4
        ]
    },
    "RKJ0C_1": {
        "text": "person sits at the table eating food.",
        "vid": "RKJ0C",
        "timestamps": [
            8.4,
            14.4
        ]
    },
    "RKJ0C_2": {
        "text": "a person closes a door.",
        "vid": "RKJ0C",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "RKJ0C_3": {
        "text": "a laughing person walks into their kitchen.",
        "vid": "RKJ0C",
        "timestamps": [
            0.0,
            14.4
        ]
    },
    "JBFPI_0": {
        "text": "person drinks from a glass.",
        "vid": "JBFPI",
        "timestamps": [
            7.6,
            13.9
        ]
    },
    "JBFPI_1": {
        "text": "the person takes a drink from a glass of water.",
        "vid": "JBFPI",
        "timestamps": [
            7.6,
            13.9
        ]
    },
    "JBFPI_2": {
        "text": "a person is working on their laptop.",
        "vid": "JBFPI",
        "timestamps": [
            0.0,
            9.3
        ]
    },
    "VU996_0": {
        "text": "person closed the door.",
        "vid": "VU996",
        "timestamps": [
            23.4,
            31.0
        ]
    },
    "VU996_1": {
        "text": "person puts some blankets away inside.",
        "vid": "VU996",
        "timestamps": [
            17.2,
            24.3
        ]
    },
    "VU996_2": {
        "text": "the person put the pillow into the closet.",
        "vid": "VU996",
        "timestamps": [
            7.4,
            14.7
        ]
    },
    "VU996_3": {
        "text": "a person walks into their closet holding a pillow.",
        "vid": "VU996",
        "timestamps": [
            0.0,
            14.9
        ]
    },
    "VU996_4": {
        "text": "person turns the light off.",
        "vid": "VU996",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "VU996_5": {
        "text": "person holding a pillow.",
        "vid": "VU996",
        "timestamps": [
            0.0,
            14.9
        ]
    },
    "VU996_6": {
        "text": "a person opens a door to a closet.",
        "vid": "VU996",
        "timestamps": [
            23.4,
            31.0
        ]
    },
    "VU996_7": {
        "text": "person closes the door behind them.",
        "vid": "VU996",
        "timestamps": [
            23.4,
            31.0
        ]
    },
    "VU996_8": {
        "text": "the person turns off the closet light.",
        "vid": "VU996",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "VU996_9": {
        "text": "person opened up the door.",
        "vid": "VU996",
        "timestamps": [
            0.4,
            7.0
        ]
    },
    "VQOI3_0": {
        "text": "person opening a bag.",
        "vid": "VQOI3",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "T42IZ_0": {
        "text": "person closes the fridge door.",
        "vid": "T42IZ",
        "timestamps": [
            19.9,
            26.9
        ]
    },
    "T42IZ_1": {
        "text": "person puts the groceries in the fridge.",
        "vid": "T42IZ",
        "timestamps": [
            12.4,
            22.6
        ]
    },
    "T42IZ_2": {
        "text": "same person opens the fridge door.",
        "vid": "T42IZ",
        "timestamps": [
            4.0,
            12.4
        ]
    },
    "422BV_0": {
        "text": "person look into a book.",
        "vid": "422BV",
        "timestamps": [
            10.4,
            16.0
        ]
    },
    "422BV_1": {
        "text": "person holding shoes.",
        "vid": "422BV",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "422BV_2": {
        "text": "person lending on the table put on some shoes.",
        "vid": "422BV",
        "timestamps": [
            5.1,
            13.7
        ]
    },
    "422BV_3": {
        "text": "the person put their shoes on.",
        "vid": "422BV",
        "timestamps": [
            5.1,
            13.7
        ]
    },
    "AYZS4_0": {
        "text": "a person is eating.",
        "vid": "AYZS4",
        "timestamps": [
            4.2,
            17.9
        ]
    },
    "AYZS4_1": {
        "text": "a person eats a banana.",
        "vid": "AYZS4",
        "timestamps": [
            4.2,
            17.9
        ]
    },
    "AYZS4_2": {
        "text": "person eating a banana.",
        "vid": "AYZS4",
        "timestamps": [
            4.2,
            17.9
        ]
    },
    "AYZS4_3": {
        "text": "person sitting down at a kitchen tables.",
        "vid": "AYZS4",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "AYZS4_4": {
        "text": "person tidy up the table.",
        "vid": "AYZS4",
        "timestamps": [
            14.9,
            26.3
        ]
    },
    "AYZS4_5": {
        "text": "the person is sitting at a table peeling.",
        "vid": "AYZS4",
        "timestamps": [
            0.0,
            8.2
        ]
    },
    "AYZS4_6": {
        "text": "person eats it.",
        "vid": "AYZS4",
        "timestamps": [
            4.2,
            17.9
        ]
    },
    "MA6GY_0": {
        "text": "person puts the others back in the box.",
        "vid": "MA6GY",
        "timestamps": [
            16.9,
            22.2
        ]
    },
    "MA6GY_1": {
        "text": "person opening a box.",
        "vid": "MA6GY",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "MA6GY_2": {
        "text": "a person opens a box of groceries.",
        "vid": "MA6GY",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "MA6GY_3": {
        "text": "person begins to take some medicine.",
        "vid": "MA6GY",
        "timestamps": [
            9.5,
            16.0
        ]
    },
    "YK49T_0": {
        "text": "a person can undress.",
        "vid": "YK49T",
        "timestamps": [
            0.0,
            13.6
        ]
    },
    "YLEEO_0": {
        "text": "a person closes a door.",
        "vid": "YLEEO",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "ST7MR_0": {
        "text": "person closes the door.",
        "vid": "ST7MR",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "ST7MR_1": {
        "text": "person they start throwing their clothes toward the doorway.",
        "vid": "ST7MR",
        "timestamps": [
            45.7,
            49.0
        ]
    },
    "ST7MR_2": {
        "text": "person they throw it on the floor.",
        "vid": "ST7MR",
        "timestamps": [
            28.3,
            35.7
        ]
    },
    "ST7MR_3": {
        "text": "person closes a door.",
        "vid": "ST7MR",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "WDF45_0": {
        "text": "person puts it on a table.",
        "vid": "WDF45",
        "timestamps": [
            5.4,
            10.1
        ]
    },
    "WDF45_1": {
        "text": "the person puts the phone down.",
        "vid": "WDF45",
        "timestamps": [
            5.3,
            10.2
        ]
    },
    "ITDHX_0": {
        "text": "person putting a pillow on the bed in the bedroom.",
        "vid": "ITDHX",
        "timestamps": [
            22.5,
            33.0
        ]
    },
    "8YFD1_0": {
        "text": "person starts undressing.",
        "vid": "8YFD1",
        "timestamps": [
            7.1,
            18.8
        ]
    },
    "8YFD1_1": {
        "text": "person is standing in laundry room looking fixing their hair.",
        "vid": "8YFD1",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "8YFD1_2": {
        "text": "a person fixes their hair in a mirror.",
        "vid": "8YFD1",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "8YFD1_3": {
        "text": "looking in mirror,then person starts undressing.",
        "vid": "8YFD1",
        "timestamps": [
            7.1,
            18.8
        ]
    },
    "RBQ9Y_0": {
        "text": "person stand up again.",
        "vid": "RBQ9Y",
        "timestamps": [
            47.9,
            54.9
        ]
    },
    "RBQ9Y_1": {
        "text": "a man begins to undress.",
        "vid": "RBQ9Y",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "RBQ9Y_2": {
        "text": "person sit on the bed.",
        "vid": "RBQ9Y",
        "timestamps": [
            38.6,
            51.9
        ]
    },
    "RBQ9Y_3": {
        "text": "person put on some shoes.",
        "vid": "RBQ9Y",
        "timestamps": [
            39.2,
            51.9
        ]
    },
    "RBQ9Y_4": {
        "text": "person putting away clothes in a bedroom.",
        "vid": "RBQ9Y",
        "timestamps": [
            53.2,
            59.0
        ]
    },
    "RBQ9Y_5": {
        "text": "person putting his clothes on the bed beside him.",
        "vid": "RBQ9Y",
        "timestamps": [
            53.2,
            59.0
        ]
    },
    "RBQ9Y_6": {
        "text": "person putting on shoes.",
        "vid": "RBQ9Y",
        "timestamps": [
            39.2,
            51.9
        ]
    },
    "RBQ9Y_7": {
        "text": "person sits down on the bed to fix his shoes.",
        "vid": "RBQ9Y",
        "timestamps": [
            38.6,
            51.9
        ]
    },
    "GV0L7_0": {
        "text": "a person turns the light on.",
        "vid": "GV0L7",
        "timestamps": [
            3.3,
            10.0
        ]
    },
    "GV0L7_1": {
        "text": "person sits on a couch.",
        "vid": "GV0L7",
        "timestamps": [
            0.1,
            12.6
        ]
    },
    "GV0L7_2": {
        "text": "person sits down on the couch.",
        "vid": "GV0L7",
        "timestamps": [
            0.1,
            12.6
        ]
    },
    "GV0L7_3": {
        "text": "a person turns a light on.",
        "vid": "GV0L7",
        "timestamps": [
            3.3,
            10.0
        ]
    },
    "ABPGE_0": {
        "text": "person takes a book from the shelf.",
        "vid": "ABPGE",
        "timestamps": [
            10.5,
            18.6
        ]
    },
    "ABPGE_1": {
        "text": "person they begin drinking a glass of water.",
        "vid": "ABPGE",
        "timestamps": [
            4.2,
            17.2
        ]
    },
    "V7YEJ_0": {
        "text": "a person lying on the floor awakens.",
        "vid": "V7YEJ",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "V7YEJ_1": {
        "text": "person begins eating.",
        "vid": "V7YEJ",
        "timestamps": [
            9.9,
            16.9
        ]
    },
    "V7YEJ_2": {
        "text": "person starts eating.",
        "vid": "V7YEJ",
        "timestamps": [
            9.9,
            16.9
        ]
    },
    "V7YEJ_3": {
        "text": "a person awakens on the floor of their recreation room.",
        "vid": "V7YEJ",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "USPJK_0": {
        "text": "the person takes a broom.",
        "vid": "USPJK",
        "timestamps": [
            17.7,
            23.9
        ]
    },
    "DUSJO_0": {
        "text": "a person looks out the window.",
        "vid": "DUSJO",
        "timestamps": [
            15.0,
            22.0
        ]
    },
    "DUSJO_1": {
        "text": "person puts the cup on a shelf.",
        "vid": "DUSJO",
        "timestamps": [
            6.9,
            12.6
        ]
    },
    "DUSJO_2": {
        "text": "person puts cup on shelf.",
        "vid": "DUSJO",
        "timestamps": [
            6.9,
            12.6
        ]
    },
    "DUSJO_3": {
        "text": "person looking out window.",
        "vid": "DUSJO",
        "timestamps": [
            15.0,
            22.0
        ]
    },
    "ACSP8_0": {
        "text": "person begins playing with their phone.",
        "vid": "ACSP8",
        "timestamps": [
            22.1,
            32.0
        ]
    },
    "21F9H_0": {
        "text": "person puts a pillow down on the bed.",
        "vid": "21F9H",
        "timestamps": [
            21.0,
            26.9
        ]
    },
    "21F9H_1": {
        "text": "a person is drinking a cup of coffee.",
        "vid": "21F9H",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "21F9H_2": {
        "text": "sitting down on a bed in a comfortable manner.",
        "vid": "21F9H",
        "timestamps": [
            26.2,
            31.0
        ]
    },
    "OWRDE_0": {
        "text": "person eating some food.",
        "vid": "OWRDE",
        "timestamps": [
            0.9,
            13.0
        ]
    },
    "OWRDE_1": {
        "text": "a person quickly eats something.",
        "vid": "OWRDE",
        "timestamps": [
            0.9,
            13.0
        ]
    },
    "OWRDE_2": {
        "text": "person sits on stairs to put on shoes.",
        "vid": "OWRDE",
        "timestamps": [
            20.8,
            36.9
        ]
    },
    "OWRDE_3": {
        "text": "person puts on tennis shoes.",
        "vid": "OWRDE",
        "timestamps": [
            20.8,
            36.9
        ]
    },
    "OWRDE_4": {
        "text": "person puts on shoes.",
        "vid": "OWRDE",
        "timestamps": [
            20.8,
            36.9
        ]
    },
    "OWRDE_5": {
        "text": "person unwraps & eats something.",
        "vid": "OWRDE",
        "timestamps": [
            0.9,
            13.0
        ]
    },
    "YG9UR_0": {
        "text": "person opened the book.",
        "vid": "YG9UR",
        "timestamps": [
            12.2,
            18.1
        ]
    },
    "CTIYN_0": {
        "text": "person sneezing into a blanket.",
        "vid": "CTIYN",
        "timestamps": [
            7.5,
            19.9
        ]
    },
    "KTXSD_0": {
        "text": "person takes something from the cupboard.",
        "vid": "KTXSD",
        "timestamps": [
            5.4,
            10.0
        ]
    },
    "TBRZ5_0": {
        "text": "the person can be seen playing with the phone.",
        "vid": "TBRZ5",
        "timestamps": [
            22.8,
            33.0
        ]
    },
    "JMCBE_0": {
        "text": "a person is throwing a blanket down the stairs.",
        "vid": "JMCBE",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "JMCBE_1": {
        "text": "a person is throwing items off the stairs like blankets.",
        "vid": "JMCBE",
        "timestamps": [
            0.0,
            6.5
        ]
    },
    "S06H3_0": {
        "text": "a person puts some food on a shelf.",
        "vid": "S06H3",
        "timestamps": [
            7.4,
            13.7
        ]
    },
    "S06H3_1": {
        "text": "a person puts something on the shelf of the garage.",
        "vid": "S06H3",
        "timestamps": [
            7.4,
            13.7
        ]
    },
    "7229M_0": {
        "text": "person takes a notebook.",
        "vid": "7229M",
        "timestamps": [
            25.2,
            36.0
        ]
    },
    "7229M_1": {
        "text": "person put on the shoes.",
        "vid": "7229M",
        "timestamps": [
            8.6,
            15.2
        ]
    },
    "RIZ7Y_0": {
        "text": "person runs out.",
        "vid": "RIZ7Y",
        "timestamps": [
            12.7,
            18.6
        ]
    },
    "RIZ7Y_1": {
        "text": "another person runs in.",
        "vid": "RIZ7Y",
        "timestamps": [
            12.7,
            18.6
        ]
    },
    "RIZ7Y_2": {
        "text": "another person runs past them.",
        "vid": "RIZ7Y",
        "timestamps": [
            12.7,
            18.6
        ]
    },
    "OIL1V_0": {
        "text": "person grabs a drinking glass from the floor.",
        "vid": "OIL1V",
        "timestamps": [
            11.1,
            16.0
        ]
    },
    "VBN1O_0": {
        "text": "a person comes running into the room.",
        "vid": "VBN1O",
        "timestamps": [
            0.0,
            6.7
        ]
    },
    "VBN1O_1": {
        "text": "a person enters through a doorway running.",
        "vid": "VBN1O",
        "timestamps": [
            0.0,
            6.7
        ]
    },
    "PCNUP_0": {
        "text": "person puts down a picture.",
        "vid": "PCNUP",
        "timestamps": [
            4.3,
            9.7
        ]
    },
    "PCNUP_1": {
        "text": "person puts the picture on the floor.",
        "vid": "PCNUP",
        "timestamps": [
            4.3,
            9.7
        ]
    },
    "PCNUP_2": {
        "text": "the person puts the picture down.",
        "vid": "PCNUP",
        "timestamps": [
            4.3,
            9.7
        ]
    },
    "PCNUP_3": {
        "text": "person starts smiling.",
        "vid": "PCNUP",
        "timestamps": [
            13.5,
            25.0
        ]
    },
    "PCNUP_4": {
        "text": "a person is holding a picture.",
        "vid": "PCNUP",
        "timestamps": [
            0.0,
            9.1
        ]
    },
    "PCNUP_5": {
        "text": "a person turns on the light.",
        "vid": "PCNUP",
        "timestamps": [
            2.0,
            7.1
        ]
    },
    "XHN6Y_0": {
        "text": "a person is cooking something on the stove.",
        "vid": "XHN6Y",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "XHN6Y_1": {
        "text": "a person is cooking at the stove.",
        "vid": "XHN6Y",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "W5ZY8_0": {
        "text": "person smiling at a camera.",
        "vid": "W5ZY8",
        "timestamps": [
            21.7,
            28.5
        ]
    },
    "K7Z6T_0": {
        "text": "a person opens a plastic bag.",
        "vid": "K7Z6T",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "K7Z6T_1": {
        "text": "one person opens a bag.",
        "vid": "K7Z6T",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "3P055_0": {
        "text": "a person is dressing in front of a mirror.",
        "vid": "3P055",
        "timestamps": [
            7.5,
            27.7
        ]
    },
    "PZ0ND_0": {
        "text": "person begin dressing.",
        "vid": "PZ0ND",
        "timestamps": [
            9.1,
            13.0
        ]
    },
    "ZC017_0": {
        "text": "person began tidying up a small table.",
        "vid": "ZC017",
        "timestamps": [
            10.2,
            18.8
        ]
    },
    "ZC017_1": {
        "text": "the person watching television got up.",
        "vid": "ZC017",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "ZC017_2": {
        "text": "person takes a bottle of medicine out of a box.",
        "vid": "ZC017",
        "timestamps": [
            13.7,
            21.3
        ]
    },
    "ZC017_3": {
        "text": "a person is sitting on the couch watching television.",
        "vid": "ZC017",
        "timestamps": [
            0.0,
            9.3
        ]
    },
    "ARKBT_0": {
        "text": "person the persin opens the dryer door.",
        "vid": "ARKBT",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "ARKBT_1": {
        "text": "person closes the door of the dryer.",
        "vid": "ARKBT",
        "timestamps": [
            24.7,
            29.0
        ]
    },
    "KB916_0": {
        "text": "person holding a towel.",
        "vid": "KB916",
        "timestamps": [
            0.0,
            14.0
        ]
    },
    "XEJ35_0": {
        "text": "person opened a book.",
        "vid": "XEJ35",
        "timestamps": [
            5.1,
            10.6
        ]
    },
    "XEJ35_1": {
        "text": "the person opens a book.",
        "vid": "XEJ35",
        "timestamps": [
            5.1,
            10.6
        ]
    },
    "X06Z6_0": {
        "text": "person they look out the window.",
        "vid": "X06Z6",
        "timestamps": [
            14.9,
            24.0
        ]
    },
    "QQMY8_0": {
        "text": "person takes a glass off of a table.",
        "vid": "QQMY8",
        "timestamps": [
            6.3,
            11.7
        ]
    },
    "QQMY8_1": {
        "text": "the person turns on a light.",
        "vid": "QQMY8",
        "timestamps": [
            0.8,
            5.4
        ]
    },
    "QQMY8_2": {
        "text": "person turns out the light in the closet.",
        "vid": "QQMY8",
        "timestamps": [
            0.8,
            5.4
        ]
    },
    "QQMY8_3": {
        "text": "person turning on a light.",
        "vid": "QQMY8",
        "timestamps": [
            0.8,
            5.4
        ]
    },
    "QQMY8_4": {
        "text": "person grabs a cup turns off the light.",
        "vid": "QQMY8",
        "timestamps": [
            9.8,
            14.0
        ]
    },
    "HUWAZ_0": {
        "text": "person drinking from a cup of coffee.",
        "vid": "HUWAZ",
        "timestamps": [
            2.0,
            10.3
        ]
    },
    "HUWAZ_1": {
        "text": "the person is drinking something from a cup.",
        "vid": "HUWAZ",
        "timestamps": [
            2.0,
            10.3
        ]
    },
    "SANRG_0": {
        "text": "person throws the towel onto the floor.",
        "vid": "SANRG",
        "timestamps": [
            13.3,
            21.2
        ]
    },
    "8NEYJ_0": {
        "text": "a person opens a door.",
        "vid": "8NEYJ",
        "timestamps": [
            3.5,
            9.0
        ]
    },
    "8NEYJ_1": {
        "text": "person stopping to look out a window.",
        "vid": "8NEYJ",
        "timestamps": [
            19.7,
            32.0
        ]
    },
    "8NEYJ_2": {
        "text": "person looks out of the window.",
        "vid": "8NEYJ",
        "timestamps": [
            19.7,
            32.0
        ]
    },
    "8NEYJ_3": {
        "text": "person seeing the door open.",
        "vid": "8NEYJ",
        "timestamps": [
            3.5,
            9.0
        ]
    },
    "BYP85_0": {
        "text": "person put them on the shelf.",
        "vid": "BYP85",
        "timestamps": [
            24.8,
            29.7
        ]
    },
    "BYP85_1": {
        "text": "person puts items onto a shelf.",
        "vid": "BYP85",
        "timestamps": [
            24.8,
            29.7
        ]
    },
    "BYP85_2": {
        "text": "person they tidy up a shelf in front of them.",
        "vid": "BYP85",
        "timestamps": [
            21.8,
            29.8
        ]
    },
    "Y44TV_0": {
        "text": "one person takes a pillow.",
        "vid": "Y44TV",
        "timestamps": [
            8.9,
            20.3
        ]
    },
    "31YNM_0": {
        "text": "the person drinks from a cup from the side table.",
        "vid": "31YNM",
        "timestamps": [
            11.7,
            24.4
        ]
    },
    "31YNM_1": {
        "text": "a person fixing a light.",
        "vid": "31YNM",
        "timestamps": [
            0.0,
            15.1
        ]
    },
    "31YNM_2": {
        "text": "person drinks from a cup.",
        "vid": "31YNM",
        "timestamps": [
            11.7,
            24.4
        ]
    },
    "DWH0T_0": {
        "text": "person start pouring themselves a glass of water.",
        "vid": "DWH0T",
        "timestamps": [
            22.4,
            32.9
        ]
    },
    "DWH0T_1": {
        "text": "person pours themselves a cup of water.",
        "vid": "DWH0T",
        "timestamps": [
            22.4,
            32.9
        ]
    },
    "MJYTA_0": {
        "text": "the person puts the bowls on the table.",
        "vid": "MJYTA",
        "timestamps": [
            8.6,
            14.9
        ]
    },
    "1KC11_0": {
        "text": "person also watching something on their laptop.",
        "vid": "1KC11",
        "timestamps": [
            2.7,
            8.9
        ]
    },
    "1KC11_1": {
        "text": "person they are watching something on their television.",
        "vid": "1KC11",
        "timestamps": [
            4.1,
            8.9
        ]
    },
    "T5SI3_0": {
        "text": "a person is laughing at a book.",
        "vid": "T5SI3",
        "timestamps": [
            1.6,
            6.6
        ]
    },
    "T5SI3_1": {
        "text": "person starts to close the box.",
        "vid": "T5SI3",
        "timestamps": [
            9.3,
            15.0
        ]
    },
    "T5SI3_2": {
        "text": "person put the paper in a box.",
        "vid": "T5SI3",
        "timestamps": [
            6.1,
            12.9
        ]
    },
    "O3Y57_0": {
        "text": "person closed the door.",
        "vid": "O3Y57",
        "timestamps": [
            2.3,
            9.0
        ]
    },
    "O3Y57_1": {
        "text": "person they begin sneezing several times in succession.",
        "vid": "O3Y57",
        "timestamps": [
            23.7,
            31.0
        ]
    },
    "O3Y57_2": {
        "text": "person they put the bag over their head.",
        "vid": "O3Y57",
        "timestamps": [
            6.2,
            13.1
        ]
    },
    "O3Y57_3": {
        "text": "person closing the door to the room.",
        "vid": "O3Y57",
        "timestamps": [
            2.3,
            9.0
        ]
    },
    "LR9KL_0": {
        "text": "a person runs laughing through the hall with a pillow.",
        "vid": "LR9KL",
        "timestamps": [
            12.2,
            20.1
        ]
    },
    "I52A6_0": {
        "text": "a person drinks a glass of water.",
        "vid": "I52A6",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "I52A6_1": {
        "text": "a person is drinking glass of water in laundry room.",
        "vid": "I52A6",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "I52A6_2": {
        "text": "person opens the dryer door.",
        "vid": "I52A6",
        "timestamps": [
            30.3,
            35.8
        ]
    },
    "1VF27_0": {
        "text": "person they start eating some food.",
        "vid": "1VF27",
        "timestamps": [
            11.0,
            18.0
        ]
    },
    "PJDUN_0": {
        "text": "person takes a book off a shelf.",
        "vid": "PJDUN",
        "timestamps": [
            7.9,
            14.6
        ]
    },
    "H411A_0": {
        "text": "person puts it in a box.",
        "vid": "H411A",
        "timestamps": [
            8.7,
            14.7
        ]
    },
    "H411A_1": {
        "text": "person put a pillow in a box close the box.",
        "vid": "H411A",
        "timestamps": [
            6.5,
            11.3
        ]
    },
    "H411A_2": {
        "text": "a person puts a pillow into a box.",
        "vid": "H411A",
        "timestamps": [
            6.5,
            11.3
        ]
    },
    "UQJ5W_0": {
        "text": "person walks into shower opens the window.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "UQJ5W_1": {
        "text": "person opens the window.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "UQJ5W_2": {
        "text": "person takes a picture of something outside.",
        "vid": "UQJ5W",
        "timestamps": [
            17.7,
            28.0
        ]
    },
    "UQJ5W_3": {
        "text": "person takes a cell phone photo through the open window.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "UQJ5W_4": {
        "text": "person eating a sandwich.",
        "vid": "UQJ5W",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "UQJ5W_5": {
        "text": "person proceeds to take a picture out of the window.",
        "vid": "UQJ5W",
        "timestamps": [
            17.7,
            28.0
        ]
    },
    "UQJ5W_6": {
        "text": "person opens the window inside the shower.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "UQJ5W_7": {
        "text": "person opens a window.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "UQJ5W_8": {
        "text": "person take a picture through the open window.",
        "vid": "UQJ5W",
        "timestamps": [
            5.6,
            13.2
        ]
    },
    "YQOCU_0": {
        "text": "a person takes some food from a cabinet.",
        "vid": "YQOCU",
        "timestamps": [
            8.4,
            13.5
        ]
    },
    "YQOCU_1": {
        "text": "person they sit down in a chair holding it.",
        "vid": "YQOCU",
        "timestamps": [
            23.1,
            32.0
        ]
    },
    "YQOCU_2": {
        "text": "a laughing person walks into the kitchen opens a cabinet.",
        "vid": "YQOCU",
        "timestamps": [
            5.7,
            11.7
        ]
    },
    "DR7K0_0": {
        "text": "person begin to dress themselves.",
        "vid": "DR7K0",
        "timestamps": [
            17.3,
            32.0
        ]
    },
    "DR7K0_1": {
        "text": "person they are  dressing themselves in a wardrobe closet.",
        "vid": "DR7K0",
        "timestamps": [
            17.3,
            32.0
        ]
    },
    "DR7K0_2": {
        "text": "a person is seen smiling.",
        "vid": "DR7K0",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "3YQE2_0": {
        "text": "person turn off the light.",
        "vid": "3YQE2",
        "timestamps": [
            24.7,
            31.0
        ]
    },
    "3YQE2_1": {
        "text": "person starts sneezing.",
        "vid": "3YQE2",
        "timestamps": [
            17.8,
            29.6
        ]
    },
    "3YQE2_2": {
        "text": "person turns off the lights.",
        "vid": "3YQE2",
        "timestamps": [
            24.7,
            31.0
        ]
    },
    "AHBE8_0": {
        "text": "person they close the box.",
        "vid": "AHBE8",
        "timestamps": [
            18.1,
            23.5
        ]
    },
    "AHBE8_1": {
        "text": "person puts shoes in pizza.",
        "vid": "AHBE8",
        "timestamps": [
            12.3,
            22.8
        ]
    },
    "AHBE8_2": {
        "text": "next the person puts the box aside.",
        "vid": "AHBE8",
        "timestamps": [
            21.8,
            26.8
        ]
    },
    "AHBE8_3": {
        "text": "person starts laughing.",
        "vid": "AHBE8",
        "timestamps": [
            21.0,
            29.0
        ]
    },
    "AHBE8_4": {
        "text": "a person opens a box.",
        "vid": "AHBE8",
        "timestamps": [
            12.7,
            17.8
        ]
    },
    "AHBE8_5": {
        "text": "person puts in some shoes.",
        "vid": "AHBE8",
        "timestamps": [
            12.3,
            22.8
        ]
    },
    "AHBE8_6": {
        "text": "person is laughing.",
        "vid": "AHBE8",
        "timestamps": [
            21.0,
            29.0
        ]
    },
    "YE47Y_0": {
        "text": "a person is sitting on the couch with a pillow.",
        "vid": "YE47Y",
        "timestamps": [
            0.0,
            14.8
        ]
    },
    "YE47Y_1": {
        "text": "a person snuggles up with a blanket on the couch.",
        "vid": "YE47Y",
        "timestamps": [
            0.0,
            12.3
        ]
    },
    "YE47Y_2": {
        "text": "a person sits on the couch holding a pillow.",
        "vid": "YE47Y",
        "timestamps": [
            0.0,
            14.8
        ]
    },
    "YE47Y_3": {
        "text": "person someone is sitting on their couch with a blanket.",
        "vid": "YE47Y",
        "timestamps": [
            0.0,
            14.8
        ]
    },
    "WM6RQ_0": {
        "text": "the person closes the refrigerator.",
        "vid": "WM6RQ",
        "timestamps": [
            12.6,
            18.0
        ]
    },
    "WM6RQ_1": {
        "text": "person open the refrigerator door.",
        "vid": "WM6RQ",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "WM6RQ_2": {
        "text": "person take food.",
        "vid": "WM6RQ",
        "timestamps": [
            11.3,
            16.8
        ]
    },
    "RV5CK_0": {
        "text": "person turn off the light.",
        "vid": "RV5CK",
        "timestamps": [
            27.1,
            34.0
        ]
    },
    "RV5CK_1": {
        "text": "person trying to turn off the light.",
        "vid": "RV5CK",
        "timestamps": [
            27.1,
            34.0
        ]
    },
    "RV5CK_2": {
        "text": "person shuts off the lights.",
        "vid": "RV5CK",
        "timestamps": [
            27.1,
            34.0
        ]
    },
    "PIJRH_0": {
        "text": "person holding a bag.",
        "vid": "PIJRH",
        "timestamps": [
            0.0,
            12.9
        ]
    },
    "PIJRH_1": {
        "text": "person they take a pillow out of the bag.",
        "vid": "PIJRH",
        "timestamps": [
            6.9,
            12.7
        ]
    },
    "PIJRH_2": {
        "text": "person takes a pillow out of a bag.",
        "vid": "PIJRH",
        "timestamps": [
            6.9,
            12.7
        ]
    },
    "ZJ37U_0": {
        "text": "person turns off light.",
        "vid": "ZJ37U",
        "timestamps": [
            2.5,
            7.0
        ]
    },
    "ZJ37U_1": {
        "text": "person eating sandwich.",
        "vid": "ZJ37U",
        "timestamps": [
            0.0,
            12.2
        ]
    },
    "ZJ37U_2": {
        "text": "person turns off a light.",
        "vid": "ZJ37U",
        "timestamps": [
            2.5,
            7.0
        ]
    },
    "ZJ37U_3": {
        "text": "the person turns off the light in the hallway.",
        "vid": "ZJ37U",
        "timestamps": [
            2.5,
            7.0
        ]
    },
    "PAA7V_0": {
        "text": "person puts the dish into a box on the floor.",
        "vid": "PAA7V",
        "timestamps": [
            16.6,
            23.9
        ]
    },
    "PAA7V_1": {
        "text": "the person takes a toy out of the box.",
        "vid": "PAA7V",
        "timestamps": [
            20.0,
            25.0
        ]
    },
    "IAHN3_0": {
        "text": "person smiling together at the same time.",
        "vid": "IAHN3",
        "timestamps": [
            1.0,
            8.9
        ]
    },
    "IAHN3_1": {
        "text": "person the other takes a picture with their camera.",
        "vid": "IAHN3",
        "timestamps": [
            7.4,
            16.0
        ]
    },
    "PDH7G_0": {
        "text": "person puts a bag down on the counter.",
        "vid": "PDH7G",
        "timestamps": [
            4.9,
            10.1
        ]
    },
    "07QNG_0": {
        "text": "person pour a cup of juice.",
        "vid": "07QNG",
        "timestamps": [
            29.4,
            36.7
        ]
    },
    "07QNG_1": {
        "text": "the person is also watching television.",
        "vid": "07QNG",
        "timestamps": [
            9.6,
            19.9
        ]
    },
    "07QNG_2": {
        "text": "person they stop to pour some water in a glass.",
        "vid": "07QNG",
        "timestamps": [
            29.4,
            36.7
        ]
    },
    "OK45U_0": {
        "text": "the person throws their clothes onto the shelf.",
        "vid": "OK45U",
        "timestamps": [
            17.2,
            22.9
        ]
    },
    "OK45U_1": {
        "text": "a person is undressing in the garage.",
        "vid": "OK45U",
        "timestamps": [
            9.0,
            19.7
        ]
    },
    "28BVI_0": {
        "text": "person puts down the glass.",
        "vid": "28BVI",
        "timestamps": [
            36.2,
            42.4
        ]
    },
    "28BVI_1": {
        "text": "person eats some food.",
        "vid": "28BVI",
        "timestamps": [
            19.0,
            34.2
        ]
    },
    "28BVI_2": {
        "text": "person holding a glass of water.",
        "vid": "28BVI",
        "timestamps": [
            36.7,
            43.1
        ]
    },
    "28BVI_3": {
        "text": "person eats something.",
        "vid": "28BVI",
        "timestamps": [
            19.0,
            34.2
        ]
    },
    "28BVI_4": {
        "text": "the person began tidying the kitchen table.",
        "vid": "28BVI",
        "timestamps": [
            35.6,
            44.0
        ]
    },
    "28BVI_5": {
        "text": "person drinks out of a glass.",
        "vid": "28BVI",
        "timestamps": [
            25.0,
            34.4
        ]
    },
    "28BVI_6": {
        "text": "a person is undressing in their kitchen.",
        "vid": "28BVI",
        "timestamps": [
            2.8,
            15.4
        ]
    },
    "28BVI_7": {
        "text": "a person standing in a kitchen takes off a sweatshirt.",
        "vid": "28BVI",
        "timestamps": [
            19.0,
            34.2
        ]
    },
    "28BVI_8": {
        "text": "person they eat a plate of food.",
        "vid": "28BVI",
        "timestamps": [
            19.0,
            34.2
        ]
    },
    "HAPCT_0": {
        "text": "person continues to laugh.",
        "vid": "HAPCT",
        "timestamps": [
            5.8,
            19.1
        ]
    },
    "HAPCT_1": {
        "text": "person laughs at the television program.",
        "vid": "HAPCT",
        "timestamps": [
            5.8,
            19.1
        ]
    },
    "HAPCT_2": {
        "text": "person takes their shoes off.",
        "vid": "HAPCT",
        "timestamps": [
            8.6,
            16.0
        ]
    },
    "HAPCT_3": {
        "text": "person starts laughing.",
        "vid": "HAPCT",
        "timestamps": [
            5.8,
            19.1
        ]
    },
    "U5RYN_0": {
        "text": "a young person turns on the lights.",
        "vid": "U5RYN",
        "timestamps": [
            0.0,
            2.8
        ]
    },
    "U5RYN_1": {
        "text": "person turns on the light.",
        "vid": "U5RYN",
        "timestamps": [
            0.0,
            2.8
        ]
    },
    "U5RYN_2": {
        "text": "person they are smiling.",
        "vid": "U5RYN",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "DUZDL_0": {
        "text": "person throws off their blanket.",
        "vid": "DUZDL",
        "timestamps": [
            1.4,
            6.4
        ]
    },
    "DUZDL_1": {
        "text": "person opens closet door.",
        "vid": "DUZDL",
        "timestamps": [
            6.5,
            12.9
        ]
    },
    "DUZDL_2": {
        "text": "person after awakening.",
        "vid": "DUZDL",
        "timestamps": [
            2.6,
            8.4
        ]
    },
    "DUZDL_3": {
        "text": "person opens the doors.",
        "vid": "DUZDL",
        "timestamps": [
            6.5,
            11.9
        ]
    },
    "580G0_0": {
        "text": "person put on their shoes.",
        "vid": "580G0",
        "timestamps": [
            14.8,
            22.0
        ]
    },
    "580G0_1": {
        "text": "person drinks from a cup.",
        "vid": "580G0",
        "timestamps": [
            6.6,
            14.7
        ]
    },
    "580G0_2": {
        "text": "person puts on a pair of shoes.",
        "vid": "580G0",
        "timestamps": [
            14.8,
            22.0
        ]
    },
    "580G0_3": {
        "text": "person puts their shoes on.",
        "vid": "580G0",
        "timestamps": [
            14.8,
            22.0
        ]
    },
    "580G0_4": {
        "text": "person drink some water with the glass.",
        "vid": "580G0",
        "timestamps": [
            6.6,
            14.7
        ]
    },
    "580G0_5": {
        "text": "a person awakens in bed.",
        "vid": "580G0",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "S2S7I_0": {
        "text": "person puts a plastic bag on the table.",
        "vid": "S2S7I",
        "timestamps": [
            2.2,
            10.1
        ]
    },
    "S2S7I_1": {
        "text": "person puts a bag of groceries down on the table.",
        "vid": "S2S7I",
        "timestamps": [
            5.2,
            9.9
        ]
    },
    "JP5NM_0": {
        "text": "a person is standing in an entryway undressing.",
        "vid": "JP5NM",
        "timestamps": [
            0.5,
            9.5
        ]
    },
    "JP5NM_1": {
        "text": "the person takes a blanket from the couch.",
        "vid": "JP5NM",
        "timestamps": [
            6.2,
            14.2
        ]
    },
    "LQC89_0": {
        "text": "person eating from a plate.",
        "vid": "LQC89",
        "timestamps": [
            12.4,
            20.0
        ]
    },
    "J662Y_0": {
        "text": "a person finishes eating some food off a small plate.",
        "vid": "J662Y",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "J662Y_1": {
        "text": "person eats from a bowl.",
        "vid": "J662Y",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "J662Y_2": {
        "text": "a person sits on a chair.",
        "vid": "J662Y",
        "timestamps": [
            0.0,
            9.2
        ]
    },
    "DD3Q1_0": {
        "text": "person sitting on the couch.",
        "vid": "DD3Q1",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "ARWNX_0": {
        "text": "a person is in the kitchen putting a box down.",
        "vid": "ARWNX",
        "timestamps": [
            5.2,
            11.5
        ]
    },
    "6XB10_0": {
        "text": "person walk out the doorway.",
        "vid": "6XB10",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "6XB10_1": {
        "text": "person they begin sneezing.",
        "vid": "6XB10",
        "timestamps": [
            26.9,
            36.5
        ]
    },
    "6XB10_2": {
        "text": "a person walks through a doorway into a room.",
        "vid": "6XB10",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "F66WG_0": {
        "text": "person began to eat something in hand.",
        "vid": "F66WG",
        "timestamps": [
            18.7,
            30.3
        ]
    },
    "F66WG_1": {
        "text": "person holding a camera in the bathroom.",
        "vid": "F66WG",
        "timestamps": [
            9.0,
            19.0
        ]
    },
    "F66WG_2": {
        "text": "a person opens a door.",
        "vid": "F66WG",
        "timestamps": [
            4.5,
            11.9
        ]
    },
    "F66WG_3": {
        "text": "person eats in a doorway.",
        "vid": "F66WG",
        "timestamps": [
            18.7,
            30.3
        ]
    },
    "F66WG_4": {
        "text": "a person holding shoes enters a bathroom.",
        "vid": "F66WG",
        "timestamps": [
            1.0,
            14.0
        ]
    },
    "F66WG_5": {
        "text": "a person eats.",
        "vid": "F66WG",
        "timestamps": [
            18.7,
            30.3
        ]
    },
    "F66WG_6": {
        "text": "person stand in the doorway eating something.",
        "vid": "F66WG",
        "timestamps": [
            18.7,
            30.3
        ]
    },
    "F66WG_7": {
        "text": "person they put their shoes on the ground.",
        "vid": "F66WG",
        "timestamps": [
            8.6,
            14.8
        ]
    },
    "F66WG_8": {
        "text": "person goes into the bathroom put shoes on the floor.",
        "vid": "F66WG",
        "timestamps": [
            8.6,
            14.8
        ]
    },
    "CIUVA_0": {
        "text": "the person puts a dish into the strainer.",
        "vid": "CIUVA",
        "timestamps": [
            52.1,
            55.0
        ]
    },
    "CIUVA_1": {
        "text": "person opened the refrigerator.",
        "vid": "CIUVA",
        "timestamps": [
            46.5,
            55.0
        ]
    },
    "ATCOR_0": {
        "text": "person turning off the light.",
        "vid": "ATCOR",
        "timestamps": [
            19.7,
            25.8
        ]
    },
    "ATCOR_1": {
        "text": "person gets up to turn off the light.",
        "vid": "ATCOR",
        "timestamps": [
            19.7,
            25.8
        ]
    },
    "9KDP0_0": {
        "text": "person puts down the laptop.",
        "vid": "9KDP0",
        "timestamps": [
            22.9,
            31.0
        ]
    },
    "9KDP0_1": {
        "text": "a person runs into the laundry room.",
        "vid": "9KDP0",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "9KDP0_2": {
        "text": "person looks at the book.",
        "vid": "9KDP0",
        "timestamps": [
            4.5,
            18.3
        ]
    },
    "V26U3_0": {
        "text": "person throws a pillow at the refrigerator.",
        "vid": "V26U3",
        "timestamps": [
            5.1,
            10.6
        ]
    },
    "V26U3_1": {
        "text": "a person is throwing a pillow at the refrigerator.",
        "vid": "V26U3",
        "timestamps": [
            5.1,
            10.6
        ]
    },
    "V26U3_2": {
        "text": "person throws a pillow at a refrigerator.",
        "vid": "V26U3",
        "timestamps": [
            5.1,
            10.6
        ]
    },
    "NKLTK_0": {
        "text": "person run to a window.",
        "vid": "NKLTK",
        "timestamps": [
            15.4,
            26.2
        ]
    },
    "NKLTK_1": {
        "text": "person runs over to a window.",
        "vid": "NKLTK",
        "timestamps": [
            15.4,
            26.2
        ]
    },
    "NKLTK_2": {
        "text": "a person awakens in a chair.",
        "vid": "NKLTK",
        "timestamps": [
            7.4,
            19.7
        ]
    },
    "NKLTK_3": {
        "text": "the person runs over to the window.",
        "vid": "NKLTK",
        "timestamps": [
            15.4,
            26.2
        ]
    },
    "PLJIZ_0": {
        "text": "person opens the door.",
        "vid": "PLJIZ",
        "timestamps": [
            3.2,
            13.4
        ]
    },
    "UOZES_0": {
        "text": "person looking out the window.",
        "vid": "UOZES",
        "timestamps": [
            31.2,
            37.0
        ]
    },
    "UOZES_1": {
        "text": "a person awakens.",
        "vid": "UOZES",
        "timestamps": [
            13.3,
            25.7
        ]
    },
    "UOZES_2": {
        "text": "the person laughs.",
        "vid": "UOZES",
        "timestamps": [
            26.3,
            32.3
        ]
    },
    "UOZES_3": {
        "text": "person closes their laptop.",
        "vid": "UOZES",
        "timestamps": [
            28.3,
            35.6
        ]
    },
    "UOZES_4": {
        "text": "person looks out the window.",
        "vid": "UOZES",
        "timestamps": [
            31.2,
            37.0
        ]
    },
    "LLRKS_0": {
        "text": "a person pours a cup of coffee.",
        "vid": "LLRKS",
        "timestamps": [
            0.5,
            9.2
        ]
    },
    "PAS7F_0": {
        "text": "person sits down on the couch.",
        "vid": "PAS7F",
        "timestamps": [
            15.9,
            22.6
        ]
    },
    "WISO0_0": {
        "text": "as the person was sneezing.",
        "vid": "WISO0",
        "timestamps": [
            1.9,
            8.6
        ]
    },
    "GOPZI_0": {
        "text": "a smiling person is putting a laptop in a bag.",
        "vid": "GOPZI",
        "timestamps": [
            28.5,
            33.0
        ]
    },
    "GOPZI_1": {
        "text": "person start laughing.",
        "vid": "GOPZI",
        "timestamps": [
            27.1,
            33.0
        ]
    },
    "EHIOY_0": {
        "text": "person eats a sandwich.",
        "vid": "EHIOY",
        "timestamps": [
            21.8,
            36.0
        ]
    },
    "EHIOY_1": {
        "text": "person eats a plate of food.",
        "vid": "EHIOY",
        "timestamps": [
            21.8,
            36.0
        ]
    },
    "EHIOY_2": {
        "text": "person start eating.",
        "vid": "EHIOY",
        "timestamps": [
            21.8,
            36.0
        ]
    },
    "8LVCL_0": {
        "text": "a person is undressing in the closet.",
        "vid": "8LVCL",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "TIWRY_0": {
        "text": "person they wash the glass.",
        "vid": "TIWRY",
        "timestamps": [
            18.2,
            27.0
        ]
    },
    "TIWRY_1": {
        "text": "person begins to wash dishes.",
        "vid": "TIWRY",
        "timestamps": [
            20.0,
            27.0
        ]
    },
    "WK9HE_0": {
        "text": "person play a game on their phone.",
        "vid": "WK9HE",
        "timestamps": [
            28.7,
            35.0
        ]
    },
    "Y8L60_0": {
        "text": "a person opens a small cabinet door.",
        "vid": "Y8L60",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "OU3XH_0": {
        "text": "person eating some food.",
        "vid": "OU3XH",
        "timestamps": [
            19.2,
            24.5
        ]
    },
    "OU3XH_1": {
        "text": "person takes a bite of food.",
        "vid": "OU3XH",
        "timestamps": [
            16.6,
            25.6
        ]
    },
    "OU3XH_2": {
        "text": "the person puts the camera down.",
        "vid": "OU3XH",
        "timestamps": [
            14.0,
            18.7
        ]
    },
    "OU3XH_3": {
        "text": "person eats some food off a plate.",
        "vid": "OU3XH",
        "timestamps": [
            19.2,
            24.5
        ]
    },
    "8N4O9_0": {
        "text": "person leaves the closet with the door still open.",
        "vid": "8N4O9",
        "timestamps": [
            1.4,
            7.4
        ]
    },
    "8N4O9_1": {
        "text": "person opens the door.",
        "vid": "8N4O9",
        "timestamps": [
            1.4,
            7.4
        ]
    },
    "8N4O9_2": {
        "text": "person takes some towels out.",
        "vid": "8N4O9",
        "timestamps": [
            11.3,
            17.7
        ]
    },
    "8N4O9_3": {
        "text": "person turns on the light.",
        "vid": "8N4O9",
        "timestamps": [
            6.3,
            10.8
        ]
    },
    "8N4O9_4": {
        "text": "person turns off the light.",
        "vid": "8N4O9",
        "timestamps": [
            19.5,
            23.0
        ]
    },
    "8N4O9_5": {
        "text": "the person opens the cabinet door.",
        "vid": "8N4O9",
        "timestamps": [
            1.4,
            7.4
        ]
    },
    "8N4O9_6": {
        "text": "person turns the light off.",
        "vid": "8N4O9",
        "timestamps": [
            19.5,
            23.0
        ]
    },
    "8N4O9_7": {
        "text": "a person turns on a light.",
        "vid": "8N4O9",
        "timestamps": [
            6.3,
            10.8
        ]
    },
    "8N4O9_8": {
        "text": "person turning on the light.",
        "vid": "8N4O9",
        "timestamps": [
            6.3,
            10.8
        ]
    },
    "8N4O9_9": {
        "text": "person opens a door.",
        "vid": "8N4O9",
        "timestamps": [
            1.4,
            7.4
        ]
    },
    "83FK5_0": {
        "text": "a person is snuggling with a pillow.",
        "vid": "83FK5",
        "timestamps": [
            0.0,
            19.3
        ]
    },
    "LBJ0W_0": {
        "text": "a person sitting on a bed takes off their shoes.",
        "vid": "LBJ0W",
        "timestamps": [
            0.0,
            14.1
        ]
    },
    "LBJ0W_1": {
        "text": "a person throws their shoes by their desk.",
        "vid": "LBJ0W",
        "timestamps": [
            9.4,
            14.1
        ]
    },
    "35ZZP_0": {
        "text": "the person puts the food on the table.",
        "vid": "35ZZP",
        "timestamps": [
            6.7,
            12.4
        ]
    },
    "77JGY_0": {
        "text": "person they stand up.",
        "vid": "77JGY",
        "timestamps": [
            19.1,
            24.6
        ]
    },
    "77JGY_1": {
        "text": "person eats some food.",
        "vid": "77JGY",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "77JGY_2": {
        "text": "person puts the sandwich down.",
        "vid": "77JGY",
        "timestamps": [
            11.4,
            22.0
        ]
    },
    "77JGY_3": {
        "text": "a person is eating a sandwich over their laptop.",
        "vid": "77JGY",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "77JGY_4": {
        "text": "person take a picture of themself.",
        "vid": "77JGY",
        "timestamps": [
            22.2,
            32.0
        ]
    },
    "77JGY_5": {
        "text": "the person puts the food down on the table.",
        "vid": "77JGY",
        "timestamps": [
            17.8,
            22.8
        ]
    },
    "77JGY_6": {
        "text": "the person is sitting at a desk eating a sandwich.",
        "vid": "77JGY",
        "timestamps": [
            0.0,
            13.9
        ]
    },
    "Z9RED_0": {
        "text": "a person walks through a bathroom doorway.",
        "vid": "Z9RED",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "G6K7T_0": {
        "text": "person starts washing clothes.",
        "vid": "G6K7T",
        "timestamps": [
            19.3,
            37.5
        ]
    },
    "J1MMG_0": {
        "text": "person they stand up.",
        "vid": "J1MMG",
        "timestamps": [
            20.9,
            29.4
        ]
    },
    "J1MMG_1": {
        "text": "person put it back on the shelf.",
        "vid": "J1MMG",
        "timestamps": [
            30.5,
            36.0
        ]
    },
    "2XXH8_0": {
        "text": "person probably washes hands.",
        "vid": "2XXH8",
        "timestamps": [
            10.8,
            25.0
        ]
    },
    "G3UF4_0": {
        "text": "a person opens a book.",
        "vid": "G3UF4",
        "timestamps": [
            3.2,
            8.4
        ]
    },
    "MZZ8Q_0": {
        "text": "a person puts something on a shelf.",
        "vid": "MZZ8Q",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "MZZ8Q_1": {
        "text": "person takes off his shoes.",
        "vid": "MZZ8Q",
        "timestamps": [
            3.8,
            10.9
        ]
    },
    "MZZ8Q_2": {
        "text": "person throws a pair of shoes toward a sofa.",
        "vid": "MZZ8Q",
        "timestamps": [
            9.7,
            16.7
        ]
    },
    "MZZ8Q_3": {
        "text": "person takes off their shoes.",
        "vid": "MZZ8Q",
        "timestamps": [
            3.8,
            10.9
        ]
    },
    "KF08J_0": {
        "text": "person sneezing multiple times.",
        "vid": "KF08J",
        "timestamps": [
            3.3,
            10.4
        ]
    },
    "KF08J_1": {
        "text": "person starts sneezing profusely.",
        "vid": "KF08J",
        "timestamps": [
            3.3,
            10.4
        ]
    },
    "3J85M_0": {
        "text": "person eat them.",
        "vid": "3J85M",
        "timestamps": [
            19.3,
            28.8
        ]
    },
    "3J85M_1": {
        "text": "person eat the food.",
        "vid": "3J85M",
        "timestamps": [
            19.3,
            28.8
        ]
    },
    "3J85M_2": {
        "text": "person next eating a sandwich in the pantry.",
        "vid": "3J85M",
        "timestamps": [
            19.5,
            27.6
        ]
    },
    "3J85M_3": {
        "text": "person eating  the snack.",
        "vid": "3J85M",
        "timestamps": [
            19.3,
            28.8
        ]
    },
    "3J85M_4": {
        "text": "person take out some food.",
        "vid": "3J85M",
        "timestamps": [
            7.2,
            15.3
        ]
    },
    "GKBSR_0": {
        "text": "person opens the door.",
        "vid": "GKBSR",
        "timestamps": [
            0.0,
            2.7
        ]
    },
    "Q5YDL_0": {
        "text": "person playing a game on a laptop.",
        "vid": "Q5YDL",
        "timestamps": [
            0.0,
            16.5
        ]
    },
    "Q5YDL_1": {
        "text": "this person eats from a bowl.",
        "vid": "Q5YDL",
        "timestamps": [
            20.1,
            37.3
        ]
    },
    "Q5YDL_2": {
        "text": "person start eating potato chips.",
        "vid": "Q5YDL",
        "timestamps": [
            20.1,
            37.3
        ]
    },
    "RT1JY_0": {
        "text": "person sits on the bed.",
        "vid": "RT1JY",
        "timestamps": [
            11.4,
            15.8
        ]
    },
    "RT1JY_1": {
        "text": "person sit on a bed.",
        "vid": "RT1JY",
        "timestamps": [
            11.4,
            15.8
        ]
    },
    "RT1JY_2": {
        "text": "a person is in a bedroom undressing by the doorway.",
        "vid": "RT1JY",
        "timestamps": [
            3.3,
            8.7
        ]
    },
    "U0P7W_0": {
        "text": "person puts the picture inside.",
        "vid": "U0P7W",
        "timestamps": [
            22.0,
            29.7
        ]
    },
    "U0P7W_1": {
        "text": "person opens the cabinet.",
        "vid": "U0P7W",
        "timestamps": [
            18.8,
            24.9
        ]
    },
    "U0P7W_2": {
        "text": "the person opens a cabinet.",
        "vid": "U0P7W",
        "timestamps": [
            18.8,
            24.9
        ]
    },
    "9TPP3_0": {
        "text": "person drinking a cup of coffee.",
        "vid": "9TPP3",
        "timestamps": [
            0.0,
            8.4
        ]
    },
    "TBEV0_0": {
        "text": "a person is undressing.",
        "vid": "TBEV0",
        "timestamps": [
            0.0,
            9.6
        ]
    },
    "TBEV0_1": {
        "text": "person snuggle with a pillow.",
        "vid": "TBEV0",
        "timestamps": [
            16.3,
            31.0
        ]
    },
    "QLGHA_0": {
        "text": "a smiling person is putting a broom in the pantry.",
        "vid": "QLGHA",
        "timestamps": [
            3.3,
            10.0
        ]
    },
    "4KYZH_0": {
        "text": "person continuing to eat.",
        "vid": "4KYZH",
        "timestamps": [
            9.4,
            14.8
        ]
    },
    "4KYZH_1": {
        "text": "person starts to eat it.",
        "vid": "4KYZH",
        "timestamps": [
            9.4,
            14.8
        ]
    },
    "4KYZH_2": {
        "text": "person grabs something to eat.",
        "vid": "4KYZH",
        "timestamps": [
            9.4,
            14.8
        ]
    },
    "4KYZH_3": {
        "text": "a person opens a refrigerator.",
        "vid": "4KYZH",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "TK1VC_0": {
        "text": "person sits down on the couch.",
        "vid": "TK1VC",
        "timestamps": [
            17.1,
            21.0
        ]
    },
    "TK1VC_1": {
        "text": "person starts sneezing.",
        "vid": "TK1VC",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "TK1VC_2": {
        "text": "person sits on the couch.",
        "vid": "TK1VC",
        "timestamps": [
            17.1,
            21.0
        ]
    },
    "TK1VC_3": {
        "text": "a person standing in a living room area begins sneezing.",
        "vid": "TK1VC",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "TK1VC_4": {
        "text": "the person takes a broom.",
        "vid": "TK1VC",
        "timestamps": [
            10.9,
            16.0
        ]
    },
    "TK1VC_5": {
        "text": "person take a book from it.",
        "vid": "TK1VC",
        "timestamps": [
            10.8,
            18.4
        ]
    },
    "52KNA_0": {
        "text": "the person puts the towel down.",
        "vid": "52KNA",
        "timestamps": [
            15.8,
            20.7
        ]
    },
    "SE2K2_0": {
        "text": "a person opens the door to the kitchen.",
        "vid": "SE2K2",
        "timestamps": [
            0.6,
            7.1
        ]
    },
    "SE2K2_1": {
        "text": "person sits in the floor smiling.",
        "vid": "SE2K2",
        "timestamps": [
            28.7,
            34.0
        ]
    },
    "LCLLN_0": {
        "text": "one person takes a glass from a shelf.",
        "vid": "LCLLN",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "LCLLN_1": {
        "text": "person drinking some water from a glass.",
        "vid": "LCLLN",
        "timestamps": [
            1.4,
            6.9
        ]
    },
    "LCLLN_2": {
        "text": "person takes a blanket from somewhere.",
        "vid": "LCLLN",
        "timestamps": [
            5.5,
            11.9
        ]
    },
    "RNLTR_0": {
        "text": "person throwing their clothes on the sofa.",
        "vid": "RNLTR",
        "timestamps": [
            7.3,
            13.5
        ]
    },
    "SS3IL_0": {
        "text": "the person takes out their phone.",
        "vid": "SS3IL",
        "timestamps": [
            8.4,
            13.4
        ]
    },
    "SS3IL_1": {
        "text": "person they put the dishes down.",
        "vid": "SS3IL",
        "timestamps": [
            1.8,
            9.3
        ]
    },
    "SS3IL_2": {
        "text": "person take out their phone.",
        "vid": "SS3IL",
        "timestamps": [
            8.4,
            13.4
        ]
    },
    "G6ZOB_0": {
        "text": "person closing the door to the entryway.",
        "vid": "G6ZOB",
        "timestamps": [
            7.0,
            14.9
        ]
    },
    "G6ZOB_1": {
        "text": "person turns on the light.",
        "vid": "G6ZOB",
        "timestamps": [
            13.9,
            22.4
        ]
    },
    "G6ZOB_2": {
        "text": "person turns on a light.",
        "vid": "G6ZOB",
        "timestamps": [
            13.9,
            22.4
        ]
    },
    "SRTX6_0": {
        "text": "person takes the food to the kitchen.",
        "vid": "SRTX6",
        "timestamps": [
            13.6,
            26.4
        ]
    },
    "XOWBN_0": {
        "text": "a person puts a sandwich onto a table.",
        "vid": "XOWBN",
        "timestamps": [
            6.7,
            13.6
        ]
    },
    "SOZ1G_0": {
        "text": "the person starts to stand up.",
        "vid": "SOZ1G",
        "timestamps": [
            9.0,
            13.0
        ]
    },
    "SOZ1G_1": {
        "text": "person is lying in bed undressing.",
        "vid": "SOZ1G",
        "timestamps": [
            9.0,
            13.0
        ]
    },
    "AK9PN_0": {
        "text": "person sit on the sofa.",
        "vid": "AK9PN",
        "timestamps": [
            25.2,
            32.0
        ]
    },
    "AK9PN_1": {
        "text": "the person is holding a vacuum.",
        "vid": "AK9PN",
        "timestamps": [
            0.0,
            13.3
        ]
    },
    "AK9PN_2": {
        "text": "person sits on a couch.",
        "vid": "AK9PN",
        "timestamps": [
            25.2,
            32.0
        ]
    },
    "AK9PN_3": {
        "text": "person starts sneezing 2 times.",
        "vid": "AK9PN",
        "timestamps": [
            18.3,
            27.4
        ]
    },
    "AK9PN_4": {
        "text": "person opens a closet door.",
        "vid": "AK9PN",
        "timestamps": [
            4.7,
            10.2
        ]
    },
    "J0AMJ_0": {
        "text": "the person takes a book.",
        "vid": "J0AMJ",
        "timestamps": [
            10.6,
            20.2
        ]
    },
    "J0AMJ_1": {
        "text": "the person opens a bag on the bed.",
        "vid": "J0AMJ",
        "timestamps": [
            7.9,
            18.3
        ]
    },
    "J0AMJ_2": {
        "text": "person takes a bag.",
        "vid": "J0AMJ",
        "timestamps": [
            4.0,
            8.8
        ]
    },
    "8LLI3_0": {
        "text": "person closes the cabinet door.",
        "vid": "8LLI3",
        "timestamps": [
            11.7,
            16.8
        ]
    },
    "8LLI3_1": {
        "text": "person takes a picture of food with their camera.",
        "vid": "8LLI3",
        "timestamps": [
            3.0,
            8.5
        ]
    },
    "8LLI3_2": {
        "text": "person closes the cabinets.",
        "vid": "8LLI3",
        "timestamps": [
            14.6,
            19.3
        ]
    },
    "8LLI3_3": {
        "text": "person closing the door behind them.",
        "vid": "8LLI3",
        "timestamps": [
            11.7,
            16.8
        ]
    },
    "8LLI3_4": {
        "text": "person puts it back on the shelf.",
        "vid": "8LLI3",
        "timestamps": [
            9.0,
            14.1
        ]
    },
    "CG83G_0": {
        "text": "next the person puts the blanket down on the sofa.",
        "vid": "CG83G",
        "timestamps": [
            16.5,
            22.6
        ]
    },
    "CG83G_1": {
        "text": "a person puts a blanket on a chair.",
        "vid": "CG83G",
        "timestamps": [
            16.5,
            22.6
        ]
    },
    "VFAE3_0": {
        "text": "which the person is putting onto a shelf.",
        "vid": "VFAE3",
        "timestamps": [
            35.0,
            41.0
        ]
    },
    "VFAE3_1": {
        "text": "person a girl walks past his doorway.",
        "vid": "VFAE3",
        "timestamps": [
            0.0,
            5.2
        ]
    },
    "VFAE3_2": {
        "text": "a person is closing the door.",
        "vid": "VFAE3",
        "timestamps": [
            0.6,
            7.0
        ]
    },
    "VFAE3_3": {
        "text": "person closes the door with her hand on the knob.",
        "vid": "VFAE3",
        "timestamps": [
            0.6,
            7.0
        ]
    },
    "2PZBY_0": {
        "text": "person opens the door.",
        "vid": "2PZBY",
        "timestamps": [
            0.1,
            12.1
        ]
    },
    "DFSHF_0": {
        "text": "a person puts food in the pantry.",
        "vid": "DFSHF",
        "timestamps": [
            5.5,
            12.8
        ]
    },
    "DFSHF_1": {
        "text": "person they open the door.",
        "vid": "DFSHF",
        "timestamps": [
            10.0,
            17.4
        ]
    },
    "TCJWE_0": {
        "text": "person another cooks on the kitchen counter.",
        "vid": "TCJWE",
        "timestamps": [
            0.0,
            14.9
        ]
    },
    "IULK6_0": {
        "text": "a person opens a book with a notepad in it.",
        "vid": "IULK6",
        "timestamps": [
            3.9,
            9.5
        ]
    },
    "IULK6_1": {
        "text": "person takes homework out of the book.",
        "vid": "IULK6",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "IULK6_2": {
        "text": "a person holds a book next to a chair.",
        "vid": "IULK6",
        "timestamps": [
            0.0,
            14.5
        ]
    },
    "OWUW8_0": {
        "text": "person throws it on the floor.",
        "vid": "OWUW8",
        "timestamps": [
            0.5,
            5.0
        ]
    },
    "OWUW8_1": {
        "text": "person throws it down to the floor.",
        "vid": "OWUW8",
        "timestamps": [
            0.5,
            5.0
        ]
    },
    "OWUW8_2": {
        "text": "person holds another towel.",
        "vid": "OWUW8",
        "timestamps": [
            0.0,
            3.9
        ]
    },
    "7RA0M_0": {
        "text": "person holding a laptop.",
        "vid": "7RA0M",
        "timestamps": [
            0.0,
            10.7
        ]
    },
    "CUQYX_0": {
        "text": "person they take off their shoes.",
        "vid": "CUQYX",
        "timestamps": [
            4.7,
            17.8
        ]
    },
    "CUQYX_1": {
        "text": "person they put their shoes in a bag.",
        "vid": "CUQYX",
        "timestamps": [
            24.3,
            30.0
        ]
    },
    "CUQYX_2": {
        "text": "person throw the bag against the wall softly.",
        "vid": "CUQYX",
        "timestamps": [
            23.4,
            32.0
        ]
    },
    "CUQYX_3": {
        "text": "person throw the bag.",
        "vid": "CUQYX",
        "timestamps": [
            23.4,
            32.0
        ]
    },
    "CUQYX_4": {
        "text": "person put them in a bag.",
        "vid": "CUQYX",
        "timestamps": [
            24.3,
            30.0
        ]
    },
    "CUQYX_5": {
        "text": "person take off their shoes.",
        "vid": "CUQYX",
        "timestamps": [
            4.7,
            17.8
        ]
    },
    "FLDHS_0": {
        "text": "person are putting stuff in a box.",
        "vid": "FLDHS",
        "timestamps": [
            5.4,
            12.8
        ]
    },
    "FLDHS_1": {
        "text": "person puts it in a box.",
        "vid": "FLDHS",
        "timestamps": [
            5.4,
            12.8
        ]
    },
    "OKHVL_0": {
        "text": "person eats a sandwich.",
        "vid": "OKHVL",
        "timestamps": [
            13.2,
            18.8
        ]
    },
    "OKHVL_1": {
        "text": "person glass of soft drinks.",
        "vid": "OKHVL",
        "timestamps": [
            18.6,
            25.2
        ]
    },
    "OKHVL_2": {
        "text": "person take a bite of a sandwich.",
        "vid": "OKHVL",
        "timestamps": [
            11.2,
            17.2
        ]
    },
    "OKHVL_3": {
        "text": "person drink from the glass.",
        "vid": "OKHVL",
        "timestamps": [
            18.6,
            25.2
        ]
    },
    "J2XFQ_0": {
        "text": "person proceeds to open the refrigerator.",
        "vid": "J2XFQ",
        "timestamps": [
            16.0,
            21.5
        ]
    },
    "J2XFQ_1": {
        "text": "person eat a sandwich.",
        "vid": "J2XFQ",
        "timestamps": [
            18.7,
            30.0
        ]
    },
    "J2XFQ_2": {
        "text": "person opening the fridge door.",
        "vid": "J2XFQ",
        "timestamps": [
            16.1,
            21.8
        ]
    },
    "J2XFQ_3": {
        "text": "person opens the door.",
        "vid": "J2XFQ",
        "timestamps": [
            16.1,
            21.8
        ]
    },
    "J2XFQ_4": {
        "text": "the person takes a sandwich from the refrigerator.",
        "vid": "J2XFQ",
        "timestamps": [
            17.2,
            22.5
        ]
    },
    "J2XFQ_5": {
        "text": "person grabbing something to eat.",
        "vid": "J2XFQ",
        "timestamps": [
            19.3,
            30.0
        ]
    },
    "J2XFQ_6": {
        "text": "person open the refrigerator.",
        "vid": "J2XFQ",
        "timestamps": [
            16.0,
            21.5
        ]
    },
    "J2XFQ_7": {
        "text": "person eats it.",
        "vid": "J2XFQ",
        "timestamps": [
            19.3,
            30.0
        ]
    },
    "98W87_0": {
        "text": "person takes a sandwich from a plate.",
        "vid": "98W87",
        "timestamps": [
            10.2,
            15.4
        ]
    },
    "8Q7ZI_0": {
        "text": "a person drinks from a cup.",
        "vid": "8Q7ZI",
        "timestamps": [
            0.0,
            3.9
        ]
    },
    "1BGZ0_0": {
        "text": "person went out of the room closing the door.",
        "vid": "1BGZ0",
        "timestamps": [
            9.5,
            15.2
        ]
    },
    "1BGZ0_1": {
        "text": "person closes the door.",
        "vid": "1BGZ0",
        "timestamps": [
            9.5,
            15.2
        ]
    },
    "1BGZ0_2": {
        "text": "a person runs into their entryway holding a bag.",
        "vid": "1BGZ0",
        "timestamps": [
            0.0,
            9.2
        ]
    },
    "1BGZ0_3": {
        "text": "the person opens the door.",
        "vid": "1BGZ0",
        "timestamps": [
            4.2,
            9.4
        ]
    },
    "1BGZ0_4": {
        "text": "person shoe,ran out of the room opening the door.",
        "vid": "1BGZ0",
        "timestamps": [
            4.2,
            9.4
        ]
    },
    "1BGZ0_5": {
        "text": "a man runs in with a bag of groceries.",
        "vid": "1BGZ0",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "1BGZ0_6": {
        "text": "person they open the door.",
        "vid": "1BGZ0",
        "timestamps": [
            4.2,
            9.4
        ]
    },
    "1BGZ0_7": {
        "text": "person they run to the door.",
        "vid": "1BGZ0",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "1BGZ0_8": {
        "text": "a person is holding a bag.",
        "vid": "1BGZ0",
        "timestamps": [
            0.0,
            9.2
        ]
    },
    "YO3KO_0": {
        "text": "person opens the door to walk out.",
        "vid": "YO3KO",
        "timestamps": [
            22.3,
            30.9
        ]
    },
    "YO3KO_1": {
        "text": "person opening the door.",
        "vid": "YO3KO",
        "timestamps": [
            22.3,
            30.9
        ]
    },
    "EOUCM_0": {
        "text": "a person is holding a box.",
        "vid": "EOUCM",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "EOUCM_1": {
        "text": "person closed the box.",
        "vid": "EOUCM",
        "timestamps": [
            6.2,
            15.9
        ]
    },
    "EOUCM_2": {
        "text": "person put the mirror in the box.",
        "vid": "EOUCM",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "EOUCM_3": {
        "text": "the person puts the mirror in the box.",
        "vid": "EOUCM",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "EOUCM_4": {
        "text": "person puts the mirror in the box.",
        "vid": "EOUCM",
        "timestamps": [
            0.0,
            8.9
        ]
    },
    "W86WR_0": {
        "text": "a person sits on the living room sofa.",
        "vid": "W86WR",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "W86WR_1": {
        "text": "a person is sitting on a couch.",
        "vid": "W86WR",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "NF45F_0": {
        "text": "person turns the lights on.",
        "vid": "NF45F",
        "timestamps": [
            4.0,
            8.9
        ]
    },
    "NF45F_1": {
        "text": "person starts undressing.",
        "vid": "NF45F",
        "timestamps": [
            8.7,
            25.6
        ]
    },
    "NF45F_2": {
        "text": "person turns on the light.",
        "vid": "NF45F",
        "timestamps": [
            4.0,
            8.9
        ]
    },
    "NF45F_3": {
        "text": "a person turns in the light.",
        "vid": "NF45F",
        "timestamps": [
            4.0,
            8.9
        ]
    },
    "NF45F_4": {
        "text": "a person turns on the light.",
        "vid": "NF45F",
        "timestamps": [
            4.0,
            8.9
        ]
    },
    "2AIP4_0": {
        "text": "person takes some medicine out of the bottle.",
        "vid": "2AIP4",
        "timestamps": [
            25.8,
            36.3
        ]
    },
    "2AIP4_1": {
        "text": "person go turn off the light.",
        "vid": "2AIP4",
        "timestamps": [
            36.3,
            46.0
        ]
    },
    "2AIP4_2": {
        "text": "person takes pills out of a bottle.",
        "vid": "2AIP4",
        "timestamps": [
            2.0,
            6.3
        ]
    },
    "2AIP4_3": {
        "text": "the person pours themselves a glass of water.",
        "vid": "2AIP4",
        "timestamps": [
            6.5,
            17.2
        ]
    },
    "3MX8V_0": {
        "text": "a person is throwing a blanket.",
        "vid": "3MX8V",
        "timestamps": [
            8.7,
            17.6
        ]
    },
    "3MX8V_1": {
        "text": "person putting the blanket on a shelf.",
        "vid": "3MX8V",
        "timestamps": [
            4.0,
            14.3
        ]
    },
    "3MX8V_2": {
        "text": "the person throws a sweater on the floor.",
        "vid": "3MX8V",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "AT9UV_0": {
        "text": "person begins to watch television.",
        "vid": "AT9UV",
        "timestamps": [
            26.0,
            36.0
        ]
    },
    "AT9UV_1": {
        "text": "person begin to sit on the couch.",
        "vid": "AT9UV",
        "timestamps": [
            27.2,
            36.0
        ]
    },
    "TCOXG_0": {
        "text": "person sits down on the sofa.",
        "vid": "TCOXG",
        "timestamps": [
            21.3,
            31.0
        ]
    },
    "TCOXG_1": {
        "text": "person sits down on a couch.",
        "vid": "TCOXG",
        "timestamps": [
            21.3,
            31.0
        ]
    },
    "TCOXG_2": {
        "text": "a person takes a glass of water from the shelf.",
        "vid": "TCOXG",
        "timestamps": [
            9.0,
            15.2
        ]
    },
    "TCOXG_3": {
        "text": "person takes a sip of water from a glass.",
        "vid": "TCOXG",
        "timestamps": [
            9.0,
            15.2
        ]
    },
    "L8RW8_0": {
        "text": "the person is undressing in front of a sink.",
        "vid": "L8RW8",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "L8RW8_1": {
        "text": "a person undresses.",
        "vid": "L8RW8",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "K64GM_0": {
        "text": "the person put the camera around their neck.",
        "vid": "K64GM",
        "timestamps": [
            11.0,
            15.8
        ]
    },
    "VXZBA_0": {
        "text": "person begins laughing.",
        "vid": "VXZBA",
        "timestamps": [
            20.3,
            25.9
        ]
    },
    "VXZBA_1": {
        "text": "a person walking slowly through a room smiling.",
        "vid": "VXZBA",
        "timestamps": [
            17.0,
            28.1
        ]
    },
    "0O6RK_0": {
        "text": "a person opens a refrigerator door.",
        "vid": "0O6RK",
        "timestamps": [
            0.6,
            7.4
        ]
    },
    "0O6RK_1": {
        "text": "person cooks food on the stove.",
        "vid": "0O6RK",
        "timestamps": [
            22.9,
            31.0
        ]
    },
    "0O6RK_2": {
        "text": "person closing the refrigerator door.",
        "vid": "0O6RK",
        "timestamps": [
            17.0,
            23.6
        ]
    },
    "0O6RK_3": {
        "text": "person starts cooking on a stove.",
        "vid": "0O6RK",
        "timestamps": [
            22.9,
            31.0
        ]
    },
    "0O6RK_4": {
        "text": "the person closes the door.",
        "vid": "0O6RK",
        "timestamps": [
            17.0,
            23.6
        ]
    },
    "0O6RK_5": {
        "text": "person fixes a light.",
        "vid": "0O6RK",
        "timestamps": [
            2.8,
            17.7
        ]
    },
    "0O6RK_6": {
        "text": "person cooking their food.",
        "vid": "0O6RK",
        "timestamps": [
            22.9,
            31.0
        ]
    },
    "0O6RK_7": {
        "text": "a person puts a light inside of a refrigerator.",
        "vid": "0O6RK",
        "timestamps": [
            12.5,
            17.6
        ]
    },
    "L3ZRP_0": {
        "text": "person they are eating a snack.",
        "vid": "L3ZRP",
        "timestamps": [
            5.0,
            15.8
        ]
    },
    "L3ZRP_1": {
        "text": "the person eats some piece of food.",
        "vid": "L3ZRP",
        "timestamps": [
            5.0,
            15.8
        ]
    },
    "358JF_0": {
        "text": "the person drinks some water from a glass.",
        "vid": "358JF",
        "timestamps": [
            18.8,
            28.9
        ]
    },
    "358JF_1": {
        "text": "the person takes a glass of water from nearby.",
        "vid": "358JF",
        "timestamps": [
            18.0,
            24.7
        ]
    },
    "02SKC_0": {
        "text": "a smiling person snuggles a blanket on their bed.",
        "vid": "02SKC",
        "timestamps": [
            3.5,
            8.8
        ]
    },
    "02SKC_1": {
        "text": "person puts it in a bag.",
        "vid": "02SKC",
        "timestamps": [
            20.5,
            33.0
        ]
    },
    "LSMNX_0": {
        "text": "person dresses self quickly.",
        "vid": "LSMNX",
        "timestamps": [
            5.1,
            13.6
        ]
    },
    "P8G8V_0": {
        "text": "person drinking from a cup.",
        "vid": "P8G8V",
        "timestamps": [
            3.8,
            11.4
        ]
    },
    "P8G8V_1": {
        "text": "person they casually drink a cup of coffee.",
        "vid": "P8G8V",
        "timestamps": [
            3.8,
            11.4
        ]
    },
    "P8G8V_2": {
        "text": "person drinking a cup of coffee.",
        "vid": "P8G8V",
        "timestamps": [
            3.8,
            11.4
        ]
    },
    "JQRMQ_0": {
        "text": "a person opens a door.",
        "vid": "JQRMQ",
        "timestamps": [
            5.9,
            11.1
        ]
    },
    "JQRMQ_1": {
        "text": "person turns on the light.",
        "vid": "JQRMQ",
        "timestamps": [
            5.8,
            19.2
        ]
    },
    "JQRMQ_2": {
        "text": "person they take a box from a shelf.",
        "vid": "JQRMQ",
        "timestamps": [
            10.8,
            21.8
        ]
    },
    "JQRMQ_3": {
        "text": "person turns on a light.",
        "vid": "JQRMQ",
        "timestamps": [
            5.8,
            19.2
        ]
    },
    "JQRMQ_4": {
        "text": "the person opens the door.",
        "vid": "JQRMQ",
        "timestamps": [
            5.9,
            11.1
        ]
    },
    "VJG6E_0": {
        "text": "person puts a blanket over a chair.",
        "vid": "VJG6E",
        "timestamps": [
            3.0,
            10.0
        ]
    },
    "VJG6E_1": {
        "text": "a person runs into the recreation room.",
        "vid": "VJG6E",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "VJG6E_2": {
        "text": "person begins to work on his laptop computer.",
        "vid": "VJG6E",
        "timestamps": [
            13.1,
            18.0
        ]
    },
    "VJG6E_3": {
        "text": "the person is holding blankets.",
        "vid": "VJG6E",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "OPSF8_0": {
        "text": "a person sitting at a desk eating some food.",
        "vid": "OPSF8",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "OPSF8_1": {
        "text": "person drinking from a coffee cup.",
        "vid": "OPSF8",
        "timestamps": [
            5.8,
            16.7
        ]
    },
    "OPSF8_2": {
        "text": "a person eats some food.",
        "vid": "OPSF8",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "OPSF8_3": {
        "text": "a person is eating at their desk.",
        "vid": "OPSF8",
        "timestamps": [
            0.0,
            10.1
        ]
    },
    "HVFXT_0": {
        "text": "person closes the door.",
        "vid": "HVFXT",
        "timestamps": [
            26.8,
            32.8
        ]
    },
    "QIT2W_0": {
        "text": "person start reading a book.",
        "vid": "QIT2W",
        "timestamps": [
            35.2,
            44.0
        ]
    },
    "QIT2W_1": {
        "text": "person eating from a bowl.",
        "vid": "QIT2W",
        "timestamps": [
            9.9,
            22.8
        ]
    },
    "QIT2W_2": {
        "text": "person playing on their laptop.",
        "vid": "QIT2W",
        "timestamps": [
            0.0,
            14.1
        ]
    },
    "QIT2W_3": {
        "text": "person eating food.",
        "vid": "QIT2W",
        "timestamps": [
            9.9,
            22.8
        ]
    },
    "QIT2W_4": {
        "text": "person a takes spoonful of the food made for lunch.",
        "vid": "QIT2W",
        "timestamps": [
            9.7,
            15.9
        ]
    },
    "ZI1GC_0": {
        "text": "a person sits down at a table.",
        "vid": "ZI1GC",
        "timestamps": [
            0.0,
            10.2
        ]
    },
    "ZI1GC_1": {
        "text": "person sit in the chair.",
        "vid": "ZI1GC",
        "timestamps": [
            6.4,
            10.4
        ]
    },
    "ZI1GC_2": {
        "text": "person opening the door.",
        "vid": "ZI1GC",
        "timestamps": [
            11.1,
            16.3
        ]
    },
    "4BEZX_0": {
        "text": "person sit down in a chair.",
        "vid": "4BEZX",
        "timestamps": [
            39.6,
            44.0
        ]
    },
    "4BEZX_1": {
        "text": "person they sit down in a chair.",
        "vid": "4BEZX",
        "timestamps": [
            39.6,
            44.0
        ]
    },
    "4BEZX_2": {
        "text": "a person opens the front door that leads outside.",
        "vid": "4BEZX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "4BEZX_3": {
        "text": "a person opens the door.",
        "vid": "4BEZX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "4BEZX_4": {
        "text": "person opening a door.",
        "vid": "4BEZX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "4BEZX_5": {
        "text": "the person closes the door.",
        "vid": "4BEZX",
        "timestamps": [
            15.8,
            24.3
        ]
    },
    "4BEZX_6": {
        "text": "person closes the door.",
        "vid": "4BEZX",
        "timestamps": [
            15.8,
            24.3
        ]
    },
    "4BEZX_7": {
        "text": "the person sits down in a chair.",
        "vid": "4BEZX",
        "timestamps": [
            39.6,
            44.0
        ]
    },
    "4BEZX_8": {
        "text": "person eventually sitting in a chair.",
        "vid": "4BEZX",
        "timestamps": [
            39.6,
            44.0
        ]
    },
    "4BEZX_9": {
        "text": "a person opens the door outside.",
        "vid": "4BEZX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "VNUPE_0": {
        "text": "there is a person cooking something on the stove.",
        "vid": "VNUPE",
        "timestamps": [
            17.4,
            25.7
        ]
    },
    "VZE8E_0": {
        "text": "person getting dressed.",
        "vid": "VZE8E",
        "timestamps": [
            18.8,
            27.0
        ]
    },
    "VZE8E_1": {
        "text": "a person awakens.",
        "vid": "VZE8E",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "VZE8E_2": {
        "text": "person throws his pillow.",
        "vid": "VZE8E",
        "timestamps": [
            3.5,
            8.7
        ]
    },
    "VZE8E_3": {
        "text": "person takes their head off a pillow.",
        "vid": "VZE8E",
        "timestamps": [
            3.1,
            8.5
        ]
    },
    "VZE8E_4": {
        "text": "person opens up a door.",
        "vid": "VZE8E",
        "timestamps": [
            11.6,
            18.5
        ]
    },
    "VZE8E_5": {
        "text": "person open the door walk back in.",
        "vid": "VZE8E",
        "timestamps": [
            11.6,
            18.5
        ]
    },
    "VZE8E_6": {
        "text": "person opening the closet door.",
        "vid": "VZE8E",
        "timestamps": [
            7.9,
            15.5
        ]
    },
    "NYHD7_0": {
        "text": "the person puts the phone away.",
        "vid": "NYHD7",
        "timestamps": [
            22.4,
            27.2
        ]
    },
    "SM41Q_0": {
        "text": "a person is sitting at a table reading something.",
        "vid": "SM41Q",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "SM41Q_1": {
        "text": "person takes a laptop.",
        "vid": "SM41Q",
        "timestamps": [
            3.7,
            13.0
        ]
    },
    "VS7VS_0": {
        "text": "laughing in a mischievous manner.",
        "vid": "VS7VS",
        "timestamps": [
            15.7,
            23.4
        ]
    },
    "O1LMX_0": {
        "text": "person opens up the laptop.",
        "vid": "O1LMX",
        "timestamps": [
            11.5,
            18.8
        ]
    },
    "O1LMX_1": {
        "text": "the person puts the book away.",
        "vid": "O1LMX",
        "timestamps": [
            8.4,
            14.2
        ]
    },
    "O1LMX_2": {
        "text": "a person holds a book.",
        "vid": "O1LMX",
        "timestamps": [
            1.9,
            14.3
        ]
    },
    "O1LMX_3": {
        "text": "person opens the laptop up.",
        "vid": "O1LMX",
        "timestamps": [
            11.5,
            18.8
        ]
    },
    "O1LMX_4": {
        "text": "the person looks at the book.",
        "vid": "O1LMX",
        "timestamps": [
            2.1,
            14.2
        ]
    },
    "7177T_0": {
        "text": "person turn on the light.",
        "vid": "7177T",
        "timestamps": [
            14.9,
            20.3
        ]
    },
    "7177T_1": {
        "text": "person turned on the closet light.",
        "vid": "7177T",
        "timestamps": [
            14.9,
            20.3
        ]
    },
    "7177T_2": {
        "text": "person opening the door.",
        "vid": "7177T",
        "timestamps": [
            9.8,
            18.2
        ]
    },
    "00T1E_0": {
        "text": "person close the laptop.",
        "vid": "00T1E",
        "timestamps": [
            0.7,
            6.3
        ]
    },
    "00T1E_1": {
        "text": "person puts on shoes.",
        "vid": "00T1E",
        "timestamps": [
            4.3,
            12.0
        ]
    },
    "00T1E_2": {
        "text": "person put on a pair of shoes.",
        "vid": "00T1E",
        "timestamps": [
            4.3,
            12.0
        ]
    },
    "00T1E_3": {
        "text": "person puts on their shoes.",
        "vid": "00T1E",
        "timestamps": [
            4.3,
            12.0
        ]
    },
    "LSKA2_0": {
        "text": "person they take the sandwich.",
        "vid": "LSKA2",
        "timestamps": [
            10.0,
            19.7
        ]
    },
    "UKSCV_0": {
        "text": "a person is dressing in a hallway.",
        "vid": "UKSCV",
        "timestamps": [
            0.0,
            11.4
        ]
    },
    "UKSCV_1": {
        "text": "a person is eating groceries.",
        "vid": "UKSCV",
        "timestamps": [
            7.7,
            23.5
        ]
    },
    "UKSCV_2": {
        "text": "another person is standing behind him eating.",
        "vid": "UKSCV",
        "timestamps": [
            7.7,
            23.5
        ]
    },
    "UKSCV_3": {
        "text": "person putting on a dress shirt.",
        "vid": "UKSCV",
        "timestamps": [
            0.0,
            11.4
        ]
    },
    "UKSCV_4": {
        "text": "person eating something.",
        "vid": "UKSCV",
        "timestamps": [
            7.7,
            23.5
        ]
    },
    "UKSCV_5": {
        "text": "another person is dressing.",
        "vid": "UKSCV",
        "timestamps": [
            0.0,
            11.4
        ]
    },
    "UKSCV_6": {
        "text": "a person is getting dressed.",
        "vid": "UKSCV",
        "timestamps": [
            0.0,
            11.4
        ]
    },
    "UKSCV_7": {
        "text": "another person is eating.",
        "vid": "UKSCV",
        "timestamps": [
            7.7,
            23.5
        ]
    },
    "CXNYW_0": {
        "text": "person eating a sandwich.",
        "vid": "CXNYW",
        "timestamps": [
            16.6,
            27.0
        ]
    },
    "CXNYW_1": {
        "text": "a person sits in a chair at the desk.",
        "vid": "CXNYW",
        "timestamps": [
            0.0,
            13.4
        ]
    },
    "CXNYW_2": {
        "text": "a seated person wearing striped pants types on a keyboard.",
        "vid": "CXNYW",
        "timestamps": [
            17.6,
            27.1
        ]
    },
    "3XL0K_0": {
        "text": "a person closes the cabinet.",
        "vid": "3XL0K",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "3XL0K_1": {
        "text": "a person closes a cabinet door.",
        "vid": "3XL0K",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "O5V8D_0": {
        "text": "person takes pictures of them-self on the steps.",
        "vid": "O5V8D",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "O5V8D_1": {
        "text": "the person goes to take a picture of themselves.",
        "vid": "O5V8D",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "ME4YL_0": {
        "text": "person they open up their laptop.",
        "vid": "ME4YL",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "ME4YL_1": {
        "text": "tidying up,the person moves blanket.",
        "vid": "ME4YL",
        "timestamps": [
            2.7,
            11.2
        ]
    },
    "ME4YL_2": {
        "text": "person they open a laptop.",
        "vid": "ME4YL",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "ME4YL_3": {
        "text": "person put a book on top of the laptop.",
        "vid": "ME4YL",
        "timestamps": [
            18.9,
            24.8
        ]
    },
    "ME4YL_4": {
        "text": "person bring over a book over close to the computer.",
        "vid": "ME4YL",
        "timestamps": [
            18.9,
            24.8
        ]
    },
    "ME4YL_5": {
        "text": "person opens up s laptop.",
        "vid": "ME4YL",
        "timestamps": [
            10.5,
            17.0
        ]
    },
    "9OCQT_0": {
        "text": "a person holds a box in front of a mirror.",
        "vid": "9OCQT",
        "timestamps": [
            0.0,
            3.6
        ]
    },
    "9OCQT_1": {
        "text": "person puts the box down.",
        "vid": "9OCQT",
        "timestamps": [
            1.5,
            7.5
        ]
    },
    "Z4Y04_0": {
        "text": "person opens the oven door.",
        "vid": "Z4Y04",
        "timestamps": [
            14.3,
            29.4
        ]
    },
    "RG0KS_0": {
        "text": "person they begin sneezing.",
        "vid": "RG0KS",
        "timestamps": [
            14.8,
            21.5
        ]
    },
    "65UVU_0": {
        "text": "a person opens the door to the bedroom.",
        "vid": "65UVU",
        "timestamps": [
            0.0,
            3.2
        ]
    },
    "65UVU_1": {
        "text": "person takes another box from the same shelf.",
        "vid": "65UVU",
        "timestamps": [
            9.6,
            16.1
        ]
    },
    "65UVU_2": {
        "text": "a person puts a container on a top shelf.",
        "vid": "65UVU",
        "timestamps": [
            4.2,
            16.0
        ]
    },
    "JZ45I_0": {
        "text": "person open a box.",
        "vid": "JZ45I",
        "timestamps": [
            28.8,
            35.0
        ]
    },
    "JZ45I_1": {
        "text": "person tilt their head back in laughter.",
        "vid": "JZ45I",
        "timestamps": [
            6.9,
            16.5
        ]
    },
    "JZ45I_2": {
        "text": "person begin laughing.",
        "vid": "JZ45I",
        "timestamps": [
            6.9,
            16.5
        ]
    },
    "UL5X4_0": {
        "text": "person takes a drink from a cup of coffee.",
        "vid": "UL5X4",
        "timestamps": [
            18.4,
            32.0
        ]
    },
    "UL5X4_1": {
        "text": "person sitting on bed stands up.",
        "vid": "UL5X4",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "LKH9A_0": {
        "text": "person turns on the light.",
        "vid": "LKH9A",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "LKH9A_1": {
        "text": "person puts the book down.",
        "vid": "LKH9A",
        "timestamps": [
            23.0,
            29.2
        ]
    },
    "LKH9A_2": {
        "text": "the person closes the book.",
        "vid": "LKH9A",
        "timestamps": [
            22.3,
            27.0
        ]
    },
    "LKH9A_3": {
        "text": "person take a book off the top of the shelf.",
        "vid": "LKH9A",
        "timestamps": [
            6.4,
            11.9
        ]
    },
    "HDHGT_0": {
        "text": "person sneezing twice.",
        "vid": "HDHGT",
        "timestamps": [
            11.5,
            19.5
        ]
    },
    "HDHGT_1": {
        "text": "person sneezing on a shelf in the pantry.",
        "vid": "HDHGT",
        "timestamps": [
            11.5,
            19.5
        ]
    },
    "HDHGT_2": {
        "text": "person opens the box.",
        "vid": "HDHGT",
        "timestamps": [
            4.2,
            16.2
        ]
    },
    "HDHGT_3": {
        "text": "the person is opening a box of cereal.",
        "vid": "HDHGT",
        "timestamps": [
            4.2,
            16.2
        ]
    },
    "GH19N_0": {
        "text": "person starts dressing.",
        "vid": "GH19N",
        "timestamps": [
            25.8,
            29.0
        ]
    },
    "GH19N_1": {
        "text": "this person puts the book down.",
        "vid": "GH19N",
        "timestamps": [
            25.8,
            29.0
        ]
    },
    "GH19N_2": {
        "text": "person is opening door to closet.",
        "vid": "GH19N",
        "timestamps": [
            0.1,
            12.1
        ]
    },
    "GH19N_3": {
        "text": "person puts homework on table.",
        "vid": "GH19N",
        "timestamps": [
            13.6,
            18.2
        ]
    },
    "GH19N_4": {
        "text": "a person opens a door holding a book.",
        "vid": "GH19N",
        "timestamps": [
            1.7,
            9.5
        ]
    },
    "QFL2O_0": {
        "text": "person laugh at it.",
        "vid": "QFL2O",
        "timestamps": [
            21.8,
            32.0
        ]
    },
    "QFL2O_1": {
        "text": "person takes a phone.",
        "vid": "QFL2O",
        "timestamps": [
            20.7,
            32.0
        ]
    },
    "D9PWE_0": {
        "text": "a person takes a vacuum.",
        "vid": "D9PWE",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "SJJLG_0": {
        "text": "person sits in a chair.",
        "vid": "SJJLG",
        "timestamps": [
            10.8,
            15.8
        ]
    },
    "SJJLG_1": {
        "text": "a person is opening a cabinet.",
        "vid": "SJJLG",
        "timestamps": [
            1.0,
            5.6
        ]
    },
    "SJJLG_2": {
        "text": "person sits on a chair.",
        "vid": "SJJLG",
        "timestamps": [
            10.8,
            15.8
        ]
    },
    "SJJLG_3": {
        "text": "a laughing person opens a cabinet in their kitchen.",
        "vid": "SJJLG",
        "timestamps": [
            1.0,
            5.6
        ]
    },
    "SJJLG_4": {
        "text": "person sits down on a chair.",
        "vid": "SJJLG",
        "timestamps": [
            10.8,
            15.8
        ]
    },
    "SJJLG_5": {
        "text": "person sits at a table in front of a laptop.",
        "vid": "SJJLG",
        "timestamps": [
            9.7,
            15.2
        ]
    },
    "SJJLG_6": {
        "text": "a person opens a kitchen cabinet.",
        "vid": "SJJLG",
        "timestamps": [
            1.0,
            5.6
        ]
    },
    "AF8I2_0": {
        "text": "a person laughs.",
        "vid": "AF8I2",
        "timestamps": [
            9.2,
            14.6
        ]
    },
    "XJE7I_0": {
        "text": "a person opens the bathroom door using the doorknob.",
        "vid": "XJE7I",
        "timestamps": [
            2.9,
            9.6
        ]
    },
    "XJE7I_1": {
        "text": "person they turn the light on.",
        "vid": "XJE7I",
        "timestamps": [
            8.4,
            13.7
        ]
    },
    "XJE7I_2": {
        "text": "person they turn on the light.",
        "vid": "XJE7I",
        "timestamps": [
            8.4,
            13.7
        ]
    },
    "XJE7I_3": {
        "text": "person opening the door.",
        "vid": "XJE7I",
        "timestamps": [
            2.9,
            9.6
        ]
    },
    "XJE7I_4": {
        "text": "person close the door.",
        "vid": "XJE7I",
        "timestamps": [
            24.7,
            30.0
        ]
    },
    "XJE7I_5": {
        "text": "person they take a bag form a counter.",
        "vid": "XJE7I",
        "timestamps": [
            20.2,
            27.9
        ]
    },
    "XJE7I_6": {
        "text": "a person opens a door.",
        "vid": "XJE7I",
        "timestamps": [
            2.9,
            9.6
        ]
    },
    "XJE7I_7": {
        "text": "person take a bag from the counter.",
        "vid": "XJE7I",
        "timestamps": [
            20.2,
            27.9
        ]
    },
    "4A28I_0": {
        "text": "a person is smiling.",
        "vid": "4A28I",
        "timestamps": [
            2.3,
            10.6
        ]
    },
    "4A28I_1": {
        "text": "laughing a person holding a bag with medicine.",
        "vid": "4A28I",
        "timestamps": [
            9.2,
            15.3
        ]
    },
    "4A28I_2": {
        "text": "person smiling when they look around.",
        "vid": "4A28I",
        "timestamps": [
            2.3,
            10.6
        ]
    },
    "6H78U_0": {
        "text": "a person plays with a phone.",
        "vid": "6H78U",
        "timestamps": [
            0.0,
            12.7
        ]
    },
    "CPM4M_0": {
        "text": "a person opens the refrigerator.",
        "vid": "CPM4M",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "CPM4M_1": {
        "text": "a person opens a refrigerator door.",
        "vid": "CPM4M",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "CPM4M_2": {
        "text": "person they start eating the cereal.",
        "vid": "CPM4M",
        "timestamps": [
            26.3,
            30.0
        ]
    },
    "CPM4M_3": {
        "text": "person starts eating from the bowl.",
        "vid": "CPM4M",
        "timestamps": [
            26.3,
            30.0
        ]
    },
    "CPM4M_4": {
        "text": "person sit on the sofa.",
        "vid": "CPM4M",
        "timestamps": [
            26.1,
            30.0
        ]
    },
    "CPM4M_5": {
        "text": "person sit on the couch.",
        "vid": "CPM4M",
        "timestamps": [
            26.1,
            30.0
        ]
    },
    "LRDW5_0": {
        "text": "the person dressed in the sweater.",
        "vid": "LRDW5",
        "timestamps": [
            8.5,
            19.0
        ]
    },
    "LRDW5_1": {
        "text": "a person opens a closet door.",
        "vid": "LRDW5",
        "timestamps": [
            0.3,
            7.1
        ]
    },
    "LRDW5_2": {
        "text": "person opens a closet door.",
        "vid": "LRDW5",
        "timestamps": [
            0.3,
            7.1
        ]
    },
    "LRDW5_3": {
        "text": "the person opened their closet.",
        "vid": "LRDW5",
        "timestamps": [
            0.3,
            7.1
        ]
    },
    "LRDW5_4": {
        "text": "person left the room closing the door behind them.",
        "vid": "LRDW5",
        "timestamps": [
            21.3,
            27.9
        ]
    },
    "LRDW5_5": {
        "text": "the person begins to put clothes on.",
        "vid": "LRDW5",
        "timestamps": [
            6.7,
            20.5
        ]
    },
    "0WYBK_0": {
        "text": "person eating a sandwich.",
        "vid": "0WYBK",
        "timestamps": [
            1.8,
            8.8
        ]
    },
    "0WYBK_1": {
        "text": "person eating some groceries.",
        "vid": "0WYBK",
        "timestamps": [
            1.9,
            7.4
        ]
    },
    "0WYBK_2": {
        "text": "that same person puts the book down on the floor.",
        "vid": "0WYBK",
        "timestamps": [
            8.2,
            12.8
        ]
    },
    "NTXXB_0": {
        "text": "person takes a picture.",
        "vid": "NTXXB",
        "timestamps": [
            16.9,
            26.9
        ]
    },
    "NTXXB_1": {
        "text": "person looking out a window.",
        "vid": "NTXXB",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "NTXXB_2": {
        "text": "person takes out a camera.",
        "vid": "NTXXB",
        "timestamps": [
            11.0,
            17.5
        ]
    },
    "NTXXB_3": {
        "text": "person watched out of the window.",
        "vid": "NTXXB",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "NTXXB_4": {
        "text": "person watching something out the window.",
        "vid": "NTXXB",
        "timestamps": [
            0.0,
            10.9
        ]
    },
    "JOMFO_0": {
        "text": "the person throws the blanket out of camera view.",
        "vid": "JOMFO",
        "timestamps": [
            15.0,
            20.1
        ]
    },
    "JOMFO_1": {
        "text": "a person is throwing a blanket.",
        "vid": "JOMFO",
        "timestamps": [
            15.0,
            20.1
        ]
    },
    "1GGRY_0": {
        "text": "a person opens a pantry door.",
        "vid": "1GGRY",
        "timestamps": [
            0.8,
            6.1
        ]
    },
    "1GGRY_1": {
        "text": "person closed the closet door.",
        "vid": "1GGRY",
        "timestamps": [
            8.9,
            14.3
        ]
    },
    "BEJVY_0": {
        "text": "the person takes a laptop.",
        "vid": "BEJVY",
        "timestamps": [
            6.8,
            12.1
        ]
    },
    "BEJVY_1": {
        "text": "a person is eating food in the man cave.",
        "vid": "BEJVY",
        "timestamps": [
            2.4,
            8.1
        ]
    },
    "EJZZZ_0": {
        "text": "person dressing themselves.",
        "vid": "EJZZZ",
        "timestamps": [
            2.4,
            10.7
        ]
    },
    "62AC0_0": {
        "text": "a seated person looks out a window.",
        "vid": "62AC0",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "SLAH4_0": {
        "text": "a person is holding a doorknob.",
        "vid": "SLAH4",
        "timestamps": [
            0.0,
            3.9
        ]
    },
    "SLAH4_1": {
        "text": "person turn off the light.",
        "vid": "SLAH4",
        "timestamps": [
            10.0,
            15.3
        ]
    },
    "JDZV7_0": {
        "text": "person washing hands at sink.",
        "vid": "JDZV7",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "JDZV7_1": {
        "text": "a person washes their hands in the bathroom sink.",
        "vid": "JDZV7",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "JDZV7_2": {
        "text": "person closing a cabinet door.",
        "vid": "JDZV7",
        "timestamps": [
            25.2,
            30.9
        ]
    },
    "JDZV7_3": {
        "text": "person opens a cabinet door.",
        "vid": "JDZV7",
        "timestamps": [
            22.7,
            32.0
        ]
    },
    "JDZV7_4": {
        "text": "a person washes their hands in the sink.",
        "vid": "JDZV7",
        "timestamps": [
            0.0,
            9.8
        ]
    },
    "1GII3_0": {
        "text": "person begins to eat it.",
        "vid": "1GII3",
        "timestamps": [
            18.7,
            25.0
        ]
    },
    "1GII3_1": {
        "text": "person begins eating it.",
        "vid": "1GII3",
        "timestamps": [
            18.7,
            25.0
        ]
    },
    "1GII3_2": {
        "text": "person eating a bag of chips.",
        "vid": "1GII3",
        "timestamps": [
            18.7,
            25.0
        ]
    },
    "UD0P0_0": {
        "text": "person drinking the entire cup.",
        "vid": "UD0P0",
        "timestamps": [
            1.1,
            6.1
        ]
    },
    "UD0P0_1": {
        "text": "one person uses a camera to take a picture.",
        "vid": "UD0P0",
        "timestamps": [
            17.5,
            25.8
        ]
    },
    "YNF6O_0": {
        "text": "that same person puts clothes.",
        "vid": "YNF6O",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "T8VDU_0": {
        "text": "a person is sitting in a chair watching tv.",
        "vid": "T8VDU",
        "timestamps": [
            17.1,
            27.6
        ]
    },
    "T8VDU_1": {
        "text": "person grabs a red drinking glass from the table.",
        "vid": "T8VDU",
        "timestamps": [
            9.8,
            21.5
        ]
    },
    "0TKKR_0": {
        "text": "person drinks a glass of water.",
        "vid": "0TKKR",
        "timestamps": [
            30.7,
            41.5
        ]
    },
    "0TKKR_1": {
        "text": "a person is sitting on a couch watching tv.",
        "vid": "0TKKR",
        "timestamps": [
            0.0,
            18.8
        ]
    },
    "0TKKR_2": {
        "text": "person eating a sandwich.",
        "vid": "0TKKR",
        "timestamps": [
            34.9,
            45.0
        ]
    },
    "0TKKR_3": {
        "text": "person they pour a drink in a glass.",
        "vid": "0TKKR",
        "timestamps": [
            30.7,
            41.5
        ]
    },
    "0TKKR_4": {
        "text": "a person eats a sandwich on the couch.",
        "vid": "0TKKR",
        "timestamps": [
            34.9,
            45.0
        ]
    },
    "0TKKR_5": {
        "text": "a person is sitting on the couch watching television.",
        "vid": "0TKKR",
        "timestamps": [
            0.0,
            18.8
        ]
    },
    "17P5V_0": {
        "text": "person puts the laptop on a love seat.",
        "vid": "17P5V",
        "timestamps": [
            11.5,
            19.0
        ]
    },
    "17P5V_1": {
        "text": "person closes the laptop.",
        "vid": "17P5V",
        "timestamps": [
            6.7,
            16.4
        ]
    },
    "15PMU_0": {
        "text": "person looking out the window.",
        "vid": "15PMU",
        "timestamps": [
            0.9,
            12.4
        ]
    },
    "15PMU_1": {
        "text": "person looking out of a window.",
        "vid": "15PMU",
        "timestamps": [
            0.9,
            12.4
        ]
    },
    "15PMU_2": {
        "text": "the person undressed.",
        "vid": "15PMU",
        "timestamps": [
            0.5,
            12.8
        ]
    },
    "15PMU_3": {
        "text": "a person is undressing.",
        "vid": "15PMU",
        "timestamps": [
            0.5,
            12.8
        ]
    },
    "15PMU_4": {
        "text": "person drinks something from the cup.",
        "vid": "15PMU",
        "timestamps": [
            21.4,
            32.0
        ]
    },
    "FMZOY_0": {
        "text": "person opens the door.",
        "vid": "FMZOY",
        "timestamps": [
            35.0,
            41.1
        ]
    },
    "9AC1T_0": {
        "text": "a person sits down reading a book.",
        "vid": "9AC1T",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "9AC1T_1": {
        "text": "a person sits at a table reading a book intensely.",
        "vid": "9AC1T",
        "timestamps": [
            0.0,
            4.8
        ]
    },
    "GGN5G_0": {
        "text": "a person opens up the cabinet.",
        "vid": "GGN5G",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "2UQKZ_0": {
        "text": "person takes a blanket.",
        "vid": "2UQKZ",
        "timestamps": [
            19.3,
            24.7
        ]
    },
    "2UQKZ_1": {
        "text": "person fixes their hair.",
        "vid": "2UQKZ",
        "timestamps": [
            6.0,
            22.8
        ]
    },
    "W1CG2_0": {
        "text": "the person is eating food.",
        "vid": "W1CG2",
        "timestamps": [
            5.0,
            16.8
        ]
    },
    "W1CG2_1": {
        "text": "the person puts the food on the desk.",
        "vid": "W1CG2",
        "timestamps": [
            12.4,
            17.6
        ]
    },
    "W1CG2_2": {
        "text": "person puts their leg up on a table.",
        "vid": "W1CG2",
        "timestamps": [
            13.4,
            19.1
        ]
    },
    "JHB0M_0": {
        "text": "a person is sitting at a table eating a sandwich.",
        "vid": "JHB0M",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "JHB0M_1": {
        "text": "person eating some groceries.",
        "vid": "JHB0M",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "JHB0M_2": {
        "text": "a person is sitting at a table eating.",
        "vid": "JHB0M",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "JHB0M_3": {
        "text": "person starts to eat it.",
        "vid": "JHB0M",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "JHB0M_4": {
        "text": "person begins pouring something from a very small bottle.",
        "vid": "JHB0M",
        "timestamps": [
            7.7,
            14.9
        ]
    },
    "JHB0M_5": {
        "text": "person pours medicine in a cup.",
        "vid": "JHB0M",
        "timestamps": [
            7.7,
            14.9
        ]
    },
    "NQMMJ_0": {
        "text": "person closes the cabinet door.",
        "vid": "NQMMJ",
        "timestamps": [
            26.8,
            34.9
        ]
    },
    "NQMMJ_1": {
        "text": "person closing the doors.",
        "vid": "NQMMJ",
        "timestamps": [
            26.8,
            34.9
        ]
    },
    "EXYY8_0": {
        "text": "a person runs into the closet holding a laptop.",
        "vid": "EXYY8",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "EXYY8_1": {
        "text": "person closing the door behind them.",
        "vid": "EXYY8",
        "timestamps": [
            14.1,
            20.0
        ]
    },
    "NAZ52_0": {
        "text": "person he closed the box.",
        "vid": "NAZ52",
        "timestamps": [
            21.3,
            27.2
        ]
    },
    "NAZ52_1": {
        "text": "person puts the box onto a shelf.",
        "vid": "NAZ52",
        "timestamps": [
            5.4,
            15.7
        ]
    },
    "NAZ52_2": {
        "text": "person closes the box.",
        "vid": "NAZ52",
        "timestamps": [
            21.3,
            27.2
        ]
    },
    "NAZ52_3": {
        "text": "person a teenager opened a box.",
        "vid": "NAZ52",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "NAZ52_4": {
        "text": "person opens a box.",
        "vid": "NAZ52",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "NAZ52_5": {
        "text": "person laughing as they go through a box.",
        "vid": "NAZ52",
        "timestamps": [
            23.8,
            33.0
        ]
    },
    "BDZNW_0": {
        "text": "person closing the door to it behind them.",
        "vid": "BDZNW",
        "timestamps": [
            28.7,
            34.0
        ]
    },
    "BDZNW_1": {
        "text": "person closing the door.",
        "vid": "BDZNW",
        "timestamps": [
            28.7,
            34.0
        ]
    },
    "ZJRCS_0": {
        "text": "person closes a window.",
        "vid": "ZJRCS",
        "timestamps": [
            4.9,
            20.2
        ]
    },
    "ZJRCS_1": {
        "text": "person laughing with a phone in hand.",
        "vid": "ZJRCS",
        "timestamps": [
            11.1,
            21.9
        ]
    },
    "N0ODO_0": {
        "text": "another person opens the door.",
        "vid": "N0ODO",
        "timestamps": [
            9.2,
            16.8
        ]
    },
    "N0ODO_1": {
        "text": "the first person closes the door.",
        "vid": "N0ODO",
        "timestamps": [
            14.9,
            21.1
        ]
    },
    "N0ODO_2": {
        "text": "another person opens the bathroom door.",
        "vid": "N0ODO",
        "timestamps": [
            9.2,
            16.8
        ]
    },
    "FQOGZ_0": {
        "text": "person putting the food on the table.",
        "vid": "FQOGZ",
        "timestamps": [
            17.5,
            23.7
        ]
    },
    "FQOGZ_1": {
        "text": "person takes something with a glass of water.",
        "vid": "FQOGZ",
        "timestamps": [
            23.6,
            29.5
        ]
    },
    "FQOGZ_2": {
        "text": "a person puts food into a bowl for a cat.",
        "vid": "FQOGZ",
        "timestamps": [
            17.5,
            23.7
        ]
    },
    "FQOGZ_3": {
        "text": "the person begins sneezing.",
        "vid": "FQOGZ",
        "timestamps": [
            10.1,
            17.1
        ]
    },
    "IEQWT_0": {
        "text": "person opens the door a few inches.",
        "vid": "IEQWT",
        "timestamps": [
            2.1,
            8.9
        ]
    },
    "IEQWT_1": {
        "text": "opening the door all the way the person turns around.",
        "vid": "IEQWT",
        "timestamps": [
            2.1,
            8.9
        ]
    },
    "X817Z_0": {
        "text": "a person is sitting on the sofa holding a book.",
        "vid": "X817Z",
        "timestamps": [
            0.0,
            14.1
        ]
    },
    "X817Z_1": {
        "text": "person putting the book aside.",
        "vid": "X817Z",
        "timestamps": [
            9.2,
            14.1
        ]
    },
    "X817Z_2": {
        "text": "a person who is siting on bed with book.",
        "vid": "X817Z",
        "timestamps": [
            0.0,
            7.7
        ]
    },
    "RG0JH_0": {
        "text": "a person sits on the bed.",
        "vid": "RG0JH",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "RG0JH_1": {
        "text": "a person is sitting on the bed.",
        "vid": "RG0JH",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "RG0JH_2": {
        "text": "a man sitting on a bed.",
        "vid": "RG0JH",
        "timestamps": [
            0.0,
            8.1
        ]
    },
    "VF49P_0": {
        "text": "a person is throwing a pillow towards the window.",
        "vid": "VF49P",
        "timestamps": [
            2.8,
            10.1
        ]
    },
    "HQ8ZM_0": {
        "text": "the person puts their phone away.",
        "vid": "HQ8ZM",
        "timestamps": [
            16.0,
            21.0
        ]
    },
    "XHYA2_0": {
        "text": "the person throws the shoes behind the door.",
        "vid": "XHYA2",
        "timestamps": [
            16.1,
            21.5
        ]
    },
    "XHYA2_1": {
        "text": "person put their coffee cup on a dresser.",
        "vid": "XHYA2",
        "timestamps": [
            12.7,
            18.1
        ]
    },
    "XHYA2_2": {
        "text": "person sits down on the bed.",
        "vid": "XHYA2",
        "timestamps": [
            20.9,
            32.0
        ]
    },
    "XHYA2_3": {
        "text": "person they throw their shoes behind the door.",
        "vid": "XHYA2",
        "timestamps": [
            16.1,
            21.5
        ]
    },
    "XHYA2_4": {
        "text": "the person throws their shoes down by the door.",
        "vid": "XHYA2",
        "timestamps": [
            16.1,
            21.5
        ]
    },
    "XHYA2_5": {
        "text": "person they sit on the bed.",
        "vid": "XHYA2",
        "timestamps": [
            20.9,
            32.0
        ]
    },
    "1W6ZK_0": {
        "text": "a person opens a door.",
        "vid": "1W6ZK",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "1W6ZK_1": {
        "text": "person stand in the doorway undressing.",
        "vid": "1W6ZK",
        "timestamps": [
            7.7,
            17.5
        ]
    },
    "1W6ZK_2": {
        "text": "person they put their clothes in a box.",
        "vid": "1W6ZK",
        "timestamps": [
            20.1,
            25.2
        ]
    },
    "1W6ZK_3": {
        "text": "person walks through the doorway.",
        "vid": "1W6ZK",
        "timestamps": [
            0.8,
            9.7
        ]
    },
    "1W6ZK_4": {
        "text": "person they open the door.",
        "vid": "1W6ZK",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "VXEXI_0": {
        "text": "another person is smiling at a cup of coffee.",
        "vid": "VXEXI",
        "timestamps": [
            17.8,
            32.0
        ]
    },
    "VXEXI_1": {
        "text": "a person is sneezing on a book.",
        "vid": "VXEXI",
        "timestamps": [
            15.0,
            23.8
        ]
    },
    "1BBIY_0": {
        "text": "person opens the door.",
        "vid": "1BBIY",
        "timestamps": [
            17.6,
            23.3
        ]
    },
    "1BBIY_1": {
        "text": "person take a picture from a shelf.",
        "vid": "1BBIY",
        "timestamps": [
            19.6,
            24.9
        ]
    },
    "1BBIY_2": {
        "text": "person closes the door.",
        "vid": "1BBIY",
        "timestamps": [
            2.2,
            12.6
        ]
    },
    "93REJ_0": {
        "text": "person drinking from a cup.",
        "vid": "93REJ",
        "timestamps": [
            3.4,
            10.5
        ]
    },
    "KJRR9_0": {
        "text": "a person opens a door.",
        "vid": "KJRR9",
        "timestamps": [
            2.4,
            9.2
        ]
    },
    "KJRR9_1": {
        "text": "person is opening a door.",
        "vid": "KJRR9",
        "timestamps": [
            2.4,
            9.2
        ]
    },
    "KJRR9_2": {
        "text": "person turning light on.",
        "vid": "KJRR9",
        "timestamps": [
            6.4,
            11.2
        ]
    },
    "KJRR9_3": {
        "text": "person turns on a light.",
        "vid": "KJRR9",
        "timestamps": [
            6.4,
            11.2
        ]
    },
    "KJRR9_4": {
        "text": "the person turns on the light.",
        "vid": "KJRR9",
        "timestamps": [
            6.4,
            11.2
        ]
    },
    "9M48H_0": {
        "text": "person puts a phone down on the counter.",
        "vid": "9M48H",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "9M48H_1": {
        "text": "a person puts their phone on the kitchen counter.",
        "vid": "9M48H",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "9M48H_2": {
        "text": "person puts their phone down.",
        "vid": "9M48H",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "WX8N8_0": {
        "text": "the person begins undressing.",
        "vid": "WX8N8",
        "timestamps": [
            6.8,
            21.2
        ]
    },
    "I7GZI_0": {
        "text": "person a girl runs into the room.",
        "vid": "I7GZI",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "I7GZI_1": {
        "text": "person she runs out of the room.",
        "vid": "I7GZI",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "I7GZI_2": {
        "text": "a person is running towards a chair.",
        "vid": "I7GZI",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "NATEB_0": {
        "text": "person closing a door.",
        "vid": "NATEB",
        "timestamps": [
            13.7,
            19.9
        ]
    },
    "NATEB_1": {
        "text": "the person closes doors to a large cupboard.",
        "vid": "NATEB",
        "timestamps": [
            13.7,
            19.9
        ]
    },
    "NATEB_2": {
        "text": "person reopens one of the doors.",
        "vid": "NATEB",
        "timestamps": [
            15.6,
            22.2
        ]
    },
    "IBWAW_0": {
        "text": "person puts the cup on a table.",
        "vid": "IBWAW",
        "timestamps": [
            17.5,
            23.3
        ]
    },
    "IBWAW_1": {
        "text": "person drank from the glass,put the glass down.",
        "vid": "IBWAW",
        "timestamps": [
            17.5,
            23.3
        ]
    },
    "IBWAW_2": {
        "text": "takes a box from the other person.",
        "vid": "IBWAW",
        "timestamps": [
            21.0,
            26.5
        ]
    },
    "IBWAW_3": {
        "text": "person he eats something out of his hand.",
        "vid": "IBWAW",
        "timestamps": [
            1.4,
            9.4
        ]
    },
    "IBWAW_4": {
        "text": "a person is eating a snack.",
        "vid": "IBWAW",
        "timestamps": [
            1.4,
            9.4
        ]
    },
    "A1BS2_0": {
        "text": "person they open a cabinet.",
        "vid": "A1BS2",
        "timestamps": [
            14.0,
            20.1
        ]
    },
    "A1BS2_1": {
        "text": "person opens the door.",
        "vid": "A1BS2",
        "timestamps": [
            14.9,
            20.6
        ]
    },
    "A1BS2_2": {
        "text": "person opened a cabinet door.",
        "vid": "A1BS2",
        "timestamps": [
            14.0,
            20.1
        ]
    },
    "MFGLZ_0": {
        "text": "person opens bag.",
        "vid": "MFGLZ",
        "timestamps": [
            18.7,
            30.4
        ]
    },
    "MFGLZ_1": {
        "text": "a person awakens in their home office.",
        "vid": "MFGLZ",
        "timestamps": [
            0.0,
            8.6
        ]
    },
    "QN7Y2_0": {
        "text": "person opens up a cabinet.",
        "vid": "QN7Y2",
        "timestamps": [
            6.1,
            12.5
        ]
    },
    "QN7Y2_1": {
        "text": "one person opens a cabinet with a television.",
        "vid": "QN7Y2",
        "timestamps": [
            6.1,
            12.5
        ]
    },
    "610PZ_0": {
        "text": "person standing in the hall drinking out of a cup.",
        "vid": "610PZ",
        "timestamps": [
            0.2,
            7.9
        ]
    },
    "6TC5G_0": {
        "text": "the person throws a bag on the closet floor.",
        "vid": "6TC5G",
        "timestamps": [
            12.3,
            17.5
        ]
    },
    "6TC5G_1": {
        "text": "person throws the rest on the floor below them.",
        "vid": "6TC5G",
        "timestamps": [
            12.3,
            17.5
        ]
    },
    "6TC5G_2": {
        "text": "person laughs as they turn off the light.",
        "vid": "6TC5G",
        "timestamps": [
            14.0,
            18.0
        ]
    },
    "6TC5G_3": {
        "text": "person shuts off the light.",
        "vid": "6TC5G",
        "timestamps": [
            14.0,
            18.0
        ]
    },
    "6TC5G_4": {
        "text": "the person turns off the light.",
        "vid": "6TC5G",
        "timestamps": [
            14.0,
            18.0
        ]
    },
    "6TC5G_5": {
        "text": "a person puts some clothes onto some clothing racks.",
        "vid": "6TC5G",
        "timestamps": [
            11.9,
            17.2
        ]
    },
    "XZ2WT_0": {
        "text": "person snuggles a blanket found inside.",
        "vid": "XZ2WT",
        "timestamps": [
            15.8,
            29.6
        ]
    },
    "6OQYV_0": {
        "text": "person turning the light off.",
        "vid": "6OQYV",
        "timestamps": [
            10.8,
            16.0
        ]
    },
    "6OQYV_1": {
        "text": "a person runs into the laundry room.",
        "vid": "6OQYV",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "6OQYV_2": {
        "text": "person runs back out.",
        "vid": "6OQYV",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "6OQYV_3": {
        "text": "a person is adding clothes to a washing machine.",
        "vid": "6OQYV",
        "timestamps": [
            5.5,
            13.2
        ]
    },
    "6OQYV_4": {
        "text": "person wards they open a cabinet.",
        "vid": "6OQYV",
        "timestamps": [
            5.3,
            12.2
        ]
    },
    "CEZ4D_0": {
        "text": "a person is undressing under a blanket.",
        "vid": "CEZ4D",
        "timestamps": [
            17.9,
            27.2
        ]
    },
    "CEZ4D_1": {
        "text": "person holding a broom on the stairs.",
        "vid": "CEZ4D",
        "timestamps": [
            27.8,
            35.0
        ]
    },
    "F75LG_0": {
        "text": "person they start drinking from a glass of water.",
        "vid": "F75LG",
        "timestamps": [
            17.1,
            26.3
        ]
    },
    "AYSTI_0": {
        "text": "a person sits in a semi-reclining position on a bed.",
        "vid": "AYSTI",
        "timestamps": [
            17.7,
            31.0
        ]
    },
    "FQGW4_0": {
        "text": "person put the cup.",
        "vid": "FQGW4",
        "timestamps": [
            5.4,
            10.2
        ]
    },
    "FQGW4_1": {
        "text": "person they begin carefully pouring the beverage into the cup.",
        "vid": "FQGW4",
        "timestamps": [
            10.6,
            17.9
        ]
    },
    "FQGW4_2": {
        "text": "person pouring a glass of milk.",
        "vid": "FQGW4",
        "timestamps": [
            10.6,
            17.9
        ]
    },
    "FQGW4_3": {
        "text": "person watch television.",
        "vid": "FQGW4",
        "timestamps": [
            17.1,
            23.0
        ]
    },
    "FQGW4_4": {
        "text": "person sits down in a chair to watch tv.",
        "vid": "FQGW4",
        "timestamps": [
            19.9,
            25.4
        ]
    },
    "FQGW4_5": {
        "text": "person pours a glass of milk.",
        "vid": "FQGW4",
        "timestamps": [
            10.6,
            17.9
        ]
    },
    "FQGW4_6": {
        "text": "person sits down in a chair to take a drink.",
        "vid": "FQGW4",
        "timestamps": [
            19.9,
            25.4
        ]
    },
    "HH1R7_0": {
        "text": "person starts sneezing furiously.",
        "vid": "HH1R7",
        "timestamps": [
            14.5,
            26.2
        ]
    },
    "0PVKV_0": {
        "text": "person wards they take a bite of their sandwich.",
        "vid": "0PVKV",
        "timestamps": [
            20.1,
            25.1
        ]
    },
    "0PVKV_1": {
        "text": "person begins eating it.",
        "vid": "0PVKV",
        "timestamps": [
            8.1,
            15.5
        ]
    },
    "0PVKV_2": {
        "text": "person takes a sandwich of the dresser.",
        "vid": "0PVKV",
        "timestamps": [
            20.1,
            25.1
        ]
    },
    "0PVKV_3": {
        "text": "person starts eating it.",
        "vid": "0PVKV",
        "timestamps": [
            8.1,
            15.5
        ]
    },
    "T42A2_0": {
        "text": "person walking across the room to open a cabinet door.",
        "vid": "T42A2",
        "timestamps": [
            23.7,
            30.5
        ]
    },
    "W8P6Q_0": {
        "text": "person sits in a chair.",
        "vid": "W8P6Q",
        "timestamps": [
            0.4,
            15.4
        ]
    },
    "W8P6Q_1": {
        "text": "the person sits in a chair.",
        "vid": "W8P6Q",
        "timestamps": [
            0.4,
            15.4
        ]
    },
    "QF1Y0_0": {
        "text": "another person opens the door.",
        "vid": "QF1Y0",
        "timestamps": [
            10.4,
            18.7
        ]
    },
    "QF1Y0_1": {
        "text": "person is opening door with bag.",
        "vid": "QF1Y0",
        "timestamps": [
            10.4,
            18.7
        ]
    },
    "QF1Y0_2": {
        "text": "person holding a bag.",
        "vid": "QF1Y0",
        "timestamps": [
            13.1,
            24.7
        ]
    },
    "0DD62_0": {
        "text": "the person looks back down at the picture.",
        "vid": "0DD62",
        "timestamps": [
            0.0,
            7.9
        ]
    },
    "LCA0Q_0": {
        "text": "person they put their laptop next to the sink.",
        "vid": "LCA0Q",
        "timestamps": [
            7.5,
            12.1
        ]
    },
    "TU9K1_0": {
        "text": "person close the closet door.",
        "vid": "TU9K1",
        "timestamps": [
            34.1,
            40.8
        ]
    },
    "TU9K1_1": {
        "text": "a person is sneezing into a mirror.",
        "vid": "TU9K1",
        "timestamps": [
            1.1,
            9.4
        ]
    },
    "TU9K1_2": {
        "text": "person tidying clothes.",
        "vid": "TU9K1",
        "timestamps": [
            15.9,
            35.4
        ]
    },
    "EK5K1_0": {
        "text": "the person takes a lollipop from a box.",
        "vid": "EK5K1",
        "timestamps": [
            19.5,
            36.4
        ]
    },
    "EK5K1_1": {
        "text": "person start sneezing.",
        "vid": "EK5K1",
        "timestamps": [
            39.9,
            44.0
        ]
    },
    "EK5K1_2": {
        "text": "person opens a box.",
        "vid": "EK5K1",
        "timestamps": [
            21.2,
            36.8
        ]
    },
    "EDSUD_0": {
        "text": "a person throws their shoes on the hallway floor.",
        "vid": "EDSUD",
        "timestamps": [
            19.8,
            24.5
        ]
    },
    "7KW31_0": {
        "text": "person holding a broom.",
        "vid": "7KW31",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "G2QBV_0": {
        "text": "the person takes a water bottle.",
        "vid": "G2QBV",
        "timestamps": [
            15.5,
            20.2
        ]
    },
    "G2QBV_1": {
        "text": "a person throws a broom into the corner.",
        "vid": "G2QBV",
        "timestamps": [
            11.3,
            19.9
        ]
    },
    "G2QBV_2": {
        "text": "person closes a door.",
        "vid": "G2QBV",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "G2QBV_3": {
        "text": "person dust pan they close the door.",
        "vid": "G2QBV",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "G2QBV_4": {
        "text": "person throws the broom in a corner.",
        "vid": "G2QBV",
        "timestamps": [
            11.3,
            19.9
        ]
    },
    "G2QBV_5": {
        "text": "a person closes a front door.",
        "vid": "G2QBV",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "3IAPG_0": {
        "text": "person puts clothes in a bag.",
        "vid": "3IAPG",
        "timestamps": [
            24.5,
            27.0
        ]
    },
    "6B2FN_0": {
        "text": "person fixing his hair.",
        "vid": "6B2FN",
        "timestamps": [
            0.0,
            6.2
        ]
    },
    "6B2FN_1": {
        "text": "person smiling as they look in the mirror.",
        "vid": "6B2FN",
        "timestamps": [
            1.2,
            7.2
        ]
    },
    "MZ3I3_0": {
        "text": "person talking on their phone.",
        "vid": "MZ3I3",
        "timestamps": [
            17.8,
            31.2
        ]
    },
    "MZ3I3_1": {
        "text": "person drinks out of a cup.",
        "vid": "MZ3I3",
        "timestamps": [
            33.1,
            44.0
        ]
    },
    "MZ3I3_2": {
        "text": "person begins to undress.",
        "vid": "MZ3I3",
        "timestamps": [
            0.0,
            12.9
        ]
    },
    "MZ3I3_3": {
        "text": "person takes a drink from a cup.",
        "vid": "MZ3I3",
        "timestamps": [
            33.1,
            44.0
        ]
    },
    "MZ3I3_4": {
        "text": "person starts talking on the phone.",
        "vid": "MZ3I3",
        "timestamps": [
            17.8,
            31.2
        ]
    },
    "MZ3I3_5": {
        "text": "person talks on a cell phone.",
        "vid": "MZ3I3",
        "timestamps": [
            17.8,
            31.2
        ]
    },
    "MZ3I3_6": {
        "text": "a person is in the hallway undressing.",
        "vid": "MZ3I3",
        "timestamps": [
            0.0,
            12.9
        ]
    },
    "M6ERH_0": {
        "text": "person proceeds to eat out the jar just.",
        "vid": "M6ERH",
        "timestamps": [
            19.9,
            32.3
        ]
    },
    "V6H2O_0": {
        "text": "a smiling person runs into their garage holding a phone.",
        "vid": "V6H2O",
        "timestamps": [
            3.5,
            10.5
        ]
    },
    "V6H2O_1": {
        "text": "person drinks from a glass.",
        "vid": "V6H2O",
        "timestamps": [
            8.1,
            14.5
        ]
    },
    "V6H2O_2": {
        "text": "person open the door.",
        "vid": "V6H2O",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "C6INR_0": {
        "text": "person take a picture with a camera.",
        "vid": "C6INR",
        "timestamps": [
            14.2,
            19.4
        ]
    },
    "2U3X0_0": {
        "text": "a man is holding some food.",
        "vid": "2U3X0",
        "timestamps": [
            0.0,
            6.7
        ]
    },
    "2U3X0_1": {
        "text": "person brings a seat with him.",
        "vid": "2U3X0",
        "timestamps": [
            24.9,
            30.0
        ]
    },
    "2U3X0_2": {
        "text": "person turned on a light.",
        "vid": "2U3X0",
        "timestamps": [
            2.8,
            7.0
        ]
    },
    "2U3X0_3": {
        "text": "a person opened a door.",
        "vid": "2U3X0",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "2U3X0_4": {
        "text": "person began eating.",
        "vid": "2U3X0",
        "timestamps": [
            24.9,
            30.0
        ]
    },
    "14HG1_0": {
        "text": "person sits on the floor.",
        "vid": "14HG1",
        "timestamps": [
            16.1,
            21.7
        ]
    },
    "0A8CF_0": {
        "text": "person drinks from a glass of water.",
        "vid": "0A8CF",
        "timestamps": [
            25.5,
            33.0
        ]
    },
    "0A8CF_1": {
        "text": "person takes a glass from somewhere.",
        "vid": "0A8CF",
        "timestamps": [
            24.9,
            33.0
        ]
    },
    "QBUAT_0": {
        "text": "a person is undressing in the bedroom.",
        "vid": "QBUAT",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "QBUAT_1": {
        "text": "person begins dressing in pajamas.",
        "vid": "QBUAT",
        "timestamps": [
            17.7,
            30.3
        ]
    },
    "QBUAT_2": {
        "text": "the person takes a blanket from the cabinet.",
        "vid": "QBUAT",
        "timestamps": [
            8.6,
            15.8
        ]
    },
    "QBUAT_3": {
        "text": "person begins to undress.",
        "vid": "QBUAT",
        "timestamps": [
            0.0,
            9.7
        ]
    },
    "48XER_0": {
        "text": "the person closes the cabinet.",
        "vid": "48XER",
        "timestamps": [
            9.8,
            15.7
        ]
    },
    "48XER_1": {
        "text": "the person takes a towel from the counter.",
        "vid": "48XER",
        "timestamps": [
            12.3,
            16.9
        ]
    },
    "48XER_2": {
        "text": "a person begins tidying a cabinet.",
        "vid": "48XER",
        "timestamps": [
            0.0,
            15.0
        ]
    },
    "KK7D4_0": {
        "text": "a person opens a closet door.",
        "vid": "KK7D4",
        "timestamps": [
            0.0,
            6.0
        ]
    },
    "KK7D4_1": {
        "text": "a person takes a towel.",
        "vid": "KK7D4",
        "timestamps": [
            0.9,
            8.2
        ]
    },
    "KK7D4_2": {
        "text": "person takes out a towel.",
        "vid": "KK7D4",
        "timestamps": [
            0.9,
            8.2
        ]
    },
    "3LIGG_0": {
        "text": "a person puts a broom down.",
        "vid": "3LIGG",
        "timestamps": [
            3.5,
            10.6
        ]
    },
    "EJFUA_0": {
        "text": "person starts running around.",
        "vid": "EJFUA",
        "timestamps": [
            13.1,
            21.0
        ]
    },
    "EJFUA_1": {
        "text": "person runs into the living room.",
        "vid": "EJFUA",
        "timestamps": [
            13.1,
            21.0
        ]
    },
    "EJFUA_2": {
        "text": "person running in place.",
        "vid": "EJFUA",
        "timestamps": [
            13.1,
            21.0
        ]
    },
    "73ZXZ_0": {
        "text": "person closes the cabinet.",
        "vid": "73ZXZ",
        "timestamps": [
            7.5,
            12.8
        ]
    },
    "73ZXZ_1": {
        "text": "person closes the door.",
        "vid": "73ZXZ",
        "timestamps": [
            8.1,
            13.0
        ]
    },
    "73ZXZ_2": {
        "text": "person puts the food away.",
        "vid": "73ZXZ",
        "timestamps": [
            6.9,
            11.8
        ]
    },
    "73ZXZ_3": {
        "text": "the person starts closing the cabinet.",
        "vid": "73ZXZ",
        "timestamps": [
            7.5,
            12.8
        ]
    },
    "FAO7J_0": {
        "text": "person laughing on a laptop.",
        "vid": "FAO7J",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "FAO7J_1": {
        "text": "person turns the light off.",
        "vid": "FAO7J",
        "timestamps": [
            36.0,
            41.1
        ]
    },
    "FAO7J_2": {
        "text": "person closes the door.",
        "vid": "FAO7J",
        "timestamps": [
            37.3,
            43.6
        ]
    },
    "FAO7J_3": {
        "text": "person closing the door behind them.",
        "vid": "FAO7J",
        "timestamps": [
            37.3,
            43.6
        ]
    },
    "FAO7J_4": {
        "text": "person leave the closet turning the light off.",
        "vid": "FAO7J",
        "timestamps": [
            36.0,
            41.1
        ]
    },
    "FAO7J_5": {
        "text": "the person laughs at something on the laptop screen.",
        "vid": "FAO7J",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "COFJV_0": {
        "text": "the person eats food.",
        "vid": "COFJV",
        "timestamps": [
            8.6,
            17.5
        ]
    },
    "COFJV_1": {
        "text": "the person is opening a bag.",
        "vid": "COFJV",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "COFJV_2": {
        "text": "person starts eating a sandwich that was inside.",
        "vid": "COFJV",
        "timestamps": [
            8.7,
            17.5
        ]
    },
    "BD9UN_0": {
        "text": "another person is tidying some clothes.",
        "vid": "BD9UN",
        "timestamps": [
            17.4,
            29.6
        ]
    },
    "LPKPO_0": {
        "text": "person grabs a plate that is sitting on the table.",
        "vid": "LPKPO",
        "timestamps": [
            0.0,
            17.1
        ]
    },
    "LPKPO_1": {
        "text": "the person is sitting at the table.",
        "vid": "LPKPO",
        "timestamps": [
            0.0,
            17.1
        ]
    },
    "LPKPO_2": {
        "text": "a person sitting in a chair at a table.",
        "vid": "LPKPO",
        "timestamps": [
            0.0,
            17.1
        ]
    },
    "LD6TD_0": {
        "text": "person reading a book.",
        "vid": "LD6TD",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "LD6TD_1": {
        "text": "a person awakens in their dining room holding a book.",
        "vid": "LD6TD",
        "timestamps": [
            5.4,
            10.3
        ]
    },
    "QD1U7_0": {
        "text": "the person puts the sandwich on the table.",
        "vid": "QD1U7",
        "timestamps": [
            1.5,
            7.6
        ]
    },
    "LWRKS_0": {
        "text": "person turns a light on.",
        "vid": "LWRKS",
        "timestamps": [
            3.3,
            11.8
        ]
    },
    "S444Y_0": {
        "text": "person they take things from the bag.",
        "vid": "S444Y",
        "timestamps": [
            6.3,
            11.7
        ]
    },
    "ZSAQG_0": {
        "text": "a person run by with shoes in hand.",
        "vid": "ZSAQG",
        "timestamps": [
            4.0,
            12.5
        ]
    },
    "ZSAQG_1": {
        "text": "another person is running with shoes.",
        "vid": "ZSAQG",
        "timestamps": [
            4.0,
            12.5
        ]
    },
    "ZSAQG_2": {
        "text": "another person runs across the room with shoes.",
        "vid": "ZSAQG",
        "timestamps": [
            4.0,
            12.5
        ]
    },
    "FC2SK_0": {
        "text": "another person opens the door.",
        "vid": "FC2SK",
        "timestamps": [
            3.8,
            10.9
        ]
    },
    "FC2SK_1": {
        "text": "person he sit on the chair.",
        "vid": "FC2SK",
        "timestamps": [
            17.5,
            28.0
        ]
    },
    "FC2SK_2": {
        "text": "person another awakens wrapped in a blanket.",
        "vid": "FC2SK",
        "timestamps": [
            5.8,
            12.9
        ]
    },
    "JKGTN_0": {
        "text": "a person takes a pillow from the shelf.",
        "vid": "JKGTN",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "JKGTN_1": {
        "text": "a person takes a  pillow of a shelf.",
        "vid": "JKGTN",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "JKGTN_2": {
        "text": "a person takes a pillow down from a shelf.",
        "vid": "JKGTN",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "0LDN3_0": {
        "text": "a person runs into the kitchen.",
        "vid": "0LDN3",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "0LDN3_1": {
        "text": "the person opens the refrigerator.",
        "vid": "0LDN3",
        "timestamps": [
            5.0,
            10.0
        ]
    },
    "0LDN3_2": {
        "text": "person opens the refrigerator.",
        "vid": "0LDN3",
        "timestamps": [
            5.0,
            10.0
        ]
    },
    "0LDN3_3": {
        "text": "person close the refrigerator.",
        "vid": "0LDN3",
        "timestamps": [
            10.0,
            15.0
        ]
    },
    "PJUM0_0": {
        "text": "person pours it into a glass.",
        "vid": "PJUM0",
        "timestamps": [
            9.6,
            21.6
        ]
    },
    "PJUM0_1": {
        "text": "person drinks from the glass.",
        "vid": "PJUM0",
        "timestamps": [
            19.5,
            29.2
        ]
    },
    "PJUM0_2": {
        "text": "person takes out a bottle of water.",
        "vid": "PJUM0",
        "timestamps": [
            1.7,
            9.2
        ]
    },
    "PJUM0_3": {
        "text": "person pours the contents into a glass.",
        "vid": "PJUM0",
        "timestamps": [
            9.6,
            21.6
        ]
    },
    "PJUM0_4": {
        "text": "a person opens a refrigerator.",
        "vid": "PJUM0",
        "timestamps": [
            0.0,
            6.1
        ]
    },
    "1TZK5_0": {
        "text": "one person stands by the window eating food.",
        "vid": "1TZK5",
        "timestamps": [
            5.7,
            11.4
        ]
    },
    "83S5W_0": {
        "text": "person closes the door behind them.",
        "vid": "83S5W",
        "timestamps": [
            5.8,
            12.4
        ]
    },
    "TFWNO_0": {
        "text": "person throwing a towel on the floor.",
        "vid": "TFWNO",
        "timestamps": [
            19.5,
            25.0
        ]
    },
    "TFWNO_1": {
        "text": "person eats some food.",
        "vid": "TFWNO",
        "timestamps": [
            11.7,
            22.6
        ]
    },
    "TFWNO_2": {
        "text": "person eating food from a plate with a fork.",
        "vid": "TFWNO",
        "timestamps": [
            11.7,
            22.6
        ]
    },
    "TFWNO_3": {
        "text": "person they start eating some food.",
        "vid": "TFWNO",
        "timestamps": [
            11.7,
            22.6
        ]
    },
    "TFWNO_4": {
        "text": "person eats from it.",
        "vid": "TFWNO",
        "timestamps": [
            11.7,
            22.6
        ]
    },
    "C6V75_0": {
        "text": "person opens the door.",
        "vid": "C6V75",
        "timestamps": [
            26.5,
            32.7
        ]
    },
    "BRBWJ_0": {
        "text": "the person puts their clothes on the shelf as well.",
        "vid": "BRBWJ",
        "timestamps": [
            1.9,
            6.4
        ]
    },
    "3OZUX_0": {
        "text": "person #1 was washing a mirror on the wall.",
        "vid": "3OZUX",
        "timestamps": [
            1.1,
            11.4
        ]
    },
    "X11CU_0": {
        "text": "person stands by the window looking out.",
        "vid": "X11CU",
        "timestamps": [
            4.0,
            13.4
        ]
    },
    "X11CU_1": {
        "text": "person another holding medicine opens a window.",
        "vid": "X11CU",
        "timestamps": [
            3.2,
            13.2
        ]
    },
    "BRQBD_0": {
        "text": "a person awakens in a bedroom.",
        "vid": "BRQBD",
        "timestamps": [
            0.1,
            8.4
        ]
    },
    "BRQBD_1": {
        "text": "the person puts the picture away.",
        "vid": "BRQBD",
        "timestamps": [
            27.2,
            33.7
        ]
    },
    "7614L_0": {
        "text": "person hold the broom between the their legs.",
        "vid": "7614L",
        "timestamps": [
            14.6,
            27.0
        ]
    },
    "7614L_1": {
        "text": "the person puts the broom down.",
        "vid": "7614L",
        "timestamps": [
            0.0,
            5.4
        ]
    },
    "ON2Z4_0": {
        "text": "person they take out a blanket.",
        "vid": "ON2Z4",
        "timestamps": [
            8.4,
            16.3
        ]
    },
    "ON2Z4_1": {
        "text": "person opens it  they trun the light on.",
        "vid": "ON2Z4",
        "timestamps": [
            6.9,
            12.0
        ]
    },
    "ON2Z4_2": {
        "text": "person takes a blanket.",
        "vid": "ON2Z4",
        "timestamps": [
            8.4,
            16.3
        ]
    },
    "ON2Z4_3": {
        "text": "a person opens the door to the closet.",
        "vid": "ON2Z4",
        "timestamps": [
            1.0,
            8.3
        ]
    },
    "HQ8K2_0": {
        "text": "person start sneezing as they reach for some dishes.",
        "vid": "HQ8K2",
        "timestamps": [
            2.8,
            9.9
        ]
    },
    "4VX01_0": {
        "text": "person they stand up.",
        "vid": "4VX01",
        "timestamps": [
            3.3,
            10.5
        ]
    },
    "4VX01_1": {
        "text": "person closes the door.",
        "vid": "4VX01",
        "timestamps": [
            24.1,
            31.0
        ]
    },
    "4VX01_2": {
        "text": "a person sits on the bathroom floor.",
        "vid": "4VX01",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "4VX01_3": {
        "text": "a person sits down on the floor.",
        "vid": "4VX01",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "3Q92U_0": {
        "text": "a person takes a pillow.",
        "vid": "3Q92U",
        "timestamps": [
            1.0,
            5.8
        ]
    },
    "4WVTC_0": {
        "text": "the person is holding a laptop.",
        "vid": "4WVTC",
        "timestamps": [
            0.0,
            7.1
        ]
    },
    "4WVTC_1": {
        "text": "person their laptop they close their laptop.",
        "vid": "4WVTC",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "4WVTC_2": {
        "text": "person towel in hand put laptop down.",
        "vid": "4WVTC",
        "timestamps": [
            2.5,
            10.1
        ]
    },
    "4TX4N_0": {
        "text": "another person is snuggling on a sofa eating a sandwich.",
        "vid": "4TX4N",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "4TX4N_1": {
        "text": "person eating a sandwich.",
        "vid": "4TX4N",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "4TX4N_2": {
        "text": "a person is sitting in a chair eating a sandwich.",
        "vid": "4TX4N",
        "timestamps": [
            0.0,
            6.8
        ]
    },
    "4TX4N_3": {
        "text": "a person is awakening in the bed.",
        "vid": "4TX4N",
        "timestamps": [
            14.4,
            28.2
        ]
    },
    "999BP_0": {
        "text": "person a girl takes a bag.",
        "vid": "999BP",
        "timestamps": [
            2.1,
            7.7
        ]
    },
    "999BP_1": {
        "text": "person puts it on the table.",
        "vid": "999BP",
        "timestamps": [
            24.4,
            31.2
        ]
    },
    "AFUBX_0": {
        "text": "a person is walking through a doorway.",
        "vid": "AFUBX",
        "timestamps": [
            7.6,
            14.2
        ]
    },
    "AFUBX_1": {
        "text": "person turns off a light.",
        "vid": "AFUBX",
        "timestamps": [
            18.8,
            23.3
        ]
    },
    "AFUBX_2": {
        "text": "person the shuts the light off.",
        "vid": "AFUBX",
        "timestamps": [
            18.8,
            23.3
        ]
    },
    "AFUBX_3": {
        "text": "person turning off the light behind them.",
        "vid": "AFUBX",
        "timestamps": [
            18.8,
            23.3
        ]
    },
    "O8T6G_0": {
        "text": "a person is smiling.",
        "vid": "O8T6G",
        "timestamps": [
            3.1,
            18.8
        ]
    },
    "O8T6G_1": {
        "text": "person trying to open medicine from a bag.",
        "vid": "O8T6G",
        "timestamps": [
            0.0,
            10.6
        ]
    },
    "O8T6G_2": {
        "text": "person sitting in a chair opening up a bag.",
        "vid": "O8T6G",
        "timestamps": [
            0.0,
            10.6
        ]
    },
    "NHH8N_0": {
        "text": "person sits on a bed.",
        "vid": "NHH8N",
        "timestamps": [
            4.7,
            13.8
        ]
    },
    "7R0LB_0": {
        "text": "a person is putting away dishes into a cabinet.",
        "vid": "7R0LB",
        "timestamps": [
            10.7,
            18.2
        ]
    },
    "7R0LB_1": {
        "text": "person sneezing on it.",
        "vid": "7R0LB",
        "timestamps": [
            6.5,
            11.0
        ]
    },
    "7R0LB_2": {
        "text": "person puts the food in the cabinet.",
        "vid": "7R0LB",
        "timestamps": [
            8.2,
            19.1
        ]
    },
    "RON2M_0": {
        "text": "person leaves the closet holding the bag.",
        "vid": "RON2M",
        "timestamps": [
            5.0,
            17.9
        ]
    },
    "RON2M_1": {
        "text": "one person puts a book.",
        "vid": "RON2M",
        "timestamps": [
            7.8,
            15.6
        ]
    },
    "RON2M_2": {
        "text": "a person wearing a blue sweater opens a coat closet.",
        "vid": "RON2M",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "DOYQE_0": {
        "text": "the person stops cooking to drink from a cup.",
        "vid": "DOYQE",
        "timestamps": [
            19.2,
            28.4
        ]
    },
    "DOYQE_1": {
        "text": "person they look at a picture.",
        "vid": "DOYQE",
        "timestamps": [
            22.8,
            37.0
        ]
    },
    "DOYQE_2": {
        "text": "person takes a drink from a coffee cup.",
        "vid": "DOYQE",
        "timestamps": [
            16.9,
            22.3
        ]
    },
    "3VWSP_0": {
        "text": "person they stand up.",
        "vid": "3VWSP",
        "timestamps": [
            24.6,
            30.0
        ]
    },
    "ZPRJH_0": {
        "text": "a person is sitting on a floor.",
        "vid": "ZPRJH",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "ZPRJH_1": {
        "text": "person throws the book down.",
        "vid": "ZPRJH",
        "timestamps": [
            12.4,
            18.4
        ]
    },
    "ZPRJH_2": {
        "text": "person looking at various books on a shelf.",
        "vid": "ZPRJH",
        "timestamps": [
            8.5,
            17.0
        ]
    },
    "ZPRJH_3": {
        "text": "a person is looking at a book.",
        "vid": "ZPRJH",
        "timestamps": [
            8.5,
            17.0
        ]
    },
    "ZPRJH_4": {
        "text": "person a guy stands up from sitting on the floor.",
        "vid": "ZPRJH",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "WEW2E_0": {
        "text": "person takes a blanket out of a bag.",
        "vid": "WEW2E",
        "timestamps": [
            1.5,
            5.8
        ]
    },
    "WEW2E_1": {
        "text": "a person walks in the entryway holding a bag.",
        "vid": "WEW2E",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "K5NFS_0": {
        "text": "person puts the white pillow on the bed.",
        "vid": "K5NFS",
        "timestamps": [
            2.7,
            9.4
        ]
    },
    "K5NFS_1": {
        "text": "person throws their pillow aside.",
        "vid": "K5NFS",
        "timestamps": [
            2.9,
            10.2
        ]
    },
    "K5NFS_2": {
        "text": "a person awakens on the floor of their study.",
        "vid": "K5NFS",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "K5NFS_3": {
        "text": "the person begins tidying their clothes.",
        "vid": "K5NFS",
        "timestamps": [
            9.9,
            15.4
        ]
    },
    "4ZJXR_0": {
        "text": "the same person opens a bag.",
        "vid": "4ZJXR",
        "timestamps": [
            2.4,
            10.6
        ]
    },
    "44PFW_0": {
        "text": "a person is opening the doorknob.",
        "vid": "44PFW",
        "timestamps": [
            17.6,
            24.2
        ]
    },
    "44PFW_1": {
        "text": "that same person opens a door.",
        "vid": "44PFW",
        "timestamps": [
            17.6,
            24.2
        ]
    },
    "44PFW_2": {
        "text": "person opens a door.",
        "vid": "44PFW",
        "timestamps": [
            17.6,
            24.2
        ]
    },
    "TTVN5_0": {
        "text": "a person is holding a camera.",
        "vid": "TTVN5",
        "timestamps": [
            0.0,
            13.5
        ]
    },
    "TTVN5_1": {
        "text": "the person begins smiling.",
        "vid": "TTVN5",
        "timestamps": [
            22.7,
            34.0
        ]
    },
    "TTVN5_2": {
        "text": "a person is playing on their phone.",
        "vid": "TTVN5",
        "timestamps": [
            0.0,
            13.2
        ]
    },
    "WKVWF_0": {
        "text": "person holding a cup of water than drinks from it.",
        "vid": "WKVWF",
        "timestamps": [
            2.4,
            9.6
        ]
    },
    "WKVWF_1": {
        "text": "a person throws a book onto the sofa.",
        "vid": "WKVWF",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "WKVWF_2": {
        "text": "person a girl throws a book onto a couch.",
        "vid": "WKVWF",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "WKVWF_3": {
        "text": "the person takes a drink from a cup of coffee.",
        "vid": "WKVWF",
        "timestamps": [
            2.4,
            9.6
        ]
    },
    "WKVWF_4": {
        "text": "person takes things out of a box.",
        "vid": "WKVWF",
        "timestamps": [
            19.7,
            30.0
        ]
    },
    "HBL9L_0": {
        "text": "a person is sitting on the stairs eating a sandwich.",
        "vid": "HBL9L",
        "timestamps": [
            1.9,
            8.8
        ]
    },
    "HBL9L_1": {
        "text": "person eating a sandwich.",
        "vid": "HBL9L",
        "timestamps": [
            1.9,
            8.8
        ]
    },
    "Z0DO7_0": {
        "text": "person puts the cup down.",
        "vid": "Z0DO7",
        "timestamps": [
            20.1,
            24.7
        ]
    },
    "LQ0FJ_0": {
        "text": "person get dressed into something else.",
        "vid": "LQ0FJ",
        "timestamps": [
            23.6,
            34.0
        ]
    },
    "LQ0FJ_1": {
        "text": "person they start undressing.",
        "vid": "LQ0FJ",
        "timestamps": [
            23.6,
            34.0
        ]
    },
    "GQ341_0": {
        "text": "person pours a cup of coffee.",
        "vid": "GQ341",
        "timestamps": [
            0.8,
            5.2
        ]
    },
    "GQ341_1": {
        "text": "laughs as the person looks at photos loaded onto it.",
        "vid": "GQ341",
        "timestamps": [
            6.0,
            14.1
        ]
    },
    "GQ341_2": {
        "text": "the person pours a cup of coffee.",
        "vid": "GQ341",
        "timestamps": [
            0.8,
            5.2
        ]
    },
    "PH5VU_0": {
        "text": "a person is putting on clothes.",
        "vid": "PH5VU",
        "timestamps": [
            18.7,
            28.0
        ]
    },
    "PH5VU_1": {
        "text": "person closes a cabinet.",
        "vid": "PH5VU",
        "timestamps": [
            27.9,
            33.5
        ]
    },
    "PH5VU_2": {
        "text": "next the person closes the doors to the wardrobe.",
        "vid": "PH5VU",
        "timestamps": [
            28.3,
            33.9
        ]
    },
    "6E8GP_0": {
        "text": "person opens a closet.",
        "vid": "6E8GP",
        "timestamps": [
            10.8,
            18.3
        ]
    },
    "6E8GP_1": {
        "text": "the person is opening a box.",
        "vid": "6E8GP",
        "timestamps": [
            1.6,
            8.4
        ]
    },
    "6E8GP_2": {
        "text": "person they open up their closet.",
        "vid": "6E8GP",
        "timestamps": [
            10.8,
            18.3
        ]
    },
    "U5T4M_0": {
        "text": "person walked over to a chair to sit down.",
        "vid": "U5T4M",
        "timestamps": [
            12.4,
            21.0
        ]
    },
    "U5T4M_1": {
        "text": "person sits in a chair.",
        "vid": "U5T4M",
        "timestamps": [
            12.4,
            21.0
        ]
    },
    "U5T4M_2": {
        "text": "person opens refrigerator grabs milk.",
        "vid": "U5T4M",
        "timestamps": [
            0.0,
            3.1
        ]
    },
    "U5T4M_3": {
        "text": "person starts eating it.",
        "vid": "U5T4M",
        "timestamps": [
            11.7,
            21.0
        ]
    },
    "U5T4M_4": {
        "text": "a person opened a refrigerator.",
        "vid": "U5T4M",
        "timestamps": [
            0.0,
            3.1
        ]
    },
    "U5T4M_5": {
        "text": "person closed the refrigerator door.",
        "vid": "U5T4M",
        "timestamps": [
            8.9,
            14.1
        ]
    },
    "U5T4M_6": {
        "text": "person eats it.",
        "vid": "U5T4M",
        "timestamps": [
            11.7,
            21.0
        ]
    },
    "EYZXC_0": {
        "text": "person pours a cup of coffee.",
        "vid": "EYZXC",
        "timestamps": [
            8.9,
            23.2
        ]
    },
    "EYZXC_1": {
        "text": "a person sits at a table.",
        "vid": "EYZXC",
        "timestamps": [
            6.4,
            11.1
        ]
    },
    "EYZXC_2": {
        "text": "person snuggling a blanket.",
        "vid": "EYZXC",
        "timestamps": [
            20.3,
            32.3
        ]
    },
    "ONMCW_0": {
        "text": "person holding the glass.",
        "vid": "ONMCW",
        "timestamps": [
            21.7,
            36.0
        ]
    },
    "ONMCW_1": {
        "text": "person takes a glass from the desk.",
        "vid": "ONMCW",
        "timestamps": [
            21.4,
            27.5
        ]
    },
    "WXXYY_0": {
        "text": "person sits on the floor.",
        "vid": "WXXYY",
        "timestamps": [
            28.0,
            36.0
        ]
    },
    "WXXYY_1": {
        "text": "person begins playing with their phone.",
        "vid": "WXXYY",
        "timestamps": [
            7.0,
            19.3
        ]
    },
    "WXXYY_2": {
        "text": "person plays on his phone.",
        "vid": "WXXYY",
        "timestamps": [
            7.0,
            19.3
        ]
    },
    "WXXYY_3": {
        "text": "person begins to play on his phone.",
        "vid": "WXXYY",
        "timestamps": [
            7.0,
            19.3
        ]
    },
    "WXXYY_4": {
        "text": "person closes the door.",
        "vid": "WXXYY",
        "timestamps": [
            4.4,
            11.4
        ]
    },
    "WXXYY_5": {
        "text": "person fixes the doorknob.",
        "vid": "WXXYY",
        "timestamps": [
            28.4,
            36.0
        ]
    },
    "WXXYY_6": {
        "text": "person start fixing the doorknob.",
        "vid": "WXXYY",
        "timestamps": [
            28.4,
            36.0
        ]
    },
    "1B9DK_0": {
        "text": "person the one holding a bag just watches.",
        "vid": "1B9DK",
        "timestamps": [
            1.6,
            8.2
        ]
    },
    "1B9DK_1": {
        "text": "a second person runs in sees themselves in the mirror.",
        "vid": "1B9DK",
        "timestamps": [
            1.3,
            7.7
        ]
    },
    "1B9DK_2": {
        "text": "a person opens door.",
        "vid": "1B9DK",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "PN1F2_0": {
        "text": "person walking around drinking from glass.",
        "vid": "PN1F2",
        "timestamps": [
            5.2,
            17.1
        ]
    },
    "PN1F2_1": {
        "text": "person is holding pillow.",
        "vid": "PN1F2",
        "timestamps": [
            2.1,
            17.3
        ]
    },
    "PN1F2_2": {
        "text": "the person walked slowly down the hall holding a pillow.",
        "vid": "PN1F2",
        "timestamps": [
            2.1,
            17.3
        ]
    },
    "PN1F2_3": {
        "text": "person holding a pillow.",
        "vid": "PN1F2",
        "timestamps": [
            2.1,
            17.3
        ]
    },
    "0F7LW_0": {
        "text": "person opens a closet door.",
        "vid": "0F7LW",
        "timestamps": [
            0.8,
            8.1
        ]
    },
    "0F7LW_1": {
        "text": "person takes down a toy laptop.",
        "vid": "0F7LW",
        "timestamps": [
            12.6,
            19.5
        ]
    },
    "0F7LW_2": {
        "text": "person turns off the light.",
        "vid": "0F7LW",
        "timestamps": [
            25.0,
            31.0
        ]
    },
    "0F7LW_3": {
        "text": "person turning off the light behind them.",
        "vid": "0F7LW",
        "timestamps": [
            25.0,
            31.0
        ]
    },
    "0F7LW_4": {
        "text": "a person takes a laptop from a closet shelf.",
        "vid": "0F7LW",
        "timestamps": [
            12.6,
            19.5
        ]
    },
    "0F7LW_5": {
        "text": "a person runs into the closet.",
        "vid": "0F7LW",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "0F7LW_6": {
        "text": "person takes a laptop from the shelf.",
        "vid": "0F7LW",
        "timestamps": [
            12.6,
            19.5
        ]
    },
    "AKU63_0": {
        "text": "a person lies sleeping on a bed.",
        "vid": "AKU63",
        "timestamps": [
            0.6,
            10.7
        ]
    },
    "XYJYK_0": {
        "text": "the person puts a towel around themself.",
        "vid": "XYJYK",
        "timestamps": [
            25.3,
            33.5
        ]
    },
    "3VH9O_0": {
        "text": "person eating snack food.",
        "vid": "3VH9O",
        "timestamps": [
            5.7,
            14.7
        ]
    },
    "3VH9O_1": {
        "text": "a person is laughing at the book.",
        "vid": "3VH9O",
        "timestamps": [
            3.3,
            7.9
        ]
    },
    "3VH9O_2": {
        "text": "person eating from a box.",
        "vid": "3VH9O",
        "timestamps": [
            5.7,
            14.7
        ]
    },
    "3VH9O_3": {
        "text": "person eating a snack out of a box.",
        "vid": "3VH9O",
        "timestamps": [
            5.7,
            14.7
        ]
    },
    "0J1BT_0": {
        "text": "the person throws their clothes on the shelf.",
        "vid": "0J1BT",
        "timestamps": [
            9.5,
            15.2
        ]
    },
    "7R44Z_0": {
        "text": "a person is putting clothes into a laundry machine.",
        "vid": "7R44Z",
        "timestamps": [
            4.9,
            11.0
        ]
    },
    "7R44Z_1": {
        "text": "a person is putting clothes in a washing machine.",
        "vid": "7R44Z",
        "timestamps": [
            4.9,
            11.0
        ]
    },
    "E8JEJ_0": {
        "text": "person they open the door multiple times.",
        "vid": "E8JEJ",
        "timestamps": [
            0.0,
            3.4
        ]
    },
    "E8JEJ_1": {
        "text": "person throw something to the floor.",
        "vid": "E8JEJ",
        "timestamps": [
            16.2,
            22.7
        ]
    },
    "E8JEJ_2": {
        "text": "person closes a door.",
        "vid": "E8JEJ",
        "timestamps": [
            4.5,
            9.3
        ]
    },
    "D8FTI_0": {
        "text": "person opens a cabinet.",
        "vid": "D8FTI",
        "timestamps": [
            1.4,
            7.0
        ]
    },
    "D8FTI_1": {
        "text": "person open a cabinet.",
        "vid": "D8FTI",
        "timestamps": [
            1.4,
            7.0
        ]
    },
    "0HR01_0": {
        "text": "a person opens a pantry door.",
        "vid": "0HR01",
        "timestamps": [
            1.0,
            13.7
        ]
    },
    "4RT06_0": {
        "text": "person takes out some food.",
        "vid": "4RT06",
        "timestamps": [
            4.8,
            12.0
        ]
    },
    "4RT06_1": {
        "text": "person turns on the light.",
        "vid": "4RT06",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "4RT06_2": {
        "text": "person turns on the lights.",
        "vid": "4RT06",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "4RT06_3": {
        "text": "person opens a refrigerator.",
        "vid": "4RT06",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "4RT06_4": {
        "text": "person opens the refrigerator.",
        "vid": "4RT06",
        "timestamps": [
            0.0,
            2.6
        ]
    },
    "4RT06_5": {
        "text": "person takes out food.",
        "vid": "4RT06",
        "timestamps": [
            4.8,
            12.0
        ]
    },
    "4RT06_6": {
        "text": "a person turns on the light.",
        "vid": "4RT06",
        "timestamps": [
            0.0,
            4.3
        ]
    },
    "6FJBD_0": {
        "text": "person looking at a laptop computer.",
        "vid": "6FJBD",
        "timestamps": [
            9.4,
            15.6
        ]
    },
    "6FJBD_1": {
        "text": "the person puts down the laptop.",
        "vid": "6FJBD",
        "timestamps": [
            9.4,
            15.6
        ]
    },
    "S407A_0": {
        "text": "person pouring water into a glass.",
        "vid": "S407A",
        "timestamps": [
            13.2,
            21.4
        ]
    },
    "S407A_1": {
        "text": "person takes a drink from a bottle of water.",
        "vid": "S407A",
        "timestamps": [
            2.8,
            7.4
        ]
    },
    "S407A_2": {
        "text": "person pouring a glass of water.",
        "vid": "S407A",
        "timestamps": [
            13.2,
            21.4
        ]
    },
    "HP3HV_0": {
        "text": "person turns off their light.",
        "vid": "HP3HV",
        "timestamps": [
            14.3,
            18.6
        ]
    },
    "BLLCM_0": {
        "text": "a person sits in a chair watching television.",
        "vid": "BLLCM",
        "timestamps": [
            30.0,
            33.0
        ]
    },
    "5GP8M_0": {
        "text": "a person walking into a walk-in closet holding a phone.",
        "vid": "5GP8M",
        "timestamps": [
            0.0,
            12.7
        ]
    },
    "NO443_0": {
        "text": "person looks out the window.",
        "vid": "NO443",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "UPT25_0": {
        "text": "a person sits down on a couch.",
        "vid": "UPT25",
        "timestamps": [
            4.3,
            12.6
        ]
    },
    "UPT25_1": {
        "text": "person sit down on the sofa.",
        "vid": "UPT25",
        "timestamps": [
            4.3,
            12.6
        ]
    },
    "72M7T_0": {
        "text": "person runs in.",
        "vid": "72M7T",
        "timestamps": [
            4.0,
            9.0
        ]
    },
    "72M7T_1": {
        "text": "one person runs in.",
        "vid": "72M7T",
        "timestamps": [
            4.0,
            9.0
        ]
    },
    "72M7T_2": {
        "text": "open a mobile,then suddenly another person comes running.",
        "vid": "72M7T",
        "timestamps": [
            4.0,
            9.0
        ]
    },
    "72M7T_3": {
        "text": "the person is also playing with a phone.",
        "vid": "72M7T",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "72M7T_4": {
        "text": "person starts undressing.",
        "vid": "72M7T",
        "timestamps": [
            14.0,
            18.0
        ]
    },
    "SROEU_0": {
        "text": "person puts box in corner.",
        "vid": "SROEU",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "SROEU_1": {
        "text": "person open cabinet door.",
        "vid": "SROEU",
        "timestamps": [
            1.1,
            8.5
        ]
    },
    "SROEU_2": {
        "text": "person opens a cabinet door with a phone in hand.",
        "vid": "SROEU",
        "timestamps": [
            1.1,
            8.5
        ]
    },
    "SROEU_3": {
        "text": "a person puts a box in a doorway.",
        "vid": "SROEU",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "N9KNS_0": {
        "text": "one person is opening their bag.",
        "vid": "N9KNS",
        "timestamps": [
            5.8,
            18.7
        ]
    },
    "N9KNS_1": {
        "text": "one person is holding a bag.",
        "vid": "N9KNS",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "KQDX6_0": {
        "text": "person opens a door.",
        "vid": "KQDX6",
        "timestamps": [
            17.0,
            25.0
        ]
    },
    "KQDX6_1": {
        "text": "person another walks by drinking something out of a cup.",
        "vid": "KQDX6",
        "timestamps": [
            4.0,
            10.1
        ]
    },
    "KQDX6_2": {
        "text": "person slowly drinking a cup of coffee.",
        "vid": "KQDX6",
        "timestamps": [
            4.0,
            10.1
        ]
    },
    "7KHIH_0": {
        "text": "person start running out of the closet.",
        "vid": "7KHIH",
        "timestamps": [
            7.4,
            12.0
        ]
    },
    "GM3UK_0": {
        "text": "a person organizes a table by putting things away.",
        "vid": "GM3UK",
        "timestamps": [
            1.6,
            6.9
        ]
    },
    "GM3UK_1": {
        "text": "a person is putting a camera on a shelf.",
        "vid": "GM3UK",
        "timestamps": [
            18.4,
            24.0
        ]
    },
    "EXW9K_0": {
        "text": "person remember that they need to start cooking for dinner.",
        "vid": "EXW9K",
        "timestamps": [
            26.1,
            33.0
        ]
    },
    "RS6EK_0": {
        "text": "person laughing at the doorway.",
        "vid": "RS6EK",
        "timestamps": [
            6.5,
            15.7
        ]
    },
    "9VF2C_0": {
        "text": "the person quickly throws the blanket off of them.",
        "vid": "9VF2C",
        "timestamps": [
            14.5,
            19.5
        ]
    },
    "9VF2C_1": {
        "text": "person runs out.",
        "vid": "9VF2C",
        "timestamps": [
            16.5,
            21.8
        ]
    },
    "WSKTN_0": {
        "text": "person opens the cupboard door.",
        "vid": "WSKTN",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "32K2C_0": {
        "text": "person reaching to fix hair.",
        "vid": "32K2C",
        "timestamps": [
            11.9,
            20.5
        ]
    },
    "D6MZ4_0": {
        "text": "person takes a drink from a glass.",
        "vid": "D6MZ4",
        "timestamps": [
            0.7,
            10.2
        ]
    },
    "LG7WK_0": {
        "text": "a person laying on a floor.",
        "vid": "LG7WK",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "LG7WK_1": {
        "text": "person laying back down on the floor for a moment.",
        "vid": "LG7WK",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "LG7WK_2": {
        "text": "a person lays on a floor.",
        "vid": "LG7WK",
        "timestamps": [
            0.0,
            3.5
        ]
    },
    "5NG6Q_0": {
        "text": "person pours some more things into a cup.",
        "vid": "5NG6Q",
        "timestamps": [
            10.9,
            22.2
        ]
    },
    "5NG6Q_1": {
        "text": "person they finish cooking.",
        "vid": "5NG6Q",
        "timestamps": [
            10.5,
            14.9
        ]
    },
    "5NG6Q_2": {
        "text": "the person is cooking on the stove.",
        "vid": "5NG6Q",
        "timestamps": [
            10.5,
            14.9
        ]
    },
    "MOTWW_0": {
        "text": "the person puts the sandwich back down.",
        "vid": "MOTWW",
        "timestamps": [
            3.5,
            7.8
        ]
    },
    "LLE9B_0": {
        "text": "person eating some food.",
        "vid": "LLE9B",
        "timestamps": [
            1.4,
            9.0
        ]
    },
    "LLE9B_1": {
        "text": "the person begins eating a cookie.",
        "vid": "LLE9B",
        "timestamps": [
            1.4,
            9.0
        ]
    },
    "LLE9B_2": {
        "text": "person closes a laptop screen.",
        "vid": "LLE9B",
        "timestamps": [
            14.3,
            22.4
        ]
    },
    "LLE9B_3": {
        "text": "person using a laptop computer.",
        "vid": "LLE9B",
        "timestamps": [
            19.3,
            24.8
        ]
    },
    "LLE9B_4": {
        "text": "person puts the laptop away.",
        "vid": "LLE9B",
        "timestamps": [
            19.3,
            24.8
        ]
    },
    "LLE9B_5": {
        "text": "person puts it on a shelf.",
        "vid": "LLE9B",
        "timestamps": [
            19.7,
            26.0
        ]
    },
    "WM2J7_0": {
        "text": "person he moves to a china cabinet to open it.",
        "vid": "WM2J7",
        "timestamps": [
            13.1,
            24.9
        ]
    },
    "WM2J7_1": {
        "text": "a person is washing a window.",
        "vid": "WM2J7",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "WM2J7_2": {
        "text": "person washing the window.",
        "vid": "WM2J7",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "WM2J7_3": {
        "text": "person start tidying a cabinet.",
        "vid": "WM2J7",
        "timestamps": [
            20.4,
            31.0
        ]
    },
    "WM2J7_4": {
        "text": "a person washes a window.",
        "vid": "WM2J7",
        "timestamps": [
            0.0,
            9.0
        ]
    },
    "GFJ98_0": {
        "text": "a person is putting a picture on a wall.",
        "vid": "GFJ98",
        "timestamps": [
            9.4,
            17.4
        ]
    },
    "UEVVN_0": {
        "text": "a person runs to the open window.",
        "vid": "UEVVN",
        "timestamps": [
            1.2,
            8.7
        ]
    },
    "1FX8Q_0": {
        "text": "one person opens a bag.",
        "vid": "1FX8Q",
        "timestamps": [
            0.0,
            5.9
        ]
    },
    "OWCJT_0": {
        "text": "person drinking from a glass.",
        "vid": "OWCJT",
        "timestamps": [
            7.6,
            11.9
        ]
    },
    "BVDIM_0": {
        "text": "person put the plate  down on the table.",
        "vid": "BVDIM",
        "timestamps": [
            22.6,
            29.2
        ]
    },
    "BVDIM_1": {
        "text": "the person puts the dishes onto a table.",
        "vid": "BVDIM",
        "timestamps": [
            22.6,
            29.2
        ]
    },
    "OKIVH_0": {
        "text": "a person is laughing in the mirror.",
        "vid": "OKIVH",
        "timestamps": [
            25.8,
            32.0
        ]
    },
    "OQ54Y_0": {
        "text": "person sit down at a table.",
        "vid": "OQ54Y",
        "timestamps": [
            26.6,
            31.1
        ]
    },
    "OQ54Y_1": {
        "text": "person walks over to the refrigerator open it up.",
        "vid": "OQ54Y",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "OQ54Y_2": {
        "text": "a person opens a refrigerator door.",
        "vid": "OQ54Y",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "OQ54Y_3": {
        "text": "person pours some juice into a glass.",
        "vid": "OQ54Y",
        "timestamps": [
            31.6,
            35.0
        ]
    },
    "OQ54Y_4": {
        "text": "person they pour the milk into a glass.",
        "vid": "OQ54Y",
        "timestamps": [
            31.6,
            35.0
        ]
    },
    "5I5E5_0": {
        "text": "the person takes a tissue from a tissue box.",
        "vid": "5I5E5",
        "timestamps": [
            2.6,
            8.4
        ]
    },
    "GS3M4_0": {
        "text": "person watching herself in the mirror.",
        "vid": "GS3M4",
        "timestamps": [
            0.9,
            7.9
        ]
    },
    "TYWHY_0": {
        "text": "person closes the cabinet.",
        "vid": "TYWHY",
        "timestamps": [
            7.6,
            14.2
        ]
    },
    "TYWHY_1": {
        "text": "person takes out a laptop computer.",
        "vid": "TYWHY",
        "timestamps": [
            11.3,
            16.6
        ]
    },
    "TYWHY_2": {
        "text": "a person runs into a room gets into a desk.",
        "vid": "TYWHY",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "TYWHY_3": {
        "text": "a person runs into their home office.",
        "vid": "TYWHY",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "TYWHY_4": {
        "text": "a person runs into the room.",
        "vid": "TYWHY",
        "timestamps": [
            0.0,
            5.0
        ]
    },
    "TYWHY_5": {
        "text": "person opens a cabinet.",
        "vid": "TYWHY",
        "timestamps": [
            1.2,
            9.2
        ]
    },
    "TYWHY_6": {
        "text": "person takes their laptop from inside.",
        "vid": "TYWHY",
        "timestamps": [
            5.4,
            13.0
        ]
    },
    "TYWHY_7": {
        "text": "a person takes a laptop from a drawer.",
        "vid": "TYWHY",
        "timestamps": [
            5.4,
            13.0
        ]
    },
    "TYWHY_8": {
        "text": "person takes a laptop out the open the laptop.",
        "vid": "TYWHY",
        "timestamps": [
            11.9,
            21.7
        ]
    },
    "TYWHY_9": {
        "text": "the person opens a cabinet.",
        "vid": "TYWHY",
        "timestamps": [
            1.2,
            9.2
        ]
    },
    "ZBBOO_0": {
        "text": "person drinking from a cup.",
        "vid": "ZBBOO",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "XF2ZM_0": {
        "text": "person begins undressing by taking their jacket off of them.",
        "vid": "XF2ZM",
        "timestamps": [
            0.9,
            14.6
        ]
    },
    "XF2ZM_1": {
        "text": "person where he begins to undress by removing his hoodie.",
        "vid": "XF2ZM",
        "timestamps": [
            0.9,
            14.6
        ]
    },
    "OGLCO_0": {
        "text": "person eating chips out of a bag.",
        "vid": "OGLCO",
        "timestamps": [
            4.2,
            14.0
        ]
    },
    "OGLCO_1": {
        "text": "person eats food from a bag.",
        "vid": "OGLCO",
        "timestamps": [
            4.2,
            14.0
        ]
    },
    "OGLCO_2": {
        "text": "this person eats food out of a bag.",
        "vid": "OGLCO",
        "timestamps": [
            4.2,
            14.0
        ]
    },
    "OGLCO_3": {
        "text": "a person is working on a laptop.",
        "vid": "OGLCO",
        "timestamps": [
            0.0,
            8.8
        ]
    },
    "DAA3F_0": {
        "text": "person begin to eat it.",
        "vid": "DAA3F",
        "timestamps": [
            24.8,
            29.3
        ]
    },
    "DAA3F_1": {
        "text": "a person is awakening in the bedroom by the window.",
        "vid": "DAA3F",
        "timestamps": [
            18.1,
            27.2
        ]
    },
    "DAA3F_2": {
        "text": "person began eating from it.",
        "vid": "DAA3F",
        "timestamps": [
            24.8,
            29.3
        ]
    },
    "DAA3F_3": {
        "text": "a person covered with a blanket awakens in bed.",
        "vid": "DAA3F",
        "timestamps": [
            18.1,
            27.2
        ]
    },
    "DAA3F_4": {
        "text": "person take some food.",
        "vid": "DAA3F",
        "timestamps": [
            11.5,
            17.4
        ]
    },
    "PRH15_0": {
        "text": "a person is putting away cans of food.",
        "vid": "PRH15",
        "timestamps": [
            1.8,
            7.1
        ]
    },
    "KOQGE_0": {
        "text": "another person comes running throwing open the door.",
        "vid": "KOQGE",
        "timestamps": [
            8.8,
            17.8
        ]
    },
    "6IL0C_0": {
        "text": "person putting books.",
        "vid": "6IL0C",
        "timestamps": [
            0.0,
            16.5
        ]
    },
    "6IL0C_1": {
        "text": "a person puts some books onto a desk.",
        "vid": "6IL0C",
        "timestamps": [
            0.0,
            16.5
        ]
    },
    "6IL0C_2": {
        "text": "person crouching on the floor to tidy her shoes.",
        "vid": "6IL0C",
        "timestamps": [
            14.6,
            25.1
        ]
    },
    "UYZKX_0": {
        "text": "this person opened up their closet.",
        "vid": "UYZKX",
        "timestamps": [
            3.9,
            10.2
        ]
    },
    "X07QW_0": {
        "text": "a person undresses by taking off a jacket.",
        "vid": "X07QW",
        "timestamps": [
            0.0,
            11.7
        ]
    },
    "X07QW_1": {
        "text": "person sits down on a couch.",
        "vid": "X07QW",
        "timestamps": [
            22.2,
            28.0
        ]
    },
    "X07QW_2": {
        "text": "next the person takes a blanket from a cabinet.",
        "vid": "X07QW",
        "timestamps": [
            11.7,
            19.8
        ]
    },
    "81VSN_0": {
        "text": "person walking through a doorway in the living room.",
        "vid": "81VSN",
        "timestamps": [
            21.3,
            39.3
        ]
    },
    "OE243_0": {
        "text": "the person puts a box in a room.",
        "vid": "OE243",
        "timestamps": [
            7.4,
            13.0
        ]
    },
    "OE243_1": {
        "text": "a person is walking up the stairs towards a doorway.",
        "vid": "OE243",
        "timestamps": [
            3.7,
            9.3
        ]
    },
    "OE243_2": {
        "text": "the person puts some shoes in a closet.",
        "vid": "OE243",
        "timestamps": [
            13.3,
            20.9
        ]
    },
    "OE243_3": {
        "text": "a person takes a box off some stairs.",
        "vid": "OE243",
        "timestamps": [
            0.0,
            3.9
        ]
    },
    "NX8X9_0": {
        "text": "person they take a broom.",
        "vid": "NX8X9",
        "timestamps": [
            19.6,
            26.3
        ]
    },
    "NX8X9_1": {
        "text": "person put it on a table.",
        "vid": "NX8X9",
        "timestamps": [
            17.1,
            23.6
        ]
    },
    "NX8X9_2": {
        "text": "person stand up.",
        "vid": "NX8X9",
        "timestamps": [
            20.5,
            26.3
        ]
    },
    "NX8X9_3": {
        "text": "person they close the book.",
        "vid": "NX8X9",
        "timestamps": [
            13.8,
            18.2
        ]
    },
    "LXLW4_0": {
        "text": "person drinks from a cup.",
        "vid": "LXLW4",
        "timestamps": [
            28.2,
            38.0
        ]
    },
    "3JCEI_0": {
        "text": "a person is smiling at their laptop.",
        "vid": "3JCEI",
        "timestamps": [
            0.3,
            9.4
        ]
    },
    "3JCEI_1": {
        "text": "a person is laughing.",
        "vid": "3JCEI",
        "timestamps": [
            0.3,
            9.4
        ]
    },
    "3JCEI_2": {
        "text": "person throw some clothes on the floor.",
        "vid": "3JCEI",
        "timestamps": [
            9.6,
            17.8
        ]
    },
    "3JCEI_3": {
        "text": "a person sits at a table laughing at a laptop.",
        "vid": "3JCEI",
        "timestamps": [
            0.3,
            9.4
        ]
    },
    "3JCEI_4": {
        "text": "person throws things on the floor from the table.",
        "vid": "3JCEI",
        "timestamps": [
            9.0,
            17.5
        ]
    },
    "QZZPS_0": {
        "text": "person sitting on the couch wearing a sweater.",
        "vid": "QZZPS",
        "timestamps": [
            0.0,
            12.8
        ]
    },
    "QZZPS_1": {
        "text": "a person is seen sitting on a couch.",
        "vid": "QZZPS",
        "timestamps": [
            0.0,
            12.8
        ]
    },
    "QZZPS_2": {
        "text": "person take some medicine.",
        "vid": "QZZPS",
        "timestamps": [
            8.0,
            12.8
        ]
    },
    "PSAVM_0": {
        "text": "person sneezing in front of the sink.",
        "vid": "PSAVM",
        "timestamps": [
            19.1,
            28.3
        ]
    },
    "PSAVM_1": {
        "text": "person atart sneezing.",
        "vid": "PSAVM",
        "timestamps": [
            19.1,
            28.3
        ]
    },
    "PSAVM_2": {
        "text": "a person is throwing a blanket in the hamper.",
        "vid": "PSAVM",
        "timestamps": [
            10.1,
            19.2
        ]
    },
    "PSAVM_3": {
        "text": "a person is washing his hands.",
        "vid": "PSAVM",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "PSAVM_4": {
        "text": "a person washes their hands in the sink.",
        "vid": "PSAVM",
        "timestamps": [
            0.0,
            6.6
        ]
    },
    "M6HAF_0": {
        "text": "person open the refrigerator door.",
        "vid": "M6HAF",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "M6HAF_1": {
        "text": "the person opens the refrigerator.",
        "vid": "M6HAF",
        "timestamps": [
            0.0,
            4.2
        ]
    },
    "HLB3J_0": {
        "text": "one person propped on a pillow awakens.",
        "vid": "HLB3J",
        "timestamps": [
            5.0,
            11.2
        ]
    },
    "0UPBN_0": {
        "text": "another person holds a box.",
        "vid": "0UPBN",
        "timestamps": [
            19.3,
            31.8
        ]
    },
    "0UPBN_1": {
        "text": "person lies down on a bed behind them.",
        "vid": "0UPBN",
        "timestamps": [
            19.6,
            34.0
        ]
    },
    "0UPBN_2": {
        "text": "person holding a box.",
        "vid": "0UPBN",
        "timestamps": [
            19.3,
            31.8
        ]
    },
    "NUW9G_0": {
        "text": "a person holding a plastic bag puts.",
        "vid": "NUW9G",
        "timestamps": [
            0.0,
            9.2
        ]
    },
    "QLFR5_0": {
        "text": "the person closes the book.",
        "vid": "QLFR5",
        "timestamps": [
            21.0,
            27.1
        ]
    },
    "5P284_0": {
        "text": "person looks out window.",
        "vid": "5P284",
        "timestamps": [
            20.5,
            33.0
        ]
    },
    "5P284_1": {
        "text": "person put phone down gets up.",
        "vid": "5P284",
        "timestamps": [
            19.9,
            25.1
        ]
    },
    "C1DK7_0": {
        "text": "person leaves closing door behind them.",
        "vid": "C1DK7",
        "timestamps": [
            22.5,
            28.0
        ]
    },
    "C1DK7_1": {
        "text": "person opens door.",
        "vid": "C1DK7",
        "timestamps": [
            20.6,
            25.9
        ]
    },
    "C1DK7_2": {
        "text": "person closing the door.",
        "vid": "C1DK7",
        "timestamps": [
            22.5,
            28.0
        ]
    },
    "C1DK7_3": {
        "text": "person opens a door.",
        "vid": "C1DK7",
        "timestamps": [
            20.6,
            25.9
        ]
    },
    "C1DK7_4": {
        "text": "a person leaves their phone on a closed laptop.",
        "vid": "C1DK7",
        "timestamps": [
            4.2,
            10.2
        ]
    },
    "STHIK_0": {
        "text": "person eventually running out of frame.",
        "vid": "STHIK",
        "timestamps": [
            1.3,
            9.0
        ]
    },
    "STHIK_1": {
        "text": "a person runs through the doorway.",
        "vid": "STHIK",
        "timestamps": [
            1.3,
            9.0
        ]
    },
    "STHIK_2": {
        "text": "person appearing to be eating it.",
        "vid": "STHIK",
        "timestamps": [
            4.1,
            8.4
        ]
    },
    "STHIK_3": {
        "text": "person drinking a cup of coffee.",
        "vid": "STHIK",
        "timestamps": [
            1.9,
            7.2
        ]
    },
    "STHIK_4": {
        "text": "person eating from a bag of food.",
        "vid": "STHIK",
        "timestamps": [
            4.1,
            8.4
        ]
    },
    "FB3ZG_0": {
        "text": "person takes a cup of coffee.",
        "vid": "FB3ZG",
        "timestamps": [
            4.5,
            9.2
        ]
    },
    "6CAZU_0": {
        "text": "person begins eating.",
        "vid": "6CAZU",
        "timestamps": [
            21.2,
            27.9
        ]
    },
    "6CAZU_1": {
        "text": "a person is sitting in a chair putting on shoes.",
        "vid": "6CAZU",
        "timestamps": [
            0.0,
            4.9
        ]
    },
    "75F82_0": {
        "text": "a person is sneezing into a phone.",
        "vid": "75F82",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "75F82_1": {
        "text": "a person is standing in a doorway sneezing.",
        "vid": "75F82",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "75F82_2": {
        "text": "person they are sneezing.",
        "vid": "75F82",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "75F82_3": {
        "text": "a person is standing in the door way sneezing.",
        "vid": "75F82",
        "timestamps": [
            0.0,
            9.4
        ]
    },
    "C4MUA_0": {
        "text": "a person walks in a doorway.",
        "vid": "C4MUA",
        "timestamps": [
            2.2,
            7.9
        ]
    },
    "M4FOP_0": {
        "text": "the person is putting away groceries.",
        "vid": "M4FOP",
        "timestamps": [
            6.2,
            11.3
        ]
    },
    "M4FOP_1": {
        "text": "a person puts stuff in a bag by the window.",
        "vid": "M4FOP",
        "timestamps": [
            5.4,
            10.0
        ]
    },
    "1VRH1_0": {
        "text": "person turn off a light.",
        "vid": "1VRH1",
        "timestamps": [
            22.8,
            31.0
        ]
    },
    "1VRH1_1": {
        "text": "person they throw the book on the floor.",
        "vid": "1VRH1",
        "timestamps": [
            12.4,
            18.7
        ]
    },
    "1VRH1_2": {
        "text": "person turn off the light on the bedside table.",
        "vid": "1VRH1",
        "timestamps": [
            22.8,
            31.0
        ]
    },
    "1VRH1_3": {
        "text": "person they throw the book.",
        "vid": "1VRH1",
        "timestamps": [
            12.4,
            18.7
        ]
    },
    "1VRH1_4": {
        "text": "person turn off the lights.",
        "vid": "1VRH1",
        "timestamps": [
            22.8,
            31.0
        ]
    },
    "1VRH1_5": {
        "text": "person shutting off the bedside light.",
        "vid": "1VRH1",
        "timestamps": [
            22.8,
            31.0
        ]
    },
    "9PXI9_0": {
        "text": "person stand up.",
        "vid": "9PXI9",
        "timestamps": [
            10.5,
            16.4
        ]
    },
    "UETQS_0": {
        "text": "person opens a laptop.",
        "vid": "UETQS",
        "timestamps": [
            1.4,
            11.2
        ]
    },
    "UETQS_1": {
        "text": "a person sits in a chair.",
        "vid": "UETQS",
        "timestamps": [
            0.0,
            11.3
        ]
    },
    "UETQS_2": {
        "text": "a person sits down at a table.",
        "vid": "UETQS",
        "timestamps": [
            0.0,
            12.6
        ]
    },
    "UETQS_3": {
        "text": "person cooking eggs on the stove.",
        "vid": "UETQS",
        "timestamps": [
            18.2,
            32.0
        ]
    },
    "UETQS_4": {
        "text": "a person is opening a laptop on a table.",
        "vid": "UETQS",
        "timestamps": [
            1.4,
            11.2
        ]
    },
    "5UNMN_0": {
        "text": "person sits in a chair at a desk.",
        "vid": "5UNMN",
        "timestamps": [
            7.3,
            13.0
        ]
    },
    "VJVHM_0": {
        "text": "a person turns on their lights.",
        "vid": "VJVHM",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "VJVHM_1": {
        "text": "the person turns on a light.",
        "vid": "VJVHM",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "AWN1C_0": {
        "text": "person they take a drink from a coffee cup.",
        "vid": "AWN1C",
        "timestamps": [
            27.0,
            39.0
        ]
    },
    "AWN1C_1": {
        "text": "person gets a drink from a red cup.",
        "vid": "AWN1C",
        "timestamps": [
            27.0,
            39.0
        ]
    },
    "AWN1C_2": {
        "text": "person takes a drink from a cup.",
        "vid": "AWN1C",
        "timestamps": [
            27.0,
            39.0
        ]
    },
    "3CLVI_0": {
        "text": "person opens the door.",
        "vid": "3CLVI",
        "timestamps": [
            16.3,
            22.3
        ]
    },
    "3CLVI_1": {
        "text": "person flicks the lightswitch on.",
        "vid": "3CLVI",
        "timestamps": [
            3.3,
            7.8
        ]
    },
    "3CLVI_2": {
        "text": "person the individual opens another nearby closet.",
        "vid": "3CLVI",
        "timestamps": [
            3.2,
            11.1
        ]
    },
    "CS7HY_0": {
        "text": "person they open a cabinet.",
        "vid": "CS7HY",
        "timestamps": [
            6.4,
            18.5
        ]
    },
    "CS7HY_1": {
        "text": "person puts the broom away.",
        "vid": "CS7HY",
        "timestamps": [
            4.5,
            9.1
        ]
    },
    "CS7HY_2": {
        "text": "a person is holding a broom.",
        "vid": "CS7HY",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "CS7HY_3": {
        "text": "a person walks into the kitchen holding a broom.",
        "vid": "CS7HY",
        "timestamps": [
            0.0,
            8.0
        ]
    },
    "CS7HY_4": {
        "text": "person open a cabinet.",
        "vid": "CS7HY",
        "timestamps": [
            6.4,
            18.5
        ]
    },
    "IAEGA_0": {
        "text": "person turns off the light.",
        "vid": "IAEGA",
        "timestamps": [
            16.0,
            19.0
        ]
    },
    "ZNQVC_0": {
        "text": "a person is tidying up the cabinet.",
        "vid": "ZNQVC",
        "timestamps": [
            0.0,
            15.4
        ]
    },
    "ZNQVC_1": {
        "text": "person closed the doors.",
        "vid": "ZNQVC",
        "timestamps": [
            8.9,
            15.9
        ]
    },
    "ZNQVC_2": {
        "text": "person takes off a pair of shoes.",
        "vid": "ZNQVC",
        "timestamps": [
            10.5,
            17.3
        ]
    },
    "ZNQVC_3": {
        "text": "the person begins to take their shoes off.",
        "vid": "ZNQVC",
        "timestamps": [
            10.5,
            17.3
        ]
    },
    "ZNQVC_4": {
        "text": "person closing the door.",
        "vid": "ZNQVC",
        "timestamps": [
            8.9,
            15.9
        ]
    },
    "ZNQVC_5": {
        "text": "person takes their shoes off.",
        "vid": "ZNQVC",
        "timestamps": [
            10.5,
            17.3
        ]
    },
    "47Y1V_0": {
        "text": "a person in the hallway holding a picture begins undressing.",
        "vid": "47Y1V",
        "timestamps": [
            1.7,
            15.6
        ]
    },
    "B0SV3_0": {
        "text": "a person walking into a closet turns on the light.",
        "vid": "B0SV3",
        "timestamps": [
            7.1,
            11.4
        ]
    },
    "B0SV3_1": {
        "text": "person drinks from a coffee cup.",
        "vid": "B0SV3",
        "timestamps": [
            18.9,
            32.0
        ]
    },
    "B0SV3_2": {
        "text": "person they pause to turn on the light.",
        "vid": "B0SV3",
        "timestamps": [
            7.1,
            11.4
        ]
    },
    "B0SV3_3": {
        "text": "person opens the doors.",
        "vid": "B0SV3",
        "timestamps": [
            2.2,
            9.1
        ]
    },
    "F1LTO_0": {
        "text": "person closes the cabinet.",
        "vid": "F1LTO",
        "timestamps": [
            19.1,
            28.2
        ]
    },
    "F1LTO_1": {
        "text": "a person opens the doors of an armoire.",
        "vid": "F1LTO",
        "timestamps": [
            0.5,
            8.7
        ]
    },
    "F1LTO_2": {
        "text": "person closes the doors.",
        "vid": "F1LTO",
        "timestamps": [
            20.6,
            26.9
        ]
    },
    "F1LTO_3": {
        "text": "person opens the doors.",
        "vid": "F1LTO",
        "timestamps": [
            0.5,
            8.7
        ]
    },
    "OSK3Y_0": {
        "text": "sneezing another person cooking on the stove.",
        "vid": "OSK3Y",
        "timestamps": [
            7.7,
            15.6
        ]
    },
    "DGHSW_0": {
        "text": "a person runs through the door.",
        "vid": "DGHSW",
        "timestamps": [
            13.1,
            19.6
        ]
    },
    "DGHSW_1": {
        "text": "a person runs down the stairs.",
        "vid": "DGHSW",
        "timestamps": [
            13.1,
            19.6
        ]
    },
    "DGHSW_2": {
        "text": "person quickly runs off.",
        "vid": "DGHSW",
        "timestamps": [
            13.1,
            19.6
        ]
    },
    "06LBQ_0": {
        "text": "person closes the top of the box.",
        "vid": "06LBQ",
        "timestamps": [
            21.6,
            26.6
        ]
    },
    "06LBQ_1": {
        "text": "a person is vacuuming the floor around an open box.",
        "vid": "06LBQ",
        "timestamps": [
            28.7,
            34.6
        ]
    },
    "ALJ7B_0": {
        "text": "person begins to drink the water from the glass.",
        "vid": "ALJ7B",
        "timestamps": [
            17.5,
            31.0
        ]
    },
    "ALJ7B_1": {
        "text": "person drinking a glass of water.",
        "vid": "ALJ7B",
        "timestamps": [
            17.5,
            31.0
        ]
    },
    "ALJ7B_2": {
        "text": "a person takes dishes off a shelf.",
        "vid": "ALJ7B",
        "timestamps": [
            2.1,
            9.8
        ]
    },
    "QZ1BS_0": {
        "text": "a person lying down awakens in the basement.",
        "vid": "QZ1BS",
        "timestamps": [
            0.0,
            12.8
        ]
    },
    "QZ1BS_1": {
        "text": "the person is laying on the floor.",
        "vid": "QZ1BS",
        "timestamps": [
            0.0,
            4.5
        ]
    },
    "Z7KC1_0": {
        "text": "person run from the room.",
        "vid": "Z7KC1",
        "timestamps": [
            24.6,
            29.8
        ]
    },
    "Z7KC1_1": {
        "text": "person runs to the front door.",
        "vid": "Z7KC1",
        "timestamps": [
            24.6,
            29.8
        ]
    },
    "Z7KC1_2": {
        "text": "person runs towards the door.",
        "vid": "Z7KC1",
        "timestamps": [
            24.6,
            29.8
        ]
    },
    "Z7KC1_3": {
        "text": "person they run to the front door.",
        "vid": "Z7KC1",
        "timestamps": [
            24.6,
            29.8
        ]
    },
    "4H935_0": {
        "text": "a person awakens in a bedroom.",
        "vid": "4H935",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "4H935_1": {
        "text": "person turns on the light.",
        "vid": "4H935",
        "timestamps": [
            4.5,
            10.2
        ]
    },
    "4H935_2": {
        "text": "person turns on a light.",
        "vid": "4H935",
        "timestamps": [
            4.5,
            10.2
        ]
    },
    "4H935_3": {
        "text": "person plugged in a light.",
        "vid": "4H935",
        "timestamps": [
            4.5,
            10.2
        ]
    },
    "4H935_4": {
        "text": "person start getting dressed.",
        "vid": "4H935",
        "timestamps": [
            23.3,
            33.0
        ]
    },
    "O76GM_0": {
        "text": "this person opens a few cabinets.",
        "vid": "O76GM",
        "timestamps": [
            0.8,
            15.3
        ]
    },
    "O76GM_1": {
        "text": "person takes out a container of food.",
        "vid": "O76GM",
        "timestamps": [
            12.8,
            19.7
        ]
    },
    "O76GM_2": {
        "text": "a person standing in the kitchen opens a cabinet.",
        "vid": "O76GM",
        "timestamps": [
            0.8,
            15.3
        ]
    },
    "O76GM_3": {
        "text": "person starts closing door.",
        "vid": "O76GM",
        "timestamps": [
            15.0,
            22.9
        ]
    },
    "FLBS9_0": {
        "text": "person laughing at a towel.",
        "vid": "FLBS9",
        "timestamps": [
            15.0,
            20.7
        ]
    },
    "IV1S7_0": {
        "text": "a person takes a glass from a cabinet.",
        "vid": "IV1S7",
        "timestamps": [
            4.7,
            11.7
        ]
    },
    "IV1S7_1": {
        "text": "person puts the glass on the table.",
        "vid": "IV1S7",
        "timestamps": [
            8.2,
            13.6
        ]
    },
    "IV1S7_2": {
        "text": "a person runs through the doorway into a dining room.",
        "vid": "IV1S7",
        "timestamps": [
            0.5,
            6.4
        ]
    },
    "D04GX_0": {
        "text": "a person opens a door.",
        "vid": "D04GX",
        "timestamps": [
            0.0,
            4.0
        ]
    },
    "D04GX_1": {
        "text": "a person is in their entryway holding a camera.",
        "vid": "D04GX",
        "timestamps": [
            8.7,
            14.0
        ]
    },
    "D04GX_2": {
        "text": "person eating a sandwich.",
        "vid": "D04GX",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "D04GX_3": {
        "text": "the person is holding a camera.",
        "vid": "D04GX",
        "timestamps": [
            8.7,
            14.0
        ]
    },
    "D04GX_4": {
        "text": "person eating the sandwich.",
        "vid": "D04GX",
        "timestamps": [
            0.0,
            5.7
        ]
    },
    "D01MJ_0": {
        "text": "person awakens from their slumber.",
        "vid": "D01MJ",
        "timestamps": [
            19.0,
            32.0
        ]
    },
    "D01MJ_1": {
        "text": "person they stand up.",
        "vid": "D01MJ",
        "timestamps": [
            28.9,
            35.8
        ]
    },
    "50E06_0": {
        "text": "person drinks from the cup.",
        "vid": "50E06",
        "timestamps": [
            15.9,
            24.9
        ]
    },
    "50E06_1": {
        "text": "a person in their recreation room is eating some food.",
        "vid": "50E06",
        "timestamps": [
            0.0,
            5.1
        ]
    },
    "50E06_2": {
        "text": "the person puts the cup down.",
        "vid": "50E06",
        "timestamps": [
            21.2,
            27.1
        ]
    },
    "P5YNX_0": {
        "text": "a person is sitting in the chair on their laptop.",
        "vid": "P5YNX",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "P5YNX_1": {
        "text": "a person is sitting in a chair.",
        "vid": "P5YNX",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "P5YNX_2": {
        "text": "person working on their laptop.",
        "vid": "P5YNX",
        "timestamps": [
            0.0,
            12.7
        ]
    },
    "6U47G_0": {
        "text": "a man sits down on a couch.",
        "vid": "6U47G",
        "timestamps": [
            5.3,
            15.5
        ]
    },
    "R4SJJ_0": {
        "text": "person closes the door.",
        "vid": "R4SJJ",
        "timestamps": [
            0.3,
            6.7
        ]
    },
    "R4SJJ_1": {
        "text": "person they throw some clothes on the bed.",
        "vid": "R4SJJ",
        "timestamps": [
            6.2,
            10.9
        ]
    },
    "R4SJJ_2": {
        "text": "person close the window.",
        "vid": "R4SJJ",
        "timestamps": [
            31.4,
            44.3
        ]
    },
    "GA7SB_0": {
        "text": "person eating a burger in a box on their bed.",
        "vid": "GA7SB",
        "timestamps": [
            19.1,
            31.0
        ]
    },
    "GA7SB_1": {
        "text": "person gets undressed.",
        "vid": "GA7SB",
        "timestamps": [
            23.2,
            29.7
        ]
    },
    "GA7SB_2": {
        "text": "a person is undressing in their bedroom.",
        "vid": "GA7SB",
        "timestamps": [
            23.2,
            29.7
        ]
    },
    "GA7SB_3": {
        "text": "person begins to eat.",
        "vid": "GA7SB",
        "timestamps": [
            19.1,
            31.0
        ]
    },
    "GA7SB_4": {
        "text": "person started to eat his food.",
        "vid": "GA7SB",
        "timestamps": [
            19.1,
            31.0
        ]
    },
    "0M0T4_0": {
        "text": "person puts clothes on a bed.",
        "vid": "0M0T4",
        "timestamps": [
            9.9,
            20.5
        ]
    },
    "0M0T4_1": {
        "text": "person starts to play with a phone.",
        "vid": "0M0T4",
        "timestamps": [
            41.4,
            51.7
        ]
    },
    "0M0T4_2": {
        "text": "person turns on the light.",
        "vid": "0M0T4",
        "timestamps": [
            52.3,
            55.0
        ]
    },
    "N5PLR_0": {
        "text": "a person is undressing from their work clothes.",
        "vid": "N5PLR",
        "timestamps": [
            1.4,
            10.8
        ]
    },
    "EG0VZ_0": {
        "text": "person takes a book.",
        "vid": "EG0VZ",
        "timestamps": [
            16.3,
            22.7
        ]
    },
    "EG0VZ_1": {
        "text": "a person awakens in their bedroom.",
        "vid": "EG0VZ",
        "timestamps": [
            7.2,
            18.4
        ]
    },
    "SSPMK_0": {
        "text": "person taking a drink from a cup.",
        "vid": "SSPMK",
        "timestamps": [
            27.1,
            34.6
        ]
    },
    "SSPMK_1": {
        "text": "person he drinks from a cup in his hand.",
        "vid": "SSPMK",
        "timestamps": [
            27.1,
            34.6
        ]
    },
    "GMLPK_0": {
        "text": "person takes a bite of the sandwich.",
        "vid": "GMLPK",
        "timestamps": [
            11.0,
            22.4
        ]
    },
    "72LJ3_0": {
        "text": "the person throws the book.",
        "vid": "72LJ3",
        "timestamps": [
            15.1,
            22.6
        ]
    },
    "72LJ3_1": {
        "text": "person throws the book on the bed.",
        "vid": "72LJ3",
        "timestamps": [
            15.1,
            22.6
        ]
    },
    "72LJ3_2": {
        "text": "the person laughs at their book.",
        "vid": "72LJ3",
        "timestamps": [
            7.2,
            13.6
        ]
    },
    "EEGGA_0": {
        "text": "person begins eating.",
        "vid": "EEGGA",
        "timestamps": [
            15.9,
            22.2
        ]
    },
    "EEGGA_1": {
        "text": "person starts eating.",
        "vid": "EEGGA",
        "timestamps": [
            15.9,
            22.2
        ]
    },
    "EEGGA_2": {
        "text": "person sits in chair.",
        "vid": "EEGGA",
        "timestamps": [
            0.0,
            4.6
        ]
    },
    "MLWB5_0": {
        "text": "person a girl is laying on the floor.",
        "vid": "MLWB5",
        "timestamps": [
            0.0,
            10.5
        ]
    },
    "MLWB5_1": {
        "text": "person start fixing their hair.",
        "vid": "MLWB5",
        "timestamps": [
            11.4,
            21.3
        ]
    },
    "0HGNK_0": {
        "text": "a second person runs in.",
        "vid": "0HGNK",
        "timestamps": [
            8.4,
            13.6
        ]
    },
    "0HGNK_1": {
        "text": "another person comes running.",
        "vid": "0HGNK",
        "timestamps": [
            8.4,
            13.6
        ]
    },
    "0HGNK_2": {
        "text": "person puts a box on the counter.",
        "vid": "0HGNK",
        "timestamps": [
            7.3,
            13.1
        ]
    },
    "0HGNK_3": {
        "text": "person puts box on the table.",
        "vid": "0HGNK",
        "timestamps": [
            7.3,
            13.1
        ]
    },
    "0HGNK_4": {
        "text": "person run away.",
        "vid": "0HGNK",
        "timestamps": [
            8.4,
            13.6
        ]
    },
    "2CJC9_0": {
        "text": "the person opens a medicine cabinet.",
        "vid": "2CJC9",
        "timestamps": [
            8.4,
            15.4
        ]
    },
    "2CJC9_1": {
        "text": "the person opens the cabinet.",
        "vid": "2CJC9",
        "timestamps": [
            8.4,
            15.4
        ]
    },
    "2CJC9_2": {
        "text": "a person is smiling at himself in the mirror.",
        "vid": "2CJC9",
        "timestamps": [
            0.0,
            11.6
        ]
    },
    "OK6BF_0": {
        "text": "the person opened the window to let fresh air in.",
        "vid": "OK6BF",
        "timestamps": [
            19.0,
            25.0
        ]
    },
    "8CCEV_0": {
        "text": "person putting the laptop on bed.",
        "vid": "8CCEV",
        "timestamps": [
            6.1,
            13.9
        ]
    },
    "8CCEV_1": {
        "text": "person they put the pillow down.",
        "vid": "8CCEV",
        "timestamps": [
            5.9,
            11.7
        ]
    },
    "8CCEV_2": {
        "text": "person holding a pillow,.",
        "vid": "8CCEV",
        "timestamps": [
            0.0,
            5.6
        ]
    },
    "8CCEV_3": {
        "text": "a person who is sitting on a floor with laptop.",
        "vid": "8CCEV",
        "timestamps": [
            6.4,
            14.8
        ]
    },
    "8CCEV_4": {
        "text": "person putting pillow aside.",
        "vid": "8CCEV",
        "timestamps": [
            5.9,
            11.7
        ]
    },
    "8CCEV_5": {
        "text": "a person is snuggling a pillow with their laptop open.",
        "vid": "8CCEV",
        "timestamps": [
            0.0,
            4.1
        ]
    },
    "SUE5L_0": {
        "text": "the person is holding a cup.",
        "vid": "SUE5L",
        "timestamps": [
            13.5,
            25.1
        ]
    },
    "R5O7F_0": {
        "text": "person putting clothes in a cabinet.",
        "vid": "R5O7F",
        "timestamps": [
            17.8,
            24.9
        ]
    },
    "R5O7F_1": {
        "text": "person start dressing with different clothes.",
        "vid": "R5O7F",
        "timestamps": [
            28.5,
            40.0
        ]
    },
    "R5O7F_2": {
        "text": "person opens a cabinet.",
        "vid": "R5O7F",
        "timestamps": [
            11.0,
            19.5
        ]
    },
    "R5O7F_3": {
        "text": "the person is undressing.",
        "vid": "R5O7F",
        "timestamps": [
            28.5,
            40.0
        ]
    },
    "R5O7F_4": {
        "text": "a person puts some clothes into a cabinet.",
        "vid": "R5O7F",
        "timestamps": [
            17.8,
            24.9
        ]
    },
    "R5O7F_5": {
        "text": "person puts the clothing on a shelf in the cabinet.",
        "vid": "R5O7F",
        "timestamps": [
            17.8,
            24.9
        ]
    },
    "Y50QF_0": {
        "text": "person opening a box in a dining room.",
        "vid": "Y50QF",
        "timestamps": [
            31.9,
            38.0
        ]
    },
    "Y50QF_1": {
        "text": "person pouring a cup of coffee.",
        "vid": "Y50QF",
        "timestamps": [
            21.8,
            30.9
        ]
    },
    "Y50QF_2": {
        "text": "person pours himself some coffee into a cup.",
        "vid": "Y50QF",
        "timestamps": [
            21.8,
            30.9
        ]
    },
    "Y50QF_3": {
        "text": "person pour a cup of coffee.",
        "vid": "Y50QF",
        "timestamps": [
            21.8,
            30.9
        ]
    },
    "WZDXS_0": {
        "text": "a person is dressing in their bedroom.",
        "vid": "WZDXS",
        "timestamps": [
            0.0,
            10.3
        ]
    },
    "WZDXS_1": {
        "text": "person watching something on a laptop screen.",
        "vid": "WZDXS",
        "timestamps": [
            13.5,
            20.2
        ]
    },
    "VEH0A_0": {
        "text": "person is lying on floor fixing door.",
        "vid": "VEH0A",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "VEH0A_1": {
        "text": "a person is sitting on the floor.",
        "vid": "VEH0A",
        "timestamps": [
            2.7,
            7.2
        ]
    },
    "VEH0A_2": {
        "text": "person starts closing door.",
        "vid": "VEH0A",
        "timestamps": [
            0.0,
            5.5
        ]
    },
    "VEH0A_3": {
        "text": "person sitting on the floor looking into a cabinet.",
        "vid": "VEH0A",
        "timestamps": [
            2.7,
            7.2
        ]
    },
    "VEH0A_4": {
        "text": "person closing a cabinet.",
        "vid": "VEH0A",
        "timestamps": [
            0.0,
            4.4
        ]
    },
    "5WS7U_0": {
        "text": "person puts shoes on.",
        "vid": "5WS7U",
        "timestamps": [
            13.6,
            21.7
        ]
    },
    "5WS7U_1": {
        "text": "person fixes their hair.",
        "vid": "5WS7U",
        "timestamps": [
            33.5,
            37.9
        ]
    },
    "5WS7U_2": {
        "text": "person puts on shoes.",
        "vid": "5WS7U",
        "timestamps": [
            13.6,
            21.7
        ]
    },
    "2OJY8_0": {
        "text": "a person is in a bedroom dressing.",
        "vid": "2OJY8",
        "timestamps": [
            3.0,
            15.7
        ]
    },
    "2OJY8_1": {
        "text": "a person gets dressed in the bedroom.",
        "vid": "2OJY8",
        "timestamps": [
            3.0,
            15.7
        ]
    },
    "2OJY8_2": {
        "text": "person open a box of dishes.",
        "vid": "2OJY8",
        "timestamps": [
            23.1,
            28.7
        ]
    },
    "2OJY8_3": {
        "text": "person begins to put dishes in a box.",
        "vid": "2OJY8",
        "timestamps": [
            23.9,
            30.1
        ]
    },
    "SPF63_0": {
        "text": "person they take something from a box.",
        "vid": "SPF63",
        "timestamps": [
            13.2,
            18.9
        ]
    },
    "SPF63_1": {
        "text": "person throws the case on the floor.",
        "vid": "SPF63",
        "timestamps": [
            23.5,
            29.8
        ]
    },
    "SPF63_2": {
        "text": "person throws the box on the floor.",
        "vid": "SPF63",
        "timestamps": [
            24.1,
            29.7
        ]
    },
    "SPF63_3": {
        "text": "the person opens the box.",
        "vid": "SPF63",
        "timestamps": [
            14.8,
            21.2
        ]
    },
    "Y665P_0": {
        "text": "person sits down on the sofa.",
        "vid": "Y665P",
        "timestamps": [
            14.5,
            22.8
        ]
    },
    "Y665P_1": {
        "text": "person sits down on the couch to read the book.",
        "vid": "Y665P",
        "timestamps": [
            14.5,
            22.8
        ]
    },
    "Y665P_2": {
        "text": "person sits down on a couch.",
        "vid": "Y665P",
        "timestamps": [
            14.5,
            22.8
        ]
    },
    "4VJDU_0": {
        "text": "the other person puts on his shoes in the background.",
        "vid": "4VJDU",
        "timestamps": [
            0.0,
            13.3
        ]
    },
    "4VJDU_1": {
        "text": "one person dresses into a pair of shoes.",
        "vid": "4VJDU",
        "timestamps": [
            0.0,
            13.5
        ]
    },
    "Y4GHN_0": {
        "text": "person closed a cabinet.",
        "vid": "Y4GHN",
        "timestamps": [
            7.0,
            19.8
        ]
    },
    "RKOOJ_0": {
        "text": "person looks at the picture.",
        "vid": "RKOOJ",
        "timestamps": [
            3.8,
            12.8
        ]
    },
    "RKOOJ_1": {
        "text": "a person walks into the room holding a picture.",
        "vid": "RKOOJ",
        "timestamps": [
            3.2,
            13.1
        ]
    },
    "Q948H_0": {
        "text": "person puts the book on the table again.",
        "vid": "Q948H",
        "timestamps": [
            7.9,
            20.7
        ]
    },
    "Q948H_1": {
        "text": "the person takes a picture out.",
        "vid": "Q948H",
        "timestamps": [
            5.8,
            22.2
        ]
    },
    "Q948H_2": {
        "text": "person puts the book back on the shelf.",
        "vid": "Q948H",
        "timestamps": [
            17.8,
            33.1
        ]
    },
    "Q948H_3": {
        "text": "person opens it up takes a picture.",
        "vid": "Q948H",
        "timestamps": [
            5.8,
            22.2
        ]
    },
    "OPMF7_0": {
        "text": "person they begin sneezing.",
        "vid": "OPMF7",
        "timestamps": [
            9.4,
            14.3
        ]
    },
    "OPMF7_1": {
        "text": "a person is also sneezing.",
        "vid": "OPMF7",
        "timestamps": [
            9.4,
            14.3
        ]
    },
    "VINM0_0": {
        "text": "person holding a pair of shoes.",
        "vid": "VINM0",
        "timestamps": [
            0.0,
            8.5
        ]
    },
    "VINM0_1": {
        "text": "a person puts his shoes down on the floor.",
        "vid": "VINM0",
        "timestamps": [
            2.7,
            9.6
        ]
    },
    "VINM0_2": {
        "text": "the person puts down the shoes.",
        "vid": "VINM0",
        "timestamps": [
            2.7,
            9.6
        ]
    },
    "VINM0_3": {
        "text": "a person is holding shoes.",
        "vid": "VINM0",
        "timestamps": [
            0.0,
            8.5
        ]
    },
    "VINM0_4": {
        "text": "person looks out the window.",
        "vid": "VINM0",
        "timestamps": [
            15.2,
            31.7
        ]
    },
    "6JLD4_0": {
        "text": "person closes the door.",
        "vid": "6JLD4",
        "timestamps": [
            23.0,
            28.7
        ]
    },
    "6JLD4_1": {
        "text": "person gets dressed.",
        "vid": "6JLD4",
        "timestamps": [
            11.2,
            19.0
        ]
    },
    "6JLD4_2": {
        "text": "a person turns on a light in the closet.",
        "vid": "6JLD4",
        "timestamps": [
            3.1,
            7.2
        ]
    },
    "6JLD4_3": {
        "text": "person turns on the lights.",
        "vid": "6JLD4",
        "timestamps": [
            3.1,
            7.2
        ]
    },
    "6JLD4_4": {
        "text": "person turns the lights off.",
        "vid": "6JLD4",
        "timestamps": [
            21.0,
            25.3
        ]
    },
    "PEWH4_0": {
        "text": "person eats a sandwich.",
        "vid": "PEWH4",
        "timestamps": [
            9.7,
            24.5
        ]
    },
    "PEWH4_1": {
        "text": "person they eat a sandwich.",
        "vid": "PEWH4",
        "timestamps": [
            9.7,
            24.5
        ]
    },
    "J95U1_0": {
        "text": "the person picked up a phone to play with it.",
        "vid": "J95U1",
        "timestamps": [
            10.3,
            28.3
        ]
    },
    "J95U1_1": {
        "text": "person begin laughing.",
        "vid": "J95U1",
        "timestamps": [
            19.1,
            23.3
        ]
    },
    "K6W5I_0": {
        "text": "person puts away the groceries.",
        "vid": "K6W5I",
        "timestamps": [
            3.3,
            18.2
        ]
    },
    "K6W5I_1": {
        "text": "the person puts the groceries on the table.",
        "vid": "K6W5I",
        "timestamps": [
            3.1,
            10.9
        ]
    },
    "K6W5I_2": {
        "text": "the person opens door.",
        "vid": "K6W5I",
        "timestamps": [
            15.3,
            20.5
        ]
    },
    "PS7XK_0": {
        "text": "the person is smiling often.",
        "vid": "PS7XK",
        "timestamps": [
            26.0,
            32.0
        ]
    },
    "WZZPC_0": {
        "text": "person they start to open a door.",
        "vid": "WZZPC",
        "timestamps": [
            5.1,
            8.0
        ]
    },
    "WZZPC_1": {
        "text": "person open a door.",
        "vid": "WZZPC",
        "timestamps": [
            5.1,
            8.0
        ]
    },
    "BZ5N5_0": {
        "text": "the person takes two glasses from the cabinet.",
        "vid": "BZ5N5",
        "timestamps": [
            2.2,
            16.8
        ]
    },
    "O6DJW_0": {
        "text": "person holds a sandwich on it.",
        "vid": "O6DJW",
        "timestamps": [
            6.7,
            12.1
        ]
    },
    "SKZUG_0": {
        "text": "a person is fixing a light in the refrigerator.",
        "vid": "SKZUG",
        "timestamps": [
            4.5,
            12.0
        ]
    },
    "SKZUG_1": {
        "text": "person is cooking on a stove.",
        "vid": "SKZUG",
        "timestamps": [
            10.6,
            17.0
        ]
    },
    "SKZUG_2": {
        "text": "a person is fixing the light in the refrigerator.",
        "vid": "SKZUG",
        "timestamps": [
            4.5,
            12.0
        ]
    },
    "SKZUG_3": {
        "text": "the person closes the refrigerator door when they are done.",
        "vid": "SKZUG",
        "timestamps": [
            9.8,
            17.0
        ]
    },
    "LFPWI_0": {
        "text": "person begins undressing.",
        "vid": "LFPWI",
        "timestamps": [
            4.0,
            18.4
        ]
    },
    "LFPWI_1": {
        "text": "a person is undressing in front of a sink.",
        "vid": "LFPWI",
        "timestamps": [
            4.0,
            18.4
        ]
    },
    "LFPWI_2": {
        "text": "a person opens a door.",
        "vid": "LFPWI",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "LFPWI_3": {
        "text": "person open the door.",
        "vid": "LFPWI",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "LFPWI_4": {
        "text": "the person opens the bathroom door.",
        "vid": "LFPWI",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "LFPWI_5": {
        "text": "a person is opening a door.",
        "vid": "LFPWI",
        "timestamps": [
            0.0,
            7.2
        ]
    },
    "WWL0K_0": {
        "text": "person throw the blanket down on the floor.",
        "vid": "WWL0K",
        "timestamps": [
            7.9,
            15.3
        ]
    },
    "WWL0K_1": {
        "text": "person throws the blanket on the floor.",
        "vid": "WWL0K",
        "timestamps": [
            7.9,
            15.3
        ]
    },
    "WWL0K_2": {
        "text": "person looking at a book.",
        "vid": "WWL0K",
        "timestamps": [
            0.0,
            7.9
        ]
    },
    "WWL0K_3": {
        "text": "person throws the blanket off the stairs.",
        "vid": "WWL0K",
        "timestamps": [
            7.9,
            15.3
        ]
    },
    "10M0F_0": {
        "text": "a person throwing a book.",
        "vid": "10M0F",
        "timestamps": [
            19.3,
            24.8
        ]
    },
    "10M0F_1": {
        "text": "person sneezing into a camera.",
        "vid": "10M0F",
        "timestamps": [
            21.6,
            32.0
        ]
    },
    "ZFT06_0": {
        "text": "a person is laughing in front of the refrigerator.",
        "vid": "ZFT06",
        "timestamps": [
            21.5,
            30.0
        ]
    },
    "ZFT06_1": {
        "text": "person opens the door.",
        "vid": "ZFT06",
        "timestamps": [
            8.6,
            14.8
        ]
    },
    "ZFT06_2": {
        "text": "person takes a glass out from the refrigerator.",
        "vid": "ZFT06",
        "timestamps": [
            18.9,
            25.7
        ]
    },
    "APLZS_0": {
        "text": "person closes the box back up.",
        "vid": "APLZS",
        "timestamps": [
            24.3,
            30.0
        ]
    },
    "APLZS_1": {
        "text": "the person opens a box.",
        "vid": "APLZS",
        "timestamps": [
            17.7,
            26.1
        ]
    },
    "9O0NP_0": {
        "text": "a person throws a book into a box.",
        "vid": "9O0NP",
        "timestamps": [
            5.1,
            13.6
        ]
    },
    "9O0NP_1": {
        "text": "a person looks through a book.",
        "vid": "9O0NP",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "9O0NP_2": {
        "text": "a person looks at a book.",
        "vid": "9O0NP",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "9O0NP_3": {
        "text": "a person in a kitchen reads from a book.",
        "vid": "9O0NP",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "BPT87_0": {
        "text": "a person runs up some stairs.",
        "vid": "BPT87",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "BPT87_1": {
        "text": "the person takes a towel.",
        "vid": "BPT87",
        "timestamps": [
            13.6,
            19.4
        ]
    },
    "BPT87_2": {
        "text": "a person runs up.",
        "vid": "BPT87",
        "timestamps": [
            0.0,
            8.7
        ]
    },
    "BPT87_3": {
        "text": "a person laughs as they walk down the stairs.",
        "vid": "BPT87",
        "timestamps": [
            7.2,
            15.3
        ]
    },
    "BPT87_4": {
        "text": "the person laughs.",
        "vid": "BPT87",
        "timestamps": [
            7.2,
            15.3
        ]
    },
    "GL7E6_0": {
        "text": "person they take the medicine.",
        "vid": "GL7E6",
        "timestamps": [
            19.4,
            25.3
        ]
    },
    "GL7E6_1": {
        "text": "person takes some medicine.",
        "vid": "GL7E6",
        "timestamps": [
            19.4,
            25.3
        ]
    },
    "GL7E6_2": {
        "text": "a person awakens in their living room sneezing.",
        "vid": "GL7E6",
        "timestamps": [
            3.3,
            12.1
        ]
    },
    "GL7E6_3": {
        "text": "person they open a bag.",
        "vid": "GL7E6",
        "timestamps": [
            9.9,
            15.0
        ]
    },
    "P4SB9_0": {
        "text": "person start eating some food from the stove.",
        "vid": "P4SB9",
        "timestamps": [
            13.1,
            19.0
        ]
    },
    "P4SB9_1": {
        "text": "person puts the broom up against a wall.",
        "vid": "P4SB9",
        "timestamps": [
            5.4,
            11.2
        ]
    },
    "P4SB9_2": {
        "text": "person puts the broom down.",
        "vid": "P4SB9",
        "timestamps": [
            5.4,
            11.2
        ]
    },
    "WC5QK_0": {
        "text": "person they sit in a chair.",
        "vid": "WC5QK",
        "timestamps": [
            17.2,
            31.0
        ]
    },
    "Y79PC_0": {
        "text": "person they undress.",
        "vid": "Y79PC",
        "timestamps": [
            12.0,
            21.3
        ]
    },
    "Y79PC_1": {
        "text": "the person undressed out of their jacket.",
        "vid": "Y79PC",
        "timestamps": [
            12.0,
            21.3
        ]
    },
    "Y79PC_2": {
        "text": "person turn off the light.",
        "vid": "Y79PC",
        "timestamps": [
            19.2,
            25.5
        ]
    },
    "08LOY_0": {
        "text": "another person runs up the stairs.",
        "vid": "08LOY",
        "timestamps": [
            0.0,
            8.3
        ]
    },
    "VRXQX_0": {
        "text": "a person is putting on clothes.",
        "vid": "VRXQX",
        "timestamps": [
            3.3,
            15.3
        ]
    },
    "VRXQX_1": {
        "text": "person drinking from a cup walking around.",
        "vid": "VRXQX",
        "timestamps": [
            16.7,
            24.4
        ]
    },
    "C6N6Y_0": {
        "text": "person eating an apple.",
        "vid": "C6N6Y",
        "timestamps": [
            0.0,
            6.4
        ]
    },
    "BO12I_0": {
        "text": "another person is closing a refrigerator.",
        "vid": "BO12I",
        "timestamps": [
            3.1,
            17.7
        ]
    },
    "BO12I_1": {
        "text": "a second person closes the door to the refrigerator.",
        "vid": "BO12I",
        "timestamps": [
            3.1,
            17.7
        ]
    },
    "120YL_0": {
        "text": "person begins to eat the cookie.",
        "vid": "120YL",
        "timestamps": [
            37.0,
            43.0
        ]
    },
    "120YL_1": {
        "text": "the person opens the box.",
        "vid": "120YL",
        "timestamps": [
            4.8,
            9.7
        ]
    },
    "120YL_2": {
        "text": "person eats the cookie.",
        "vid": "120YL",
        "timestamps": [
            37.0,
            43.0
        ]
    },
    "120YL_3": {
        "text": "the person sits down in a chair.",
        "vid": "120YL",
        "timestamps": [
            35.5,
            43.0
        ]
    },
    "120YL_4": {
        "text": "person sitting at the table.",
        "vid": "120YL",
        "timestamps": [
            35.0,
            43.0
        ]
    },
    "120YL_5": {
        "text": "the person opens the box of cookies.",
        "vid": "120YL",
        "timestamps": [
            4.8,
            9.7
        ]
    },
    "120YL_6": {
        "text": "person sits down in a chair at the table.",
        "vid": "120YL",
        "timestamps": [
            35.0,
            43.0
        ]
    },
    "120YL_7": {
        "text": "person takes the plate to the table to eat.",
        "vid": "120YL",
        "timestamps": [
            37.0,
            43.0
        ]
    },
    "MK16R_0": {
        "text": "a person is smiling.",
        "vid": "MK16R",
        "timestamps": [
            10.7,
            17.1
        ]
    },
    "MK16R_1": {
        "text": "person putting groceries away.",
        "vid": "MK16R",
        "timestamps": [
            0.4,
            9.8
        ]
    },
    "H032R_0": {
        "text": "person throws a towel on the floor.",
        "vid": "H032R",
        "timestamps": [
            0.8,
            6.8
        ]
    },
    "H032R_1": {
        "text": "person sitting down on a pillow in the bed.",
        "vid": "H032R",
        "timestamps": [
            12.4,
            23.0
        ]
    },
    "LUQWY_0": {
        "text": "person they open the laptop.",
        "vid": "LUQWY",
        "timestamps": [
            8.3,
            20.5
        ]
    },
    "KV6V8_0": {
        "text": "person the girl closes her laptop.",
        "vid": "KV6V8",
        "timestamps": [
            7.3,
            14.0
        ]
    },
    "07TCM_0": {
        "text": "person starts putting on their shoes.",
        "vid": "07TCM",
        "timestamps": [
            6.0,
            15.9
        ]
    },
    "07TCM_1": {
        "text": "person putting shoes.",
        "vid": "07TCM",
        "timestamps": [
            6.0,
            15.9
        ]
    },
    "07TCM_2": {
        "text": "person dressing for the cold.",
        "vid": "07TCM",
        "timestamps": [
            13.3,
            26.1
        ]
    },
    "07TCM_3": {
        "text": "person starts sneezing.",
        "vid": "07TCM",
        "timestamps": [
            22.1,
            35.0
        ]
    },
    "07TCM_4": {
        "text": "person putting shoes on.",
        "vid": "07TCM",
        "timestamps": [
            6.0,
            15.9
        ]
    },
    "RFH6M_0": {
        "text": "person puts a towel over the shoulder.",
        "vid": "RFH6M",
        "timestamps": [
            12.9,
            20.2
        ]
    },
    "RFH6M_1": {
        "text": "a person opens the refrigerator.",
        "vid": "RFH6M",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "RFH6M_2": {
        "text": "person closes the door.",
        "vid": "RFH6M",
        "timestamps": [
            0.3,
            5.7
        ]
    },
    "RFH6M_3": {
        "text": "the person opens the refrigerator,removes food.",
        "vid": "RFH6M",
        "timestamps": [
            0.0,
            3.8
        ]
    },
    "7IPW7_0": {
        "text": "a person walks through the doorway.",
        "vid": "7IPW7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "7IPW7_1": {
        "text": "person walks through the doorway into a room.",
        "vid": "7IPW7",
        "timestamps": [
            0.0,
            6.3
        ]
    },
    "H0Q6V_0": {
        "text": "person set up on the sofa take off shoes.",
        "vid": "H0Q6V",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "H0Q6V_1": {
        "text": "person takes their shoes off.",
        "vid": "H0Q6V",
        "timestamps": [
            0.0,
            13.1
        ]
    },
    "CUHT0_0": {
        "text": "person takes a picture of the couch with a camera.",
        "vid": "CUHT0",
        "timestamps": [
            11.0,
            16.6
        ]
    },
    "CUHT0_1": {
        "text": "a person walks into the living holding a pillow.",
        "vid": "CUHT0",
        "timestamps": [
            0.0,
            7.9
        ]
    },
    "CUHT0_2": {
        "text": "person they put the camera on the baby's jumper.",
        "vid": "CUHT0",
        "timestamps": [
            13.3,
            21.7
        ]
    },
    "FJYZH_0": {
        "text": "person eat something they took out of their pocket.",
        "vid": "FJYZH",
        "timestamps": [
            12.1,
            19.0
        ]
    },
    "FJYZH_1": {
        "text": "person eat a small snack they got from their pocket.",
        "vid": "FJYZH",
        "timestamps": [
            12.1,
            19.0
        ]
    },
    "FJYZH_2": {
        "text": "person put the book down on a chair.",
        "vid": "FJYZH",
        "timestamps": [
            5.6,
            11.0
        ]
    },
    "FJYZH_3": {
        "text": "person standing near a closet holding a homework book.",
        "vid": "FJYZH",
        "timestamps": [
            4.8,
            9.2
        ]
    },
    "FJYZH_4": {
        "text": "person they put the book down on a chair.",
        "vid": "FJYZH",
        "timestamps": [
            5.6,
            11.0
        ]
    },
    "M18XP_0": {
        "text": "a person opens a door.",
        "vid": "M18XP",
        "timestamps": [
            0.0,
            8.6
        ]
    },
    "M18XP_1": {
        "text": "person they close the door.",
        "vid": "M18XP",
        "timestamps": [
            2.5,
            11.2
        ]
    },
    "ZC59Y_0": {
        "text": "a person is opening a book.",
        "vid": "ZC59Y",
        "timestamps": [
            2.8,
            10.2
        ]
    },
    "FSOFF_0": {
        "text": "another person walks by the takes off their shoes.",
        "vid": "FSOFF",
        "timestamps": [
            11.8,
            21.0
        ]
    },
    "FSOFF_1": {
        "text": "person proceeds to take their shoes off.",
        "vid": "FSOFF",
        "timestamps": [
            11.8,
            21.0
        ]
    },
    "4KK20_0": {
        "text": "person throwing a box down.",
        "vid": "4KK20",
        "timestamps": [
            24.4,
            32.0
        ]
    },
    "4KK20_1": {
        "text": "person talking on their phone.",
        "vid": "4KK20",
        "timestamps": [
            1.8,
            13.7
        ]
    },
    "4KK20_2": {
        "text": "person opening a box.",
        "vid": "4KK20",
        "timestamps": [
            18.3,
            30.4
        ]
    },
    "4KK20_3": {
        "text": "person throwing the box to the floor angrily.",
        "vid": "4KK20",
        "timestamps": [
            24.4,
            32.0
        ]
    },
    "SVIXG_0": {
        "text": "person opening a box.",
        "vid": "SVIXG",
        "timestamps": [
            1.4,
            13.1
        ]
    },
    "SVIXG_1": {
        "text": "person eating from a box of food.",
        "vid": "SVIXG",
        "timestamps": [
            16.5,
            28.0
        ]
    },
    "SVIXG_2": {
        "text": "person eating something out of it.",
        "vid": "SVIXG",
        "timestamps": [
            16.5,
            28.0
        ]
    },
    "SVIXG_3": {
        "text": "person eats a few pieces from inside.",
        "vid": "SVIXG",
        "timestamps": [
            16.5,
            28.0
        ]
    },
    "7JHW2_0": {
        "text": "the person puts the laptop down onto a table.",
        "vid": "7JHW2",
        "timestamps": [
            3.1,
            8.3
        ]
    },
    "7JHW2_1": {
        "text": "a person runs into the garage.",
        "vid": "7JHW2",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "7JHW2_2": {
        "text": "person holding a laptop.",
        "vid": "7JHW2",
        "timestamps": [
            0.0,
            7.0
        ]
    },
    "7JHW2_3": {
        "text": "person sets a laptop computer on a counter.",
        "vid": "7JHW2",
        "timestamps": [
            3.1,
            8.3
        ]
    }
}